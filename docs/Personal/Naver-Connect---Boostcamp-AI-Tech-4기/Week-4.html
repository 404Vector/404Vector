<!DOCTYPE html>
<html lang="en"><head><title>Week 4</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;family=IBM Plex Mono:wght@400;600&amp;display=swap"/><link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin="anonymous"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="HyeongSeok Kim's Vault"/><meta property="og:title" content="Week 4"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Week 4"/><meta name="twitter:description" content="Class of visual perception Modern augmentation techniques Transfer learning Knowledge distillation Hard Label vs Soft Label GoogLeNet Receptive Field(수용필드, 수용장) ResNet Two-stage detector vs One-stage detector Analysis of model behaviors Class of visual perception Color perception Motion perception ..."/><meta property="og:description" content="Class of visual perception Modern augmentation techniques Transfer learning Knowledge distillation Hard Label vs Soft Label GoogLeNet Receptive Field(수용필드, 수용장) ResNet Two-stage detector vs One-stage detector Analysis of model behaviors Class of visual perception Color perception Motion perception ..."/><meta property="og:image:alt" content="Class of visual perception Modern augmentation techniques Transfer learning Knowledge distillation Hard Label vs Soft Label GoogLeNet Receptive Field(수용필드, 수용장) ResNet Two-stage detector vs One-stage detector Analysis of model behaviors Class of visual perception Color perception Motion perception ..."/><meta property="twitter:domain" content="quartz.jzhao.xyz"/><meta property="og:url" content="https://quartz.jzhao.xyz/Personal/Naver-Connect---Boostcamp-AI-Tech-4기/Week-4"/><meta property="twitter:url" content="https://quartz.jzhao.xyz/Personal/Naver-Connect---Boostcamp-AI-Tech-4기/Week-4"/><link rel="icon" href="../../static/icon.png"/><meta name="description" content="Class of visual perception Modern augmentation techniques Transfer learning Knowledge distillation Hard Label vs Soft Label GoogLeNet Receptive Field(수용필드, 수용장) ResNet Two-stage detector vs One-stage detector Analysis of model behaviors Class of visual perception Color perception Motion perception ..."/><meta name="generator" content="Quartz"/><link href="../../index.css" rel="stylesheet" type="text/css" spa-preserve/><style>.expand-button {
  position: absolute;
  display: flex;
  float: right;
  padding: 0.4rem;
  margin: 0.3rem;
  right: 0;
  color: var(--gray);
  border-color: var(--dark);
  background-color: var(--light);
  border: 1px solid;
  border-radius: 5px;
  opacity: 0;
  transition: 0.2s;
}
.expand-button > svg {
  fill: var(--light);
  filter: contrast(0.3);
}
.expand-button:hover {
  cursor: pointer;
  border-color: var(--secondary);
}
.expand-button:focus {
  outline: 0;
}

pre:hover > .expand-button {
  opacity: 1;
  transition: 0.2s;
}

#mermaid-container {
  position: fixed;
  contain: layout;
  z-index: 999;
  left: 0;
  top: 0;
  width: 100vw;
  height: 100vh;
  overflow: hidden;
  display: none;
  backdrop-filter: blur(4px);
  background: rgba(0, 0, 0, 0.5);
}
#mermaid-container.active {
  display: inline-block;
}
#mermaid-container > #mermaid-space {
  border: 1px solid var(--lightgray);
  background-color: var(--light);
  border-radius: 5px;
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  height: 80vh;
  width: 80vw;
  overflow: hidden;
}
#mermaid-container > #mermaid-space > .mermaid-content {
  padding: 2rem;
  position: relative;
  transform-origin: 0 0;
  transition: transform 0.1s ease;
  overflow: visible;
  min-height: 200px;
  min-width: 200px;
}
#mermaid-container > #mermaid-space > .mermaid-content pre {
  margin: 0;
  border: none;
}
#mermaid-container > #mermaid-space > .mermaid-content svg {
  max-width: none;
  height: auto;
}
#mermaid-container > #mermaid-space > .mermaid-controls {
  position: absolute;
  bottom: 20px;
  right: 20px;
  display: flex;
  gap: 8px;
  padding: 8px;
  background: var(--light);
  border: 1px solid var(--lightgray);
  border-radius: 6px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  z-index: 2;
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 32px;
  height: 32px;
  padding: 0;
  border: 1px solid var(--lightgray);
  background: var(--light);
  color: var(--dark);
  border-radius: 4px;
  cursor: pointer;
  font-size: 16px;
  font-family: var(--bodyFont);
  transition: all 0.2s ease;
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:hover {
  background: var(--lightgray);
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:active {
  transform: translateY(1px);
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:nth-child(2) {
  width: auto;
  padding: 0 12px;
  font-size: 14px;
}
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,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 */</style><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../../static/contentIndex.json").then(data => data.json())</script><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="https://quartz.jzhao.xyz/index.xml"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image" content="https://quartz.jzhao.xyz/Personal/Naver-Connect---Boostcamp-AI-Tech-4기/Week-4-og-image.webp"/><meta property="og:image:url" content="https://quartz.jzhao.xyz/Personal/Naver-Connect---Boostcamp-AI-Tech-4기/Week-4-og-image.webp"/><meta name="twitter:image" content="https://quartz.jzhao.xyz/Personal/Naver-Connect---Boostcamp-AI-Tech-4기/Week-4-og-image.webp"/><meta property="og:image:type" content="image/.webp"/></head><body data-slug="Personal/Naver-Connect---Boostcamp-AI-Tech-4기/Week-4"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href="../..">HyeongSeok Kim's Vault</a></h2><div class="spacer mobile-only"></div><div class="flex-component" style="flex-direction: row; flex-wrap: nowrap; gap: 1rem;"><div style="flex-grow: 1; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><div class="search"><button class="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div class="search-container"><div class="search-space"><input autocomplete="off" class="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div class="search-layout" data-preview="true"></div></div></div></div></div><div style="flex-grow: 0; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><button class="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div style="flex-grow: 0; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><button class="readermode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="readerIcon" fill="currentColor" stroke="currentColor" stroke-width="0.2" stroke-linecap="round" stroke-linejoin="round" width="64px" height="64px" viewBox="0 0 24 24" aria-label="Reader mode"><title>Reader mode</title><g transform="translate(-1.8, -1.8) scale(1.15, 1.2)"><path d="M8.9891247,2.5 C10.1384702,2.5 11.2209868,2.96705384 12.0049645,3.76669482 C12.7883914,2.96705384 13.8709081,2.5 15.0202536,2.5 L18.7549359,2.5 C19.1691495,2.5 19.5049359,2.83578644 19.5049359,3.25 L19.5046891,4.004 L21.2546891,4.00457396 C21.6343849,4.00457396 21.9481801,4.28672784 21.9978425,4.6528034 L22.0046891,4.75457396 L22.0046891,20.25 C22.0046891,20.6296958 21.7225353,20.943491 21.3564597,20.9931534 L21.2546891,21 L2.75468914,21 C2.37499337,21 2.06119817,20.7178461 2.01153575,20.3517706 L2.00468914,20.25 L2.00468914,4.75457396 C2.00468914,4.37487819 2.28684302,4.061083 2.65291858,4.01142057 L2.75468914,4.00457396 L4.50368914,4.004 L4.50444233,3.25 C4.50444233,2.87030423 4.78659621,2.55650904 5.15267177,2.50684662 L5.25444233,2.5 L8.9891247,2.5 Z M4.50368914,5.504 L3.50468914,5.504 L3.50468914,19.5 L10.9478955,19.4998273 C10.4513189,18.9207296 9.73864328,18.5588115 8.96709342,18.5065584 L8.77307039,18.5 L5.25444233,18.5 C4.87474657,18.5 4.56095137,18.2178461 4.51128895,17.8517706 L4.50444233,17.75 L4.50368914,5.504 Z M19.5049359,17.75 C19.5049359,18.1642136 19.1691495,18.5 18.7549359,18.5 L15.2363079,18.5 C14.3910149,18.5 13.5994408,18.8724714 13.0614828,19.4998273 L20.5046891,19.5 L20.5046891,5.504 L19.5046891,5.504 L19.5049359,17.75 Z M18.0059359,3.999 L15.0202536,4 L14.8259077,4.00692283 C13.9889509,4.06666544 13.2254227,4.50975805 12.7549359,5.212 L12.7549359,17.777 L12.7782651,17.7601316 C13.4923805,17.2719483 14.3447024,17 15.2363079,17 L18.0059359,16.999 L18.0056891,4.798 L18.0033792,4.75457396 L18.0056891,4.71 L18.0059359,3.999 Z M8.9891247,4 L6.00368914,3.999 L6.00599909,4.75457396 L6.00599909,4.75457396 L6.00368914,4.783 L6.00368914,16.999 L8.77307039,17 C9.57551536,17 10.3461406,17.2202781 11.0128313,17.6202194 L11.2536891,17.776 L11.2536891,5.211 C10.8200889,4.56369974 10.1361548,4.13636104 9.37521067,4.02745763 L9.18347055,4.00692283 L8.9891247,4 Z"></path></g></svg></button></div></div><div class="explorer" data-behavior="link" data-collapsed="collapsed" data-savestate="true" data-data-fns="{&quot;order&quot;:[&quot;filter&quot;,&quot;map&quot;,&quot;sort&quot;],&quot;sortFn&quot;:&quot;(a,b)=>!a.isFolder&amp;&amp;!b.isFolder||a.isFolder&amp;&amp;b.isFolder?a.displayName.localeCompare(b.displayName,void 0,{numeric:!0,sensitivity:\&quot;base\&quot;}):!a.isFolder&amp;&amp;b.isFolder?1:-1&quot;,&quot;filterFn&quot;:&quot;node=>node.slugSegment!==\&quot;tags\&quot;&quot;,&quot;mapFn&quot;:&quot;node=>node&quot;}"><button type="button" class="explorer-toggle mobile-explorer hide-until-loaded" data-mobile="true" aria-controls="explorer-content"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-menu"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg></button><button type="button" class="title-button explorer-toggle desktop-explorer" data-mobile="false" aria-expanded="true"><h2>Explorer</h2><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div class="explorer-content" aria-expanded="false"><ul class="explorer-ul overflow" id="list-0"><li class="overflow-end"></li></ul></div><template id="template-file"><li><a href="#"></a></li></template><template id="template-folder"><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div><button class="folder-button"><span class="folder-title"></span></button></div></div><div class="folder-outer"><ul class="content"></ul></div></li></template></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../Personal/">Personal</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../Personal/Naver-Connect---Boostcamp-AI-Tech-4기/">Naver Connect   Boostcamp AI Tech 4기</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Week 4</a></div></nav><h1 class="article-title">Week 4</h1><p show-comma="true" class="content-meta"><time datetime="2025-06-17T08:48:27.127Z">Jun 17, 2025</time><span>7 min read</span></p></div></div><article class="popover-hint"><ul>
<li><a href="#class-of-visual-perception" class="internal alias">Class of visual perception</a></li>
<li><a href="#modern-augmentation-techniques" class="internal alias">Modern augmentation techniques</a></li>
<li><a href="#transfer-learning" class="internal alias">Transfer learning</a></li>
<li><a href="#knowledge-distillation" class="internal alias">Knowledge distillation</a></li>
<li><a href="#hard-label-vs-soft-label" class="internal alias">Hard Label vs Soft Label</a></li>
<li><a href="#googlenet" class="internal alias">GoogLeNet</a></li>
<li><a href="#receptive-field%EC%88%98%EC%9A%A9%ED%95%84%EB%93%9C-%EC%88%98%EC%9A%A9%EC%9E%A5" class="internal alias">Receptive Field(수용필드, 수용장)</a></li>
<li><a href="#resnet" class="internal alias">ResNet</a></li>
<li><a href="#two-stage-detector-vs-one-stage-detector" class="internal alias">Two-stage detector vs One-stage detector</a></li>
<li><a href="#analysis-of-model-behaviors" class="internal alias">Analysis of model behaviors</a></li>
</ul>
<hr/>
<h2 id="class-of-visual-perception">Class of visual perception<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#class-of-visual-perception" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>
<p>Color perception</p>
</li>
<li>
<p>Motion perception</p>
</li>
<li>
<p>3D perception</p>
</li>
<li>
<p>Semantic-level perception</p>
</li>
<li>
<p>Social perception (emotion perception)</p>
</li>
<li>
<p>Visuomotor perception, etc.</p>
</li>
</ul>
<h2 id="modern-augmentation-techniques">Modern augmentation techniques<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#modern-augmentation-techniques" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>
<p>identity</p>
</li>
<li>
<p>auto contrast</p>
</li>
<li>
<p>equalize</p>
</li>
<li>
<p>rotate</p>
</li>
<li>
<p>solarize</p>
</li>
<li>
<p>color</p>
</li>
<li>
<p>posterize</p>
</li>
<li>
<p>contrast</p>
</li>
<li>
<p>brightness</p>
</li>
<li>
<p>sharpness</p>
</li>
<li>
<p>shear-x, y</p>
</li>
<li>
<p>translate-x, y</p>
</li>
</ul>
<h2 id="transfer-learning">Transfer learning<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#transfer-learning" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>현실에서는 고품질 혹은 대량의 dataset을 얻기 힘듬</li>
<li>이미 잘 만들어진 dataset으로 잘 만든 model(pre-trained model)을 가져와 활용하는 기술</li>
</ul>
<p><img src="../../resources/Untitled-82.png" width="auto" height="auto" alt="Untitled 82.png"/></p>
<h2 id="knowledge-distillation">Knowledge distillation<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#knowledge-distillation" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Knowledge distillation - Wikipedia </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>In machine learning, knowledge distillation is the process of transferring knowledge from a large model to a smaller one.<br/>
<a href="https://en.wikipedia.org/wiki/Knowledge_distillation" class="external">https://en.wikipedia.org/wiki/Knowledge_distillation<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<p><img src="../../resources/Untitled-1-61.png" width="auto" height="auto" alt="Untitled 1 61.png"/></p>
<ul>
<li>기계학습에서 Knowlkege distillation은 큰 모델에서 작은 모델(일반적으로) 지식을 이전하는 프로세스</li>
<li>모델압축, unlabeled dataset에 대한 pseudo-label(가짜 라벨) 생성에 사용</li>
</ul>
<p><img src="../../resources/Untitled-2-45.png" width="auto" height="auto" alt="Untitled 2 45.png"/></p>
<ul>
<li>
<p>Student Model이 Teacher Model의 결과를 흉내내게(mimic) 함</p>
</li>
</ul>
<h2 id="hard-label-vs-soft-label">Hard Label vs Soft Label<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#hard-label-vs-soft-label" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>
<p>Hard Label : one-hot vector 형태</p>
<ul>
<li>ex <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0</span><span class="mclose">]</span></span></span></span></li>
</ul>
</li>
<li>
<p>Soft Label : softmax 형태</p>
<ul>
<li>
<p>ex <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathnormal">b</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0.14</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0.8</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">0.06</span><span class="mclose">]</span></span></span></span></p>
</li>
</ul>
</li>
</ul>
<h2 id="googlenet">GoogLeNet<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#googlenet" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>
<p>Stacked inception modules</p>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Inception Module <br/>
Log In Sign Up Inception Modules are used in Convolutional Neural Networks to allow for more efficient computation and deeper Networks through a dimensionality reduction with stacked 1×1 convolutions.<br/>
<a href="https://deepai.org/machine-learning-glossary-and-terms/inception-module" class="external">https://deepai.org/machine-learning-glossary-and-terms/inception-module<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p></div>
                  
                </div>
</blockquote>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Inception v1 - 2014 | DataCrew <br/>
니가 뭘 좋아할지 몰라서 다 준비해봤어.<br/>
<a href="http://datacrew.tech/inception-v1-2014/" class="external">http://datacrew.tech/inception-v1-2014/<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p></div>
                  
                </div>
</blockquote>
<p><img src="../../resources/Untitled-3-33.png" width="auto" height="auto" alt="Untitled 3 33.png"/></p>
<ul>
<li>다양한 conv 필터와 pooling을 수행</li>
</ul>
<p><img src="../../resources/Untitled-4-24.png" width="auto" height="auto" alt="Untitled 4 24.png"/></p>
<ul>
<li>하지만 파라미터 수가 너무 많이 필요한 단점이 있음, 이를 1x1 Covolution을 통해 Channel 수를 줄여 해결</li>
</ul>
</li>
<li>
<p>Auxiliary Classifier</p>
<ul>
<li>
<p>Vanishing gradient를 해결하기 위해 도중에 값을 injection</p>
</li>
<li>
<p>낮은 단계에 해당하는 layer에서도 backpropagation되는 gradient signal을 증폭시킴</p>
</li>
</ul>
</li>
</ul>
<h2 id="receptive-field수용필드-수용장">Receptive Field(수용필드, 수용장)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#receptive-field수용필드-수용장" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>What is a receptive field? | CNNs #2 </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://www.youtube.com/watch?v=70A3uYfM1qA" class="external">https://www.youtube.com/watch?v=70A3uYfM1qA<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>A guide to receptive field arithmetic for Convolutional Neural Networks </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>The receptive field is perhaps one of the most important concepts in Convolutional Neural Networks (CNNs) that deserves more attention from the literature.<br/>
<a href="https://blog.mlreview.com/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807" class="external">https://blog.mlreview.com/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Info</p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://www.baeldung.com/cs/cnn-receptive-field-size" class="external">https://www.baeldung.com/cs/cnn-receptive-field-size<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<p><img src="../../resources/Untitled-45.png" width="auto" height="auto" alt="Untitled 45.png"/></p>
<ul>
<li>특정 CNN Feature에 대해서 입력공간이 영향을 받는 크기
<ul>
<li>
<p>ex ) 첫 번째 CNN 계층의 Feature의 입력 공간에 대한 Receptive Field는 3x3이다.</p>
</li>
<li>
<p>ex ) 두 번째 CNN 계층의 Feature의 입력 공간에 대한 Receptive Field는 5x5이다.</p>
</li>
</ul>
</li>
</ul>
<h2 id="resnet">ResNet<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#resnet" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Residual neural network - Wikipedia </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>A residual neural network ( ResNet) is an artificial neural network (ANN).<br/>
<a href="https://en.wikipedia.org/wiki/Residual_neural_network" class="external">https://en.wikipedia.org/wiki/Residual_neural_network<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Info</p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" class="external">https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<p><img src="../../resources/Untitled-5-19.png" width="auto" height="auto" alt="Untitled 5 19.png"/></p>
<ul>
<li>Shortcut connection을 도입하여 기존보다 더 깊게 층을 쌓을 수 있게 됨</li>
<li>직접 구현하기
<ul>
<li>
<p>ConvBlock</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-dark"><code data-language="Python" data-theme="github-dark" style="display:grid;"><span data-line><span>class ConvBlock(nn.Module):</span></span>
<span data-line><span>    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):</span></span>
<span data-line><span>        super().__init__()</span></span>
<span data-line> </span>
<span data-line><span>        #\#fill it##</span></span>
<span data-line><span>        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding) # kernel size = ...</span></span>
<span data-line><span>        self.batchnorm = nn.BatchNorm2d(out_channels)</span></span>
<span data-line> </span>
<span data-line><span>    def forward(self, x):</span></span>
<span data-line><span>        </span></span>
<span data-line><span>        #\#fill it##</span></span>
<span data-line><span>        x = self.conv(x)</span></span>
<span data-line><span>        x = self.batchnorm(x)</span></span>
<span data-line><span>        return x</span></span></code></pre></figure>
</li>
<li>
<p>ResBlock</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-dark"><code data-language="Python" data-theme="github-dark" style="display:grid;"><span data-line><span>class ResBlock(nn.Module):</span></span>
<span data-line><span>    def __init__(self, in_channels, out_channels, pool_stride = 1):</span></span>
<span data-line><span>        super().__init__()</span></span>
<span data-line> </span>
<span data-line><span>        self.kernel_size = 3</span></span>
<span data-line><span>        self.padding = 1</span></span>
<span data-line><span>        self.stride = 1</span></span>
<span data-line><span>        self.relu = nn.ReLU()</span></span>
<span data-line><span>        self.pool_stride = pool_stride</span></span>
<span data-line><span>        self.in_channels = in_channels</span></span>
<span data-line><span>        self.out_channels = out_channels</span></span>
<span data-line><span>        if(in_channels == out_channels):</span></span>
<span data-line><span>          self.skip = torch.nn.Identity()</span></span>
<span data-line><span>        else:</span></span>
<span data-line><span>          self.skip = torch.nn.Conv2d(in_channels=in_channels, </span></span>
<span data-line><span>                               out_channels=out_channels, </span></span>
<span data-line><span>                               kernel_size=1, </span></span>
<span data-line><span>                               stride=self.pool_stride)</span></span>
<span data-line><span>          </span></span>
<span data-line><span>        self.conv1 = ConvBlock(in_channels=in_channels, </span></span>
<span data-line><span>                               out_channels = out_channels, </span></span>
<span data-line><span>                               kernel_size=self.kernel_size, </span></span>
<span data-line><span>                               stride=self.stride, </span></span>
<span data-line><span>                               padding=self.padding)</span></span>
<span data-line><span>        </span></span>
<span data-line><span>        self.conv2 = ConvBlock(in_channels=out_channels, </span></span>
<span data-line><span>                               out_channels = out_channels, </span></span>
<span data-line><span>                               kernel_size=self.kernel_size, </span></span>
<span data-line><span>                               stride=self.pool_stride, </span></span>
<span data-line><span>                               padding=self.padding)</span></span>
<span data-line> </span>
<span data-line><span>    def forward(self, x):</span></span>
<span data-line><span>        </span></span>
<span data-line><span>        #\#fill##</span></span>
<span data-line><span>        y = self.conv1(x)</span></span>
<span data-line><span>        y = self.relu(y)</span></span>
<span data-line><span>        y = self.conv2(y)</span></span>
<span data-line><span>        return  self.relu(y + self.skip(x))</span></span></code></pre></figure>
</li>
<li>
<p>Resnet Model</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-dark"><code data-language="Python" data-theme="github-dark" style="display:grid;"><span data-line><span>class ResNet(nn.Module):</span></span>
<span data-line><span>    def __init__(self, in_channels, out_channels, nker=64, nblk=[3,4,6,3]):</span></span>
<span data-line><span>        super(ResNet, self).__init__()</span></span>
<span data-line> </span>
<span data-line><span>        self.enc = ConvBlock(in_channels, nker, kernel_size=7, stride=2, padding=1)</span></span>
<span data-line><span>        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)</span></span>
<span data-line><span>        self.average_pool = nn.AvgPool2d(kernel_size=5, stride=1)</span></span>
<span data-line> </span>
<span data-line> </span>
<span data-line><span>        #\#fill##</span></span>
<span data-line><span>        self.relu = nn.ReLU()</span></span>
<span data-line><span>        layers = []</span></span>
<span data-line><span>        for j, b in enumerate(nblk):</span></span>
<span data-line><span>          __out_chennel = 64 * (j+1)</span></span>
<span data-line><span>          for i in range(b):</span></span>
<span data-line><span>            if(j != 0 and i == 0):</span></span>
<span data-line><span>              __pool_stride = 2</span></span>
<span data-line><span>              __in_chennel = 64 * j</span></span>
<span data-line> </span>
<span data-line><span>            else:</span></span>
<span data-line><span>              __pool_stride = 1</span></span>
<span data-line><span>              __in_chennel = __out_chennel</span></span>
<span data-line><span>            print(__in_chennel, __out_chennel, __pool_stride)</span></span>
<span data-line><span>            layers.append(ResBlock(__in_chennel, __out_chennel, __pool_stride))</span></span>
<span data-line><span>        print('complete auto layer making')</span></span>
<span data-line><span>        self.conv = nn.Sequential(*layers)</span></span>
<span data-line> </span>
<span data-line><span>        self.fc = nn.Linear(nker*2*2, 10)</span></span>
<span data-line> </span>
<span data-line><span>    def forward(self, x):</span></span>
<span data-line><span>        x = self.enc(x)</span></span>
<span data-line><span>        x = self.max_pool(x)</span></span>
<span data-line> </span>
<span data-line><span>        #\#fill##</span></span>
<span data-line><span>        x = self.conv(x)</span></span>
<span data-line><span>        x = self.average_pool(x)</span></span>
<span data-line><span>        x = x.view(x.shape[0], -1)</span></span>
<span data-line><span>        out = self.fc(x)</span></span>
<span data-line> </span>
<span data-line><span>        return out</span></span></code></pre></figure>
</li>
</ul>
</li>
</ul>
<h2 id="two-stage-detector-vs-one-stage-detector">Two-stage detector vs One-stage detector<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#two-stage-detector-vs-one-stage-detector" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>One stage vs two stage object detection </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>Instead of “region detection + object classification”, its “(1)region proposal + (2)classification and localization in two stage detectors.<br/>
<a href="https://stackoverflow.com/questions/65942471/one-stage-vs-two-stage-object-detection" class="external">https://stackoverflow.com/questions/65942471/one-stage-vs-two-stage-object-detection<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<p><img src="../../resources/Untitled-54.png" width="auto" height="auto" alt="Untitled 54.png"/></p>
<ul>
<li>Object detection 시, ROI Search와 ROI 내 Image Classification을 별도로 수행하면 Two-stage detector, 한번에 수행한다면 One-stage detector
<ul>
<li>속도 : Two Stage detector &lt; One-stage detector(better)</li>
<li>정확도 : Two Stage detector(better) &lt; One-stage detector</li>
</ul>
</li>
<li>Traditional Methods
<ul>
<li>Raw Image Segmentation → 유사 영역 Merge → 후보 영역(Candidate box) 추출</li>
</ul>
</li>
<li>Two-stage detector
<ul>
<li>
<p>R-CNN</p>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Info</p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://arxiv.org/pdf/1311.2524.pdf" class="external">https://arxiv.org/pdf/1311.2524.pdf<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
</li>
<li>
<p>Fast RCNN</p>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Info</p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf" class="external">https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
</li>
<li>
<p>Faster RCNN</p>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Info</p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://arxiv.org/pdf/1506.01497.pdf" class="external">https://arxiv.org/pdf/1506.01497.pdf<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
</li>
</ul>
</li>
<li>One-stage detector
<ul>
<li>
<p>YOLO</p>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Info</p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf" class="external">https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
</li>
<li>
<p>SSD</p>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Info</p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://arxiv.org/pdf/1512.02325.pdf" class="external">https://arxiv.org/pdf/1512.02325.pdf<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
</li>
<li>
<p>RetinaNet</p>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Info</p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://arxiv.org/pdf/1708.02002.pdf" class="external">https://arxiv.org/pdf/1708.02002.pdf<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
</li>
</ul>
</li>
<li>etc. Detection with Transformer
<ul>
<li>
<p>DETR</p>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Info</p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://arxiv.org/pdf/2005.12872.pdf" class="external">https://arxiv.org/pdf/2005.12872.pdf<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="analysis-of-model-behaviors">Analysis of model behaviors<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#analysis-of-model-behaviors" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<ul>
<li>
<p>Embedding feature analysis</p>
<p><img src="../../resources/Untitled-38.png" width="auto" height="auto" alt="Untitled 38.png"/></p>
<ul>
<li>Dataset들에 대한 Model의 고차원 high level feature vector를 수집(모델의 뒷부분, High level feature)</li>
<li>알고싶은 이미지도 마찬가지로 inferrence 시켜서 high level feature vector를 수집</li>
<li>feature vector들끼리의 유사성으로 해당 이미지와 유사한 high level feature vector를 Dataset 내의 이미지들을 얻을 수 있음</li>
</ul>
<p><img src="../../resources/Untitled-1-32.png" width="auto" height="auto" alt="Untitled 1 32.png"/></p>
</li>
<li>
<p>t-SNE(t-distributed stochastic neighbor embedding)</p>
<ul>
<li>고차원 백터를 저차원으로 표현할 수 있는 방법</li>
</ul>
<p><img src="../../resources/Untitled-2-19.png" width="auto" height="auto" alt="Untitled 2 19.png"/></p>
</li>
<li>
<p>CAM(Class activation mapping)</p>
<ul>
<li>
<p>Conv블록의 뒤에 3ch conv블록 생성, class에 대한 weighted sum</p>
</li>
<li>
<p>hitmap 느낌으로 모델이 인지한 부분을 볼 수 있음</p>
<p><img src="../../resources/Untitled-3-17.png" width="auto" height="auto" alt="Untitled 3 17.png"/></p>
</li>
<li>
<p>모델이 처음부터 저 모양이라면 바로 쓸 수 있지만, 그렇지 않은 경우(FC layer 등이 있는 경우) 해당 부분을 제거하고 새롭게 추가한 신경망을 (GAP Layer + FC Layer)을 다시 훈련시켜야 함</p>
</li>
</ul>
</li>
<li>
<p>Grad-CAM</p>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Info</p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://arxiv.org/pdf/1610.02391.pdf" class="external">https://arxiv.org/pdf/1610.02391.pdf<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<blockquote class="callout info" data-callout="info" data-callout-metadata="] [논문리뷰">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Grad-CAM - 새내기 코드 여행 <br/>
인공지능은 이미 거의 모든 분야에서 다양한 용도로 사용되고 있습니다.<br/>
<a href="https://joungheekim.github.io/2020/10/14/paper-review/" class="external">https://joungheekim.github.io/2020/10/14/paper-review/<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p></div>
                  
                </div>
</blockquote>
<p><img src="../../resources/Untitled-4-12.png" width="auto" height="auto" alt="Untitled 4 12.png"/></p>
<ul>
<li>CAM을 일반화 한 방법</li>
</ul>
</li>
</ul></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div class="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false,&quot;enableRadial&quot;:false}"></div><button class="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div class="global-graph-outer"><div class="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.2,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true,&quot;enableRadial&quot;:true}"></div></div></div><div class="toc desktop-only"><button type="button" class="toc-header" aria-controls="toc-content" aria-expanded="true"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><ul class="toc-content overflow" id="list-1"><li class="depth-0"><a href="#class-of-visual-perception" data-for="class-of-visual-perception">Class of visual perception</a></li><li class="depth-0"><a href="#modern-augmentation-techniques" data-for="modern-augmentation-techniques">Modern augmentation techniques</a></li><li class="depth-0"><a href="#transfer-learning" data-for="transfer-learning">Transfer learning</a></li><li class="depth-0"><a href="#knowledge-distillation" data-for="knowledge-distillation">Knowledge distillation</a></li><li class="depth-0"><a href="#hard-label-vs-soft-label" data-for="hard-label-vs-soft-label">Hard Label vs Soft Label</a></li><li class="depth-0"><a href="#googlenet" data-for="googlenet">GoogLeNet</a></li><li class="depth-0"><a href="#receptive-field수용필드-수용장" data-for="receptive-field수용필드-수용장">Receptive Field(수용필드, 수용장)</a></li><li class="depth-0"><a href="#resnet" data-for="resnet">ResNet</a></li><li class="depth-0"><a href="#two-stage-detector-vs-one-stage-detector" data-for="two-stage-detector-vs-one-stage-detector">Two-stage detector vs One-stage detector</a></li><li class="depth-0"><a href="#analysis-of-model-behaviors" data-for="analysis-of-model-behaviors">Analysis of model behaviors</a></li><li class="overflow-end"></li></ul></div><div class="backlinks"><h3>Backlinks</h3><ul id="list-2" class="overflow"><li><a href="../../Knowledge/Machine-Learning(WIP)/Analysis-of-model-behaviors" class="internal">Analysis of model behaviors</a></li><li><a href="../../Knowledge/Machine-Learning(WIP)/GoogLeNet(Inception-v1)" class="internal">GoogLeNet(Inception v1)</a></li><li><a href="../../Knowledge/Machine-Learning(WIP)/Knowledge-distillation" class="internal">Knowledge distillation</a></li><li><a href="../../Knowledge/Machine-Learning(WIP)/Receptive-Field(수용필드,-수용장)" class="internal">Receptive Field(수용필드, 수용장)</a></li><li><a href="../../Knowledge/Machine-Learning(WIP)/ResNet" class="internal">ResNet</a></li><li><a href="../../Knowledge/Machine-Learning(WIP)/Transfer-Learning" class="internal">Transfer Learning</a></li><li><a href="../../Knowledge/Machine-Learning(WIP)/Two-stage-detector-vs-One-stage-detector" class="internal">Two-stage detector vs One-stage detector</a></li><li><a href="../../Personal/Naver-Connect---Boostcamp-AI-Tech-4기/Naver-Connect---Boostcamp-AI-Tech-4기" class="internal">Naver Connect - Boostcamp AI Tech 4기</a></li><li class="overflow-end"></li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.5.1</a> © 2025</p><ul><li><a href="https://github.com/404Vector">GitHub</a></li></ul></footer></div></div></body><script type="application/javascript">function n(){let t=this.parentElement;t.classList.toggle("is-collapsed");let e=t.getElementsByClassName("callout-content")[0];if(!e)return;let l=t.classList.contains("is-collapsed");e.style.gridTemplateRows=l?"0fr":"1fr"}function c(){let t=document.getElementsByClassName("callout is-collapsible");for(let e of t){let l=e.getElementsByClassName("callout-title")[0],s=e.getElementsByClassName("callout-content")[0];if(!l||!s)continue;l.addEventListener("click",n),window.addCleanup(()=>l.removeEventListener("click",n));let o=e.classList.contains("is-collapsed");s.style.gridTemplateRows=o?"0fr":"1fr"}}document.addEventListener("nav",c);
</script><script type="module">function f(i,e){if(!i)return;function r(o){o.target===this&&(o.preventDefault(),o.stopPropagation(),e())}function t(o){o.key.startsWith("Esc")&&(o.preventDefault(),e())}i?.addEventListener("click",r),window.addCleanup(()=>i?.removeEventListener("click",r)),document.addEventListener("keydown",t),window.addCleanup(()=>document.removeEventListener("keydown",t))}function y(i){for(;i.firstChild;)i.removeChild(i.firstChild)}var h=class{constructor(e,r){this.container=e;this.content=r;this.setupEventListeners(),this.setupNavigationControls(),this.resetTransform()}isDragging=!1;startPan={x:0,y:0};currentPan={x:0,y:0};scale=1;MIN_SCALE=.5;MAX_SCALE=3;cleanups=[];setupEventListeners(){let e=this.onMouseDown.bind(this),r=this.onMouseMove.bind(this),t=this.onMouseUp.bind(this),o=this.resetTransform.bind(this);this.container.addEventListener("mousedown",e),document.addEventListener("mousemove",r),document.addEventListener("mouseup",t),window.addEventListener("resize",o),this.cleanups.push(()=>this.container.removeEventListener("mousedown",e),()=>document.removeEventListener("mousemove",r),()=>document.removeEventListener("mouseup",t),()=>window.removeEventListener("resize",o))}cleanup(){for(let e of this.cleanups)e()}setupNavigationControls(){let e=document.createElement("div");e.className="mermaid-controls";let r=this.createButton("+",()=>this.zoom(.1)),t=this.createButton("-",()=>this.zoom(-.1)),o=this.createButton("Reset",()=>this.resetTransform());e.appendChild(t),e.appendChild(o),e.appendChild(r),this.container.appendChild(e)}createButton(e,r){let t=document.createElement("button");return t.textContent=e,t.className="mermaid-control-button",t.addEventListener("click",r),window.addCleanup(()=>t.removeEventListener("click",r)),t}onMouseDown(e){e.button===0&&(this.isDragging=!0,this.startPan={x:e.clientX-this.currentPan.x,y:e.clientY-this.currentPan.y},this.container.style.cursor="grabbing")}onMouseMove(e){this.isDragging&&(e.preventDefault(),this.currentPan={x:e.clientX-this.startPan.x,y:e.clientY-this.startPan.y},this.updateTransform())}onMouseUp(){this.isDragging=!1,this.container.style.cursor="grab"}zoom(e){let r=Math.min(Math.max(this.scale+e,this.MIN_SCALE),this.MAX_SCALE),t=this.content.getBoundingClientRect(),o=t.width/2,n=t.height/2,c=r-this.scale;this.currentPan.x-=o*c,this.currentPan.y-=n*c,this.scale=r,this.updateTransform()}updateTransform(){this.content.style.transform=`translate(${this.currentPan.x}px, ${this.currentPan.y}px) scale(${this.scale})`}resetTransform(){this.scale=1;let e=this.content.querySelector("svg");this.currentPan={x:e.getBoundingClientRect().width/2,y:e.getBoundingClientRect().height/2},this.updateTransform()}},C=["--secondary","--tertiary","--gray","--light","--lightgray","--highlight","--dark","--darkgray","--codeFont"],E;document.addEventListener("nav",async()=>{let e=document.querySelector(".center").querySelectorAll("code.mermaid");if(e.length===0)return;E||=await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.esm.min.mjs");let r=E.default,t=new WeakMap;for(let n of e)t.set(n,n.innerText);async function o(){for(let s of e){s.removeAttribute("data-processed");let a=t.get(s);a&&(s.innerHTML=a)}let n=C.reduce((s,a)=>(s[a]=window.getComputedStyle(document.documentElement).getPropertyValue(a),s),{}),c=document.documentElement.getAttribute("saved-theme")==="dark";r.initialize({startOnLoad:!1,securityLevel:"loose",theme:c?"dark":"base",themeVariables:{fontFamily:n["--codeFont"],primaryColor:n["--light"],primaryTextColor:n["--darkgray"],primaryBorderColor:n["--tertiary"],lineColor:n["--darkgray"],secondaryColor:n["--secondary"],tertiaryColor:n["--tertiary"],clusterBkg:n["--light"],edgeLabelBackground:n["--highlight"]}}),await r.run({nodes:e})}await o(),document.addEventListener("themechange",o),window.addCleanup(()=>document.removeEventListener("themechange",o));for(let n=0;n<e.length;n++){let v=function(){let g=l.querySelector("#mermaid-space"),m=l.querySelector(".mermaid-content");if(!m)return;y(m);let w=c.querySelector("svg").cloneNode(!0);m.appendChild(w),l.classList.add("active"),g.style.cursor="grab",u=new h(g,m)},M=function(){l.classList.remove("active"),u?.cleanup(),u=null},c=e[n],s=c.parentElement,a=s.querySelector(".clipboard-button"),d=s.querySelector(".expand-button"),p=window.getComputedStyle(a),L=a.offsetWidth+parseFloat(p.marginLeft||"0")+parseFloat(p.marginRight||"0");d.style.right=`calc(${L}px + 0.3rem)`,s.prepend(d);let l=s.querySelector("#mermaid-container");if(!l)return;let u=null;d.addEventListener("click",v),f(l,M),window.addCleanup(()=>{u?.cleanup(),d.removeEventListener("click",v)})}});
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="../../postscript.js" type="module"></script></html>