<!DOCTYPE html>
<html lang="en"><head><title>Week 10</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;family=IBM Plex Mono:wght@400;600&amp;display=swap"/><link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin="anonymous"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="HyeongSeok Kim's Vault"/><meta property="og:title" content="Week 10"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Week 10"/><meta name="twitter:description" content="Object Detection Library Overview MMDetection Two-Stage Detector의 Pipeline MMDetection 2Stage Model Pipeline Detectron2 PipeLine Neck Overview Neck은 무엇인가? 2-Stage Pipline 왜 마지막 feature map 만을 사용해야하는가? FPN(Feature Pyramid Network) Pipeline Stage Mapping PANet(Path Aggregation Network) FPN의 단점 Adapti..."/><meta property="og:description" content="Object Detection Library Overview MMDetection Two-Stage Detector의 Pipeline MMDetection 2Stage Model Pipeline Detectron2 PipeLine Neck Overview Neck은 무엇인가? 2-Stage Pipline 왜 마지막 feature map 만을 사용해야하는가? FPN(Feature Pyramid Network) Pipeline Stage Mapping PANet(Path Aggregation Network) FPN의 단점 Adapti..."/><meta property="og:image:alt" content="Object Detection Library Overview MMDetection Two-Stage Detector의 Pipeline MMDetection 2Stage Model Pipeline Detectron2 PipeLine Neck Overview Neck은 무엇인가? 2-Stage Pipline 왜 마지막 feature map 만을 사용해야하는가? FPN(Feature Pyramid Network) Pipeline Stage Mapping PANet(Path Aggregation Network) FPN의 단점 Adapti..."/><meta property="twitter:domain" content="quartz.jzhao.xyz"/><meta property="og:url" content="https://quartz.jzhao.xyz/vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/Week-10/Week-10"/><meta property="twitter:url" content="https://quartz.jzhao.xyz/vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/Week-10/Week-10"/><link rel="icon" href="../../../../../../static/icon.png"/><meta name="description" content="Object Detection Library Overview MMDetection Two-Stage Detector의 Pipeline MMDetection 2Stage Model Pipeline Detectron2 PipeLine Neck Overview Neck은 무엇인가? 2-Stage Pipline 왜 마지막 feature map 만을 사용해야하는가? FPN(Feature Pyramid Network) Pipeline Stage Mapping PANet(Path Aggregation Network) FPN의 단점 Adapti..."/><meta name="generator" content="Quartz"/><link href="../../../../../../index.css" rel="stylesheet" type="text/css" spa-preserve/><style>.expand-button {
  position: absolute;
  display: flex;
  float: right;
  padding: 0.4rem;
  margin: 0.3rem;
  right: 0;
  color: var(--gray);
  border-color: var(--dark);
  background-color: var(--light);
  border: 1px solid;
  border-radius: 5px;
  opacity: 0;
  transition: 0.2s;
}
.expand-button > svg {
  fill: var(--light);
  filter: contrast(0.3);
}
.expand-button:hover {
  cursor: pointer;
  border-color: var(--secondary);
}
.expand-button:focus {
  outline: 0;
}

pre:hover > .expand-button {
  opacity: 1;
  transition: 0.2s;
}

#mermaid-container {
  position: fixed;
  contain: layout;
  z-index: 999;
  left: 0;
  top: 0;
  width: 100vw;
  height: 100vh;
  overflow: hidden;
  display: none;
  backdrop-filter: blur(4px);
  background: rgba(0, 0, 0, 0.5);
}
#mermaid-container.active {
  display: inline-block;
}
#mermaid-container > #mermaid-space {
  border: 1px solid var(--lightgray);
  background-color: var(--light);
  border-radius: 5px;
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  height: 80vh;
  width: 80vw;
  overflow: hidden;
}
#mermaid-container > #mermaid-space > .mermaid-content {
  padding: 2rem;
  position: relative;
  transform-origin: 0 0;
  transition: transform 0.1s ease;
  overflow: visible;
  min-height: 200px;
  min-width: 200px;
}
#mermaid-container > #mermaid-space > .mermaid-content pre {
  margin: 0;
  border: none;
}
#mermaid-container > #mermaid-space > .mermaid-content svg {
  max-width: none;
  height: auto;
}
#mermaid-container > #mermaid-space > .mermaid-controls {
  position: absolute;
  bottom: 20px;
  right: 20px;
  display: flex;
  gap: 8px;
  padding: 8px;
  background: var(--light);
  border: 1px solid var(--lightgray);
  border-radius: 6px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  z-index: 2;
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 32px;
  height: 32px;
  padding: 0;
  border: 1px solid var(--lightgray);
  background: var(--light);
  color: var(--dark);
  border-radius: 4px;
  cursor: pointer;
  font-size: 16px;
  font-family: var(--bodyFont);
  transition: all 0.2s ease;
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:hover {
  background: var(--lightgray);
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:active {
  transform: translateY(1px);
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:nth-child(2) {
  width: auto;
  padding: 0 12px;
  font-size: 14px;
}
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,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 */</style><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../../../../../../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../../../../../../static/contentIndex.json").then(data => data.json())</script><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="https://quartz.jzhao.xyz/index.xml"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image" content="https://quartz.jzhao.xyz/vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/Week-10/Week-10-og-image.webp"/><meta property="og:image:url" content="https://quartz.jzhao.xyz/vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/Week-10/Week-10-og-image.webp"/><meta name="twitter:image" content="https://quartz.jzhao.xyz/vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/Week-10/Week-10-og-image.webp"/><meta property="og:image:type" content="image/.webp"/></head><body data-slug="vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/Week-10/Week-10"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href="../../../../../..">HyeongSeok Kim's Vault</a></h2><div class="spacer mobile-only"></div><div class="flex-component" style="flex-direction: row; flex-wrap: nowrap; gap: 1rem;"><div style="flex-grow: 1; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><div class="search"><button class="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div class="search-container"><div class="search-space"><input autocomplete="off" class="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div class="search-layout" data-preview="true"></div></div></div></div></div><div style="flex-grow: 0; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><button class="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div style="flex-grow: 0; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><button class="readermode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="readerIcon" fill="currentColor" stroke="currentColor" stroke-width="0.2" stroke-linecap="round" stroke-linejoin="round" width="64px" height="64px" viewBox="0 0 24 24" aria-label="Reader mode"><title>Reader mode</title><g transform="translate(-1.8, -1.8) scale(1.15, 1.2)"><path d="M8.9891247,2.5 C10.1384702,2.5 11.2209868,2.96705384 12.0049645,3.76669482 C12.7883914,2.96705384 13.8709081,2.5 15.0202536,2.5 L18.7549359,2.5 C19.1691495,2.5 19.5049359,2.83578644 19.5049359,3.25 L19.5046891,4.004 L21.2546891,4.00457396 C21.6343849,4.00457396 21.9481801,4.28672784 21.9978425,4.6528034 L22.0046891,4.75457396 L22.0046891,20.25 C22.0046891,20.6296958 21.7225353,20.943491 21.3564597,20.9931534 L21.2546891,21 L2.75468914,21 C2.37499337,21 2.06119817,20.7178461 2.01153575,20.3517706 L2.00468914,20.25 L2.00468914,4.75457396 C2.00468914,4.37487819 2.28684302,4.061083 2.65291858,4.01142057 L2.75468914,4.00457396 L4.50368914,4.004 L4.50444233,3.25 C4.50444233,2.87030423 4.78659621,2.55650904 5.15267177,2.50684662 L5.25444233,2.5 L8.9891247,2.5 Z M4.50368914,5.504 L3.50468914,5.504 L3.50468914,19.5 L10.9478955,19.4998273 C10.4513189,18.9207296 9.73864328,18.5588115 8.96709342,18.5065584 L8.77307039,18.5 L5.25444233,18.5 C4.87474657,18.5 4.56095137,18.2178461 4.51128895,17.8517706 L4.50444233,17.75 L4.50368914,5.504 Z M19.5049359,17.75 C19.5049359,18.1642136 19.1691495,18.5 18.7549359,18.5 L15.2363079,18.5 C14.3910149,18.5 13.5994408,18.8724714 13.0614828,19.4998273 L20.5046891,19.5 L20.5046891,5.504 L19.5046891,5.504 L19.5049359,17.75 Z M18.0059359,3.999 L15.0202536,4 L14.8259077,4.00692283 C13.9889509,4.06666544 13.2254227,4.50975805 12.7549359,5.212 L12.7549359,17.777 L12.7782651,17.7601316 C13.4923805,17.2719483 14.3447024,17 15.2363079,17 L18.0059359,16.999 L18.0056891,4.798 L18.0033792,4.75457396 L18.0056891,4.71 L18.0059359,3.999 Z M8.9891247,4 L6.00368914,3.999 L6.00599909,4.75457396 L6.00599909,4.75457396 L6.00368914,4.783 L6.00368914,16.999 L8.77307039,17 C9.57551536,17 10.3461406,17.2202781 11.0128313,17.6202194 L11.2536891,17.776 L11.2536891,5.211 C10.8200889,4.56369974 10.1361548,4.13636104 9.37521067,4.02745763 L9.18347055,4.00692283 L8.9891247,4 Z"></path></g></svg></button></div></div><div class="explorer" data-behavior="link" data-collapsed="collapsed" data-savestate="true" data-data-fns="{&quot;order&quot;:[&quot;filter&quot;,&quot;map&quot;,&quot;sort&quot;],&quot;sortFn&quot;:&quot;(a,b)=>!a.isFolder&amp;&amp;!b.isFolder||a.isFolder&amp;&amp;b.isFolder?a.displayName.localeCompare(b.displayName,void 0,{numeric:!0,sensitivity:\&quot;base\&quot;}):!a.isFolder&amp;&amp;b.isFolder?1:-1&quot;,&quot;filterFn&quot;:&quot;node=>node.slugSegment!==\&quot;tags\&quot;&quot;,&quot;mapFn&quot;:&quot;node=>node&quot;}"><button type="button" class="explorer-toggle mobile-explorer hide-until-loaded" data-mobile="true" aria-controls="explorer-content"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-menu"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg></button><button type="button" class="title-button explorer-toggle desktop-explorer" data-mobile="false" aria-expanded="true"><h2>Explorer</h2><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div class="explorer-content" aria-expanded="false"><ul class="explorer-ul overflow" id="list-0"><li class="overflow-end"></li></ul></div><template id="template-file"><li><a href="#"></a></li></template><template id="template-folder"><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div><button class="folder-button"><span class="folder-title"></span></button></div></div><div class="folder-outer"><ul class="content"></ul></div></li></template></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../../../../../../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../../../vault/">Main</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../../../vault/Notion/">Notion</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../../../vault/Notion/DB/">DB</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/">DB Blog Post</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/">Naver Connect   Boostcamp AI Tech 4기</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/Week-10/">Week 10</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Week 10</a></div></nav><h1 class="article-title">Week 10</h1><p show-comma="true" class="content-meta"><time datetime="2025-06-16T10:23:10.354Z">Jun 16, 2025</time><span>18 min read</span></p><ul class="tags"><li><a href="../../../../../../tags/class" class="internal tag-link">class</a></li></ul></div></div><article class="popover-hint"><ul>
<li><a href="#object-detection-library" class="internal alias">Object Detection Library</a>
<ul>
<li><a href="#overview" class="internal alias">Overview</a></li>
<li><a href="#mmdetection" class="internal alias">MMDetection</a>
<ul>
<li><a href="#two-stage-detector%EC%9D%98-pipeline" class="internal alias">Two-Stage Detector의 Pipeline</a></li>
<li><a href="#mmdetection-2stage-model-pipeline" class="internal alias">MMDetection 2Stage Model Pipeline</a></li>
</ul>
</li>
<li><a href="#detectron2" class="internal alias">Detectron2</a>
<ul>
<li><a href="#pipeline" class="internal alias">PipeLine</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#neck" class="internal alias">Neck</a>
<ul>
<li><a href="#overview" class="internal alias">Overview</a>
<ul>
<li><a href="#neck%EC%9D%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80" class="internal alias">Neck은 무엇인가?</a></li>
<li><a href="#2-stage-pipline" class="internal alias">2-Stage Pipline</a></li>
<li><a href="#%EC%99%9C-%EB%A7%88%EC%A7%80%EB%A7%89-feature-map-%EB%A7%8C%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%B4%EC%95%BC%ED%95%98%EB%8A%94%EA%B0%80" class="internal alias">왜 마지막 feature map 만을 사용해야하는가?</a></li>
</ul>
</li>
<li><a href="#fpnfeature-pyramid-network" class="internal alias">FPN(Feature Pyramid Network)</a>
<ul>
<li><a href="#pipeline" class="internal alias">Pipeline</a></li>
<li><a href="#stage-mapping" class="internal alias">Stage Mapping</a></li>
</ul>
</li>
<li><a href="#panetpath-aggregation-network" class="internal alias">PANet(Path Aggregation Network)</a>
<ul>
<li><a href="#fpn%EC%9D%98-%EB%8B%A8%EC%A0%90" class="internal alias">FPN의 단점</a></li>
<li><a href="#adaptive-feature-pooling" class="internal alias">Adaptive Feature Pooling</a></li>
</ul>
</li>
<li><a href="#detectrors" class="internal alias">DetectroRS</a>
<ul>
<li><a href="#motivation" class="internal alias">Motivation</a></li>
<li><a href="#rfprecursive-feature-pyramid" class="internal alias">RFP(Recursive Feature Pyramid)</a></li>
<li><a href="#atrous-convolutionor-dilated-convolution" class="internal alias">Atrous Convolution(or dilated convolution)</a></li>
<li><a href="#asppatrous-spatial-pyramid-pooling" class="internal alias">ASPP(Atrous Spatial Pyramid Pooling)</a></li>
</ul>
</li>
<li><a href="#bifpnefficientdet" class="internal alias">BiFPN(EfficientDet)</a>
<ul>
<li><a href="#weighted-featrue-fusion" class="internal alias">Weighted Featrue Fusion</a></li>
</ul>
</li>
<li><a href="#nasfpn" class="internal alias">NasFPN</a></li>
<li><a href="#augfpn" class="internal alias">AugFPN</a>
<ul>
<li><a href="#%EA%B8%B0%EC%A1%B4-fpn%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%A0%90" class="internal alias">기존 FPN의 문제점</a></li>
<li><a href="#residual-featrue-augmenmtation" class="internal alias">Residual Featrue Augmenmtation</a></li>
<li><a href="#soft-roi-selection" class="internal alias">Soft ROI Selection</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#1-stage-detectors" class="internal alias">1 Stage Detectors</a>
<ul>
<li><a href="#background--history" class="internal alias">Background &amp; History</a>
<ul>
<li><a href="#2-stage-detector" class="internal alias">2 Stage Detector</a></li>
<li><a href="#1-stage-detector" class="internal alias">1 Stage Detector</a></li>
<li><a href="#history" class="internal alias">History</a></li>
</ul>
</li>
<li><a href="#yolo-v1you-only-look-once" class="internal alias">Yolo v1(You Only Look Once)</a>
<ul>
<li><a href="#history" class="internal alias">History</a></li>
<li><a href="#pipeline" class="internal alias">Pipeline</a></li>
<li><a href="#network-architecture" class="internal alias">Network Architecture</a></li>
<li><a href="#pipeline" class="internal alias">Pipeline</a></li>
<li><a href="#loss" class="internal alias">Loss</a></li>
<li><a href="#%EC%9E%A5%EC%A0%90" class="internal alias">장점</a></li>
<li><a href="#%EB%8B%A8%EC%A0%90" class="internal alias">단점</a></li>
</ul>
</li>
<li><a href="#ssd" class="internal alias">SSD</a>
<ul>
<li><a href="#yolo-vs-ssd" class="internal alias">Yolo vs SSD</a></li>
<li><a href="#pipeline" class="internal alias">Pipeline</a></li>
<li><a href="#training" class="internal alias">Training</a></li>
<li><a href="#loss" class="internal alias">Loss</a></li>
</ul>
</li>
<li><a href="#yolo-follow-up" class="internal alias">YOLO Follow-up</a>
<ul>
<li><a href="#yolo-v2" class="internal alias">Yolo v2</a></li>
<li><a href="#yolo-v3" class="internal alias">Yolo v3</a></li>
</ul>
</li>
<li><a href="#retinanet" class="internal alias">RetinaNet</a>
<ul>
<li><a href="#1-stage-detector%EC%9D%98-%EA%B3%A0%EC%A7%88%EC%A0%81-%EB%AC%B8%EC%A0%9C" class="internal alias">1 Stage Detector의 고질적 문제</a></li>
<li><a href="#concept" class="internal alias">Concept</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#efficientdet" class="internal alias">EfficientDet</a>
<ul>
<li><a href="#efficientnet" class="internal alias">EfficientNet</a>
<ul>
<li><a href="#%EB%93%B1%EC%9E%A5%EB%B0%B0%EA%B2%BD" class="internal alias">등장배경</a></li>
<li><a href="#model-scaling" class="internal alias">Model Scaling</a></li>
<li><a href="#better-accuracy--efficiency" class="internal alias">Better Accuracy &amp; Efficiency</a></li>
</ul>
</li>
<li><a href="#efficientdet" class="internal alias">EfficientDet</a>
<ul>
<li><a href="#motivation" class="internal alias">Motivation</a></li>
<li><a href="#%EA%B8%B0%EC%A1%B4-detection-model%EB%93%A4%EC%9D%98-%EB%AC%B8%EC%A0%9C%EC%99%80-%ED%95%B4%EA%B2%B0%EB%B0%A9%EB%B2%95" class="internal alias">기존 Detection Model들의 문제와 해결방법</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<hr/>
<h1 id="object-detection-library">Object Detection Library<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#object-detection-library" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<h2 id="overview">Overview<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#overview" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>




















<div class="table-container"><table><thead><tr><th></th><th>MMDetection</th><th>Detectron2</th></tr></thead><tbody><tr><td>특징</td><td>- 전체 프레임워크를 모듈 단위로 분리해 관리할 수 있음  <br/>- 많은 프레임워크를 지원함  <br/>- 다른 라이브러리에 비해 빠름</td><td>- 전체 프레임워크를 모듈 단위로 분리해 관리할 수 있음  <br/>- OD 외에도 Segmentation, Pose Prediction 등의 알고리즘을 지원함</td></tr><tr><td>지원 모델</td><td>- Fast R-CNN  <br/>- SSD  <br/>- YOLO v3  <br/>- DETR  <br/>..etc</td><td>- Faster R-CNN  <br/>- RetinaNet  <br/>- Mask R-CNN  <br/>- DETR  <br/>..etc</td></tr></tbody></table></div>
<h2 id="mmdetection">MMDetection<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#mmdetection" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Pytorch 기반의 Object Detection 오픈소스 라이브러리</p>
<p>일정 수준의 코딩실력이 된다면 쉽게 사용 가능</p>
<p>커스터마이징 어려움</p>
<h3 id="two-stage-detector의-pipeline">Two-Stage Detector의 Pipeline<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#two-stage-detector의-pipeline" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Input→Backbone→Neck(일종의 Feature Map)→Dense Prediction→Prediction</p>
<h3 id="mmdetection-2stage-model-pipeline">MMDetection 2Stage Model Pipeline<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#mmdetection-2stage-model-pipeline" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>➡️ Backbone➡️Neck➡️—————➡️ROI Head<br/>
↘️ ↗️<br/>
DenseHead</p>
<ul>
<li>
<p>Backbone : 이미지를 Feature Map으로 변형</p>
</li>
<li>
<p>Neck : Backbone과 Head를 연결, Feature Map을 재구성(ex. FPN)</p>
</li>
<li>
<p>Dense head : Feature Map의 dense location을 수행</p>
</li>
<li>
<p>ROI Head : ROI의 Feature를 받아 box classification, 좌표 회귀 등을 예측</p>
</li>
</ul>
<h2 id="detectron2">Detectron2<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#detectron2" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Facebook AI Research의 Pythorch 기반 라이브러리</p>
<p>Object detection, segmentation, pose prediction 등 알고리즘 제공</p>
<h3 id="pipeline">PipeLine<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pipeline" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>Setup Config</li>
<li>Setup Trainer</li>
<li>Satrt Training</li>
</ul>
<hr/>
<h1 id="neck">Neck<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#neck" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<h2 id="overview-1">Overview<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#overview-1" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Info</p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://arxiv.org/pdf/1905.05055.pdf" class="external">https://arxiv.org/pdf/1905.05055.pdf<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<p><img src="../../../../../../vault/resources/Untitled-76.png" width="auto" height="auto" alt="Untitled 76.png"/></p>
<h3 id="neck은-무엇인가">Neck은 무엇인가?<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#neck은-무엇인가" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Object Detection에서 말하는 Backbone, Neck, Head </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>Backbone, neck, head는 무엇을 의미하는 걸까?<br/>
<a href="https://velog.io/@peterkim/Object-Detection%EC%97%90%EC%84%9C-%EB%A7%90%ED%95%98%EB%8A%94-Backbone-Neck-Head" class="external">https://velog.io/@peterkim/Object-Detection%EC%97%90%EC%84%9C-%EB%A7%90%ED%95%98%EB%8A%94-Backbone-Neck-Head<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<h3 id="2-stage-pipline">2-Stage Pipline<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#2-stage-pipline" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>Input → Backbone → RPN→ Prediction</li>
</ul>
<p>기존에는 Backbone에서 마지막 Feature Map을 사용해왔음</p>
<h3 id="왜-마지막-feature-map-만을-사용해야하는가">왜 마지막 feature map 만을 사용해야하는가?<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#왜-마지막-feature-map-만을-사용해야하는가" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>연구를 통해 중간 과정의 Feature map들도 사용할 수 있겠다는 결론</li>
<li>중간단계의 Feature map들도 활용 시작</li>
<li>크기 별로 feaute를 추출하기 때문에 검출에 유리</li>
<li>다양한 크기의 객체를 더 잘 탐지하기 위해 필요</li>
</ul>
<p>Low Level의 Feature는 Semantic 정보가 약하고, Local한 정보가 강함</p>
<p>High Level의 Feature는 Semantic 정보는 강하나 Local한 정보가 약함</p>
<ul>
<li>
<p>서로간의 Feuatre 교환 필요</p>
</li>
</ul>
<p><img src="../../../../../../vault/resources/Untitled-48.png" width="auto" height="auto" alt="Untitled 48.png"/></p>
<p><img src="../../../../../../vault/resources/Untitled-1-57.png" width="auto" height="auto" alt="Untitled 1 57.png"/></p>
<h2 id="fpnfeature-pyramid-network">FPN(Feature Pyramid Network)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#fpnfeature-pyramid-network" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Understanding Feature Pyramid Networks for object detection (FPN) </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>Detecting objects in different scales is challenging in particular for small objects.<br/>
<a href="https://jonathan-hui.medium.com/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c" class="external">https://jonathan-hui.medium.com/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<p><img src="../../../../../../vault/resources/Untitled.png" width="auto" height="auto" alt/></p>
<p>High Level에서 Low Level로 Semantic 정보 전달 필요</p>
<p>Pyramid 구조를 통해 High level 정보를 low level에 순차적으로 전달</p>
<p>용어</p>
<ul>
<li>Low level = Early stage = bottome</li>
<li>High level = Late Stage = Top</li>
</ul>
<p><img src="../../../../../../vault/resources/Untitled-1.png" width="auto" height="auto" alt/></p>
<h3 id="pipeline-1">Pipeline<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pipeline-1" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>Bottom-Up
<ul>
<li>image ~~ High Level까지 feature 전달됨, 일발적인 CNN Backbone 통과 과정을 의미</li>
</ul>
</li>
<li>Top-Down
<ul>
<li>High Level ~~ Low Level까지 feature 전달</li>
<li>Dimm이 맞지 않음
<ul>
<li>
<p>Top-Down Path : Up Convolution 진행(h,w 피팅)</p>
</li>
<li>
<p>기존 level Path : 1x1 Convolution 진행(c 피팅)</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="stage-mapping">Stage Mapping<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#stage-mapping" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>ROI가 어느 Stage에서 온 것인지 알아야 함, roi의 w와 h 값으로 stage를 추정</li>
</ul>
<p><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.3955em;vertical-align:-0.345em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0505em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">224</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9378em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mord mathnormal mtight">h</span></span></span><span style="top:-2.8978em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1022em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mclose">)]</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0315em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">4</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">a</span><span class="mord mathnormal">u</span><span class="mord mathnormal">lt</span><span class="mclose">)</span></span></span></span></p>
<p>Code</p>
<ul>
<li>Build laterals :각 feature map 마다 다른 채널을 맞춰주는 단계</li>
<li>Build Top-down : channel을 맞춘 후 top-down 형식으로 featuremap 교환</li>
<li>Build outputs : 최종 3x3 CNN을 통과하여 RPN을 들어갈 feature 완성</li>
</ul>
<h2 id="panetpath-aggregation-network">PANet(Path Aggregation Network)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#panetpath-aggregation-network" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Path Aggregation Network for Instance Segmentation </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>The way that information propagates in neural networks is of great importance.<br/>
<a href="https://arxiv.org/abs/1803.01534" class="external">https://arxiv.org/abs/1803.01534<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<h3 id="fpn의-단점">FPN의 단점<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#fpn의-단점" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>Bottom-Up의 과정에서 실제로는 매우 많은 CNN Layer를 거치기 때문에 상위 Level의 Layer로 Feature를 재대로 전달하는지 장담 할 수 없음(ex : ResNet의 긴 CNN 구조)</li>
</ul>
<p><img src="../../../../../../vault/resources/Untitled-8.png" width="auto" height="auto" alt="Untitled 8.png"/></p>
<p>PANet의 Solution : Bottom-Up Path augmentation(첨가)를 위한 Network를 추가</p>
<h3 id="adaptive-feature-pooling">Adaptive Feature Pooling<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#adaptive-feature-pooling" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>기존의 stage mapping(k 값 구하기)의 문제 : 수 pixel 차이로 stage가 변하는 경계선상에 있는 roi들이 존재</li>
<li>Solution : 모든 Stage에서 ROI Pooling 수행</li>
</ul>
<h2 id="detectrors">DetectroRS<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#detectrors" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>DetectoRS: Detecting Objects with Recursive Feature Pyramid and Switchable Atrous Convolution </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>Many modern object detectors demonstrate outstanding performances by using the mechanism of looking and thinking twice.<br/>
<a href="https://arxiv.org/abs/2006.02334" class="external">https://arxiv.org/abs/2006.02334<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<h3 id="motivation">Motivation<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#motivation" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>Looking and thinking twice
<ul>
<li>RPN</li>
<li>Cascade R-CNN</li>
<li>반복적인 작업을 수행하면 성능이 올라갈까?</li>
</ul>
</li>
</ul>
<p><img src="../../../../../../vault/resources/Untitled-16.png" width="auto" height="auto" alt="Untitled 16.png"/></p>
<p><img src="../../../../../../vault/resources/Untitled-1-11.png" width="auto" height="auto" alt="Untitled 1 11.png"/></p>
<h3 id="rfprecursive-feature-pyramid">RFP(Recursive Feature Pyramid)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#rfprecursive-feature-pyramid" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>
<p>Feature Pyramid 구조와 유사, 추가적으로 backbone에서 feature pyramid의 정보를 가지고 학습 수행</p>
</li>
<li>
<p>Flops가 증가하는 단점</p>
</li>
</ul>
<h3 id="atrous-convolutionor-dilated-convolution">Atrous Convolution(or dilated convolution)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#atrous-convolutionor-dilated-convolution" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Atrous Convolution </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>Atrous Convolution 1.<br/>
<a href="https://better-tomorrow.tistory.com/entry/Atrous-Convolution" class="external">https://better-tomorrow.tistory.com/entry/Atrous-Convolution<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<ul>
<li>
<p>R<strong>eceptive field를 키우는 테크닉</strong></p>
</li>
</ul>
<h3 id="asppatrous-spatial-pyramid-pooling">ASPP(Atrous Spatial Pyramid Pooling)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#asppatrous-spatial-pyramid-pooling" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>ASPP(Atrous Spatial Pyramid Pooling) </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>gaussian37’s blog<br/>
<a href="https://gaussian37.github.io/vision-segmentation-aspp/" class="external">https://gaussian37.github.io/vision-segmentation-aspp/<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<p><img src="../../../../../../vault/resources/Untitled-2-41.png" width="auto" height="auto" alt="Untitled 2 41.png"/></p>
<ul>
<li>다른 크기로 Atrous Colvolution을 수행한 뒤, Concat하여 사용</li>
</ul>
<h2 id="bifpnefficientdet">BiFPN(EfficientDet)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#bifpnefficientdet" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>EfficientDet: Scalable and Efficient Object Detection </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>Model efficiency has become increasingly important in computer vision.<br/>
<a href="https://arxiv.org/abs/1911.09070" class="external">https://arxiv.org/abs/1911.09070<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<p><img src="../../../../../../vault/resources/Untitled-31.png" width="auto" height="auto" alt="Untitled 31.png"/></p>
<p><img src="../../../../../../vault/resources/Untitled-1-25.png" width="auto" height="auto" alt="Untitled 1 25.png"/></p>
<p>효율성을 위해, feature map이 한 곳에서만 오는 node들을 삭제(flops 감소)</p>
<h3 id="weighted-featrue-fusion">Weighted Featrue Fusion<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#weighted-featrue-fusion" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>
<p>FPN과 같이 단순 Summantion이 아니라 feature 별 가중치를 부여해서 summantion</p>
</li>
<li>
<p>Feature별 가중치를 통해 중요한 feature를 강조하여 성능 상승</p>
<p><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0972em;vertical-align:-0.2481em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-2.4519em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">6</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.5868em;vertical-align:-0.4451em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1417em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">ϵ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5102em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">⋅</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9021em;"><span style="top:-2.214em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">6</span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">⋅</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="mord mathnormal mtight">es</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">ze</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9021em;"><span style="top:-2.214em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">7</span></span></span><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286em;"><span></span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mclose">)</span></span></span></span></p>
<p>→ <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> : 분모가 0이 되지 않기 위한 매우 작은 값</p>
</li>
</ul>
<p>더 가볍고, 더 높은 성능 구현</p>
<p><img src="../../../../../../vault/resources/Untitled-3-30.png" width="auto" height="auto" alt="Untitled 3 30.png"/></p>
<h2 id="nasfpn">NasFPN<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#nasfpn" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>Current state-of-the-art convolutional architectures for object detection are manually designed.<br/>
<a href="https://arxiv.org/abs/1904.07392" class="external">https://arxiv.org/abs/1904.07392<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<p>기존에는 사람이 구조를 찾았음</p>
<p>FPN 구조에 따라서 성능이 변화</p>
<p>→ NAS를 사용해서 가장 성능이 높은 구조만을 채택해보면 어떨까?</p>
<p><img src="../../../../../../vault/resources/Untitled-4-22.png" width="auto" height="auto" alt="Untitled 4 22.png"/></p>
<p><img src="../../../../../../vault/resources/Untitled-5-18.png" width="auto" height="auto" alt="Untitled 5 18.png"/></p>
<p>같은 inference time 대비 높은 성능</p>
<ul>
<li>COCO Dataset, ResNet 기준으로 찾은 Architecture, 범용적이지 못함
<ul>
<li>Parameter가 많이 소요</li>
</ul>
</li>
<li>High serch cost
<ul>
<li>다른 Architecture, 다른 backbone에 적용하려면 새롭게 구해야 함</li>
</ul>
</li>
</ul>
<h2 id="augfpn">AugFPN<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#augfpn" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>AugFPN: Improving Multi-scale Feature Learning for Object Detection </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>Current state-of-the-art detectors typically exploit feature pyramid to detect objects at different scales.<br/>
<a href="https://arxiv.org/abs/1912.05384" class="external">https://arxiv.org/abs/1912.05384<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<h3 id="기존-fpn의-문제점">기존 FPN의 문제점<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#기존-fpn의-문제점" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>
<p>서로 다른 Level의 feature 간의 semantic 차이</p>
</li>
<li>
<p>Highest feature map의 정보 손실</p>
<ul>
<li>가장 위의 layer는 다른 layer와 다르게 위쪽에서 전달해주는 feature가 없음</li>
</ul>
</li>
<li>
<p>1개의 feature map에서 roi 생성</p>
</li>
</ul>
<h3 id="residual-featrue-augmenmtation">Residual Featrue Augmenmtation<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#residual-featrue-augmenmtation" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><img src="../../../../../../vault/resources/Untitled-6-15.png" width="auto" height="auto" alt="Untitled 6 15.png"/></p>
<ul>
<li>
<p>기존의 FPN의 문제점 중, “Highest feature map의 정보 손실”를 해결하기 위해 기존 backbone에서 Residual Feature Augmentation을 사용해 C5 Feature를 M5 Feature로 전달</p>
</li>
<li>
<p>Ratio-invariant Adaptive Pooling</p>
<ul>
<li>Target Feature Map을 Pyramid 형태로 다양한 Scale의 feature map 생성</li>
</ul>
<p><img src="../../../../../../vault/resources/Untitled-7-11.png" width="auto" height="auto" alt="Untitled 7 11.png"/></p>
</li>
<li>
<p>Adaptive Spatial Fusion</p>
<ul>
<li>Ratio-invariant Adaptive Pooling을 통해 생성한 다양한 크기의 N개의 Feature Map을 Upsample을 통해 동일 크기로 변경, Channel의 경우 256 Channel 고정</li>
<li>Upsample된 N개의 Feature Map를 Concat → Nx256xHxW</li>
<li>1x1 Conv → CxHxW</li>
<li>3x3 Conv → NxHxW</li>
<li>Sigmoid → Nx(1xHxW)
<ul>
<li>일종의 featuremap당 pixel별 weight로 볼 수 있음</li>
</ul>
</li>
<li>Weighted Sum → 256xHxW
<ul>
<li>
<p>N개의 Feature Map과 위 Sigmod 결과로 가중합 수행</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="soft-roi-selection">Soft ROI Selection<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#soft-roi-selection" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>FPN : 하나의 FeatureMap에서 ROI 계산, Sub-optimal</li>
<li>PANet : 모든 Feature map 사용, 하지만 max pool을 사용했기에 정보손실 가능성 존재</li>
</ul>
<p>모든 Scale의 Feature에서 ROI Projection 진행 후 ROI Pooling 수행</p>
<p>Channel-wise 가중치 계산 후 가중합을 사용</p>
<ul>
<li>PANet의 Max Pooling을 학습가능한 가중 합으로 대체</li>
</ul>
<hr/>
<h1 id="1-stage-detectors">1 Stage Detectors<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#1-stage-detectors" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<h2 id="background--history">Background &amp; History<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#background--history" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>An overview of object detection: one-stage methods. </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>In this post, I’ll discuss an overview of deep learning techniques for object detection using convolutional neural networks.<br/>
<a href="https://www.jeremyjordan.me/object-detection-one-stage/" class="external">https://www.jeremyjordan.me/object-detection-one-stage/<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<p>2 Stage Detector들의 단점 : 속도가 매우 느림</p>
<p>Real World에서 사용 가능한 Object Detector는 없을까?</p>
<h3 id="2-stage-detector">2 Stage Detector<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#2-stage-detector" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Input → Region Proposal → Classification → Multi-class classification &amp; Bounding regression For each Proposed Region</p>
<h3 id="1-stage-detector">1 Stage Detector<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#1-stage-detector" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Input → Conv Layers → Feature Maps → Multi-class classification &amp; Bounding regression For each Grid or Spatial Location</p>
<ul>
<li>Localization, Classification이 동시에 진행됨</li>
<li>전체 이미지에 대해 특징 추출, 객체 검출이 이루어짐</li>
<li>속도가 매우 빠름</li>
<li>영역추출을 하지 않고 이미지를 보기 때문에 맥락적 이해가 높음
<ul>
<li>Background Error 낮음</li>
</ul>
</li>
<li>Yolo, SSD, RetinaNet, …etc</li>
</ul>
<h3 id="history">History<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#history" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Info</p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p><a href="https://arxiv.org/pdf/1905.05055.pdf" class="external">https://arxiv.org/pdf/1905.05055.pdf<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<p><img src="../../../../../../vault/resources/Untitled-8-9.png" width="auto" height="auto" alt="Untitled 8 9.png"/></p>
<h2 id="yolo-v1you-only-look-once">Yolo v1(You Only Look Once)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#yolo-v1you-only-look-once" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>You Only Look Once: Unified, Real-Time Object Detection </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>We present YOLO, a new approach to object detection.<br/>
<a href="https://arxiv.org/abs/1506.02640" class="external">https://arxiv.org/abs/1506.02640<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<h3 id="history-1">History<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#history-1" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>
<p>v1 : 이미지의 Bbox와 Classification을 동시에 예측하는 1 Stage Detector 등장</p>
</li>
<li>
<p>v2 : 빠르고 강력하고 더 좋게 향상</p>
</li>
<li>
<p>v3 : multi-scale feature maps 사용</p>
</li>
<li>
<p>v4 : 최신 딥러닝 기술(BagOf Freebies=BOF, Bag of Specials=BOS) 사용</p>
</li>
<li>
<p>v5 : 크기별로 모델 구성(Small, Medium, Lage, Xlarge)</p>
</li>
</ul>
<p>Region Proposal 단계가 없음</p>
<p>GooLeNet의 변형구조</p>
<h3 id="pipeline-2">Pipeline<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pipeline-2" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><img src="../../../../../../vault/resources/Untitled-64.png" width="auto" height="auto" alt="Untitled 64.png"/></p>
<ul>
<li>입력 이미지를 SxS 그리드 영역으로 나누기</li>
<li>각 그리드 영역마다 B개의 Bounding box와 Confidence score 계산
<ul>
<li>Confidence = Pr(Object) x IOU(truth;pred)</li>
</ul>
</li>
<li>각 그리드 영역마다 C개의 Class에 대한 확률 계산(C=20)
<ul>
<li>
<p>Conditional class probability = Pr(Class_i | Object)</p>
</li>
</ul>
</li>
</ul>
<h3 id="network-architecture">Network Architecture<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#network-architecture" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><img src="../../../../../../vault/resources/Untitled-1-47.png" width="auto" height="auto" alt="Untitled 1 47.png"/></p>
<p>Output channel : 7(H)x7(W)x30(Info)</p>
<ul>
<li>Cell(Grid로 나눈 영역)마다 30개의 정보가 저장됨
<ul>
<li>
<p>5개 : 1번 Bonding Box 정보(center x, center y, width, height, confidence score)</p>
</li>
<li>
<p>5개 : 2번 Bonding Box 정보(x, y, width, height, confidence score)</p>
</li>
<li>
<p>20개 : 각 Class일 확률</p>
</li>
</ul>
</li>
</ul>
<h3 id="pipeline-3">Pipeline<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pipeline-3" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>
<p>각 Cell의 Bbox의 Confidence score와 Class 확률 Multiply → 20개의 Class별 Score를 담고 있는 7x7x2개의 Bbox가 생성됨</p>
</li>
<li>
<p>Score Thresholding → 너무 작은 Score는 0으로 Drop</p>
</li>
<li>
<p>Sort Descending → 내림차순으로 정렬</p>
</li>
<li>
<p>NMS</p>
</li>
<li>
<p>Out</p>
</li>
</ul>
<h3 id="loss">Loss<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#loss" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><img src="../../../../../../vault/resources/Untitled-2-31.png" width="auto" height="auto" alt="Untitled 2 31.png"/></p>
<h3 id="장점">장점<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#장점" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Faster R-CNN에 비해 6배 빠른 속도</p>
<p>다른 real-time detector에 비해 2배 높은 정확도</p>
<p>물체의 일반화된 표현을 학습(학습하지 않은 다른 도메인의 이미지에서도 좋은 성능을 보임)</p>
<h3 id="단점">단점<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#단점" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Grid 보다 작은 크기의 물체 검출 불가능</p>
<p>마지막 feature만을 사용</p>
<h2 id="ssd">SSD<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#ssd" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>SSD: Single Shot MultiBox Detector </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>We present a method for detecting objects in images using a single deep neural network.<br/>
<a href="https://arxiv.org/abs/1512.02325" class="external">https://arxiv.org/abs/1512.02325<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<h3 id="yolo-vs-ssd">Yolo vs SSD<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#yolo-vs-ssd" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><img src="../../../../../../vault/resources/Untitled-9-8.png" width="auto" height="auto" alt="Untitled 9 8.png"/></p>
<ul>
<li>Yolo
<ul>
<li>448 x 448 input</li>
<li>fc layer</li>
<li>use only last feature map</li>
</ul>
</li>
<li>SSD
<ul>
<li>
<p>300 x 300 input</p>
</li>
<li>
<p>no fc layer</p>
</li>
<li>
<p>use 6 featrue map</p>
<ul>
<li>early stage : small object detection</li>
<li>late stage : big object detection</li>
</ul>
</li>
<li>
<p>Default Box(=anchor box)</p>
<p><img src="../../../../../../vault/resources/Untitled-10-7.png" width="auto" height="auto" alt="Untitled 10 7.png"/></p>
</li>
</ul>
</li>
</ul>
<h3 id="pipeline-4">Pipeline<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pipeline-4" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>
<p>Multi-scale feature maps 사용</p>
</li>
<li>
<p>Feature Map(HxWx256)을 3x3 Conv로 5x5xC로 변환</p>
<ul>
<li>C = Number of Bbox * (cx, cy, w, h, background, class_1,class_2,…class_n)</li>
<li>Number of Bbox(default box) : 6</li>
</ul>
</li>
<li>
<p>각 Feature Map에 3x3 Conv(stride 1, padding1)연산으로 n * n * (#default box * (offset + <a href="../../../../../.././../../../../../tags/class" class="tag-link internal alias" data-slug="tags/class">class</a>))의 output 생성 → 8732개의 bounding box</p>
</li>
</ul>
<h3 id="training">Training<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#training" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>
<p>Hard negative mining</p>
</li>
<li>
<p>NMS</p>
</li>
</ul>
<h3 id="loss-1">Loss<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#loss-1" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>
<p>Loss Function</p>
<p><img src="../../../../../../vault/resources/Untitled-3-2.png" width="auto" height="auto" alt="Untitled 3 2.png"/></p>
</li>
<li>
<p>Localization Loss</p>
<p><img src="../../../../../../vault/resources/Untitled-4.png" width="auto" height="auto" alt/></p>
</li>
<li>
<p>Confidence Loss</p>
<p><img src="../../../../../../vault/resources/Untitled-5.png" width="auto" height="auto" alt/></p>
</li>
</ul>
<h2 id="yolo-follow-up">YOLO Follow-up<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#yolo-follow-up" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="yolo-v2">Yolo v2<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#yolo-v2" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>Better : 정확도 향상
<ul>
<li>Batch normalization : mAP 2% up</li>
<li>High resolution classifier : mAP 4% up
<ul>
<li>Apply 224x224 Pretrained VGG to 448 x 448 Task</li>
<li>Fine Tuning using 448x448 image</li>
</ul>
</li>
<li>Conv with anchor boxes : mAP 5% up
<ul>
<li>remove fc layer</li>
<li>anchor box 도입</li>
<li>5개의 anchor box</li>
</ul>
</li>
<li>Passthrough Layer
<ul>
<li>Early feature map과 late feature map을 합쳐주는 Layer</li>
</ul>
</li>
</ul>
</li>
<li>Fatser : 속도 향상
<ul>
<li>GoogLeNet을 버리고 Darknet-19 아키텍쳐 적용</li>
</ul>
</li>
<li>Stronger : 더 많은 class 예측 80 → 9000
<ul>
<li>
<p>ImageNet, Coco Dataset 사용</p>
</li>
</ul>
</li>
</ul>
<h3 id="yolo-v3">Yolo v3<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#yolo-v3" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>Darknet-53 사용
<ul>
<li>Resnet-101, resnet 152와 비슷한 성능 및 높은 FPS 달성</li>
</ul>
</li>
<li>Skip Connection 적용</li>
<li>Max pooling x, Conv stride 2 사용</li>
<li>Multi-scale feature map 사용(52x52, 26x26, 13x13)</li>
</ul>
<h2 id="retinanet">RetinaNet<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#retinanet" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Focal Loss for Dense Object Detection </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations.<br/>
<a href="https://arxiv.org/abs/1708.02002" class="external">https://arxiv.org/abs/1708.02002<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<h3 id="1-stage-detector의-고질적-문제">1 Stage Detector의 고질적 문제<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#1-stage-detector의-고질적-문제" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>Class imbalance
<ul>
<li>Grid로 나눠서 Cell 마다 모두 Bbox를 추정하게 함</li>
<li>Positive Sample(Object area) &lt; Negative Sample(BG Area)</li>
</ul>
</li>
<li>Anchor Box 대부분은 Negative Sample
<ul>
<li>
<p>2 Stage detector의 경우 RPN에서 BG 제거</p>
</li>
<li>
<p>Hard Negative mining</p>
</li>
</ul>
</li>
</ul>
<h3 id="concept">Concept<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#concept" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>Focal Loss 제안 : Cross entropy loss + scaling factor
<ul>
<li>쉬운 예제에 작은 가중치, 어려운 예제에 큰 가중치</li>
</ul>
</li>
</ul>
<p><img src="../../../../../../vault/resources/Untitled-11-7.png" width="auto" height="auto" alt="Untitled 11 7.png"/></p>
<hr/>
<h1 id="efficientdet">EfficientDet<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#efficientdet" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<h2 id="efficientnet">EfficientNet<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#efficientnet" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available.<br/>
<a href="https://arxiv.org/abs/1905.11946" class="external">https://arxiv.org/abs/1905.11946<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<h3 id="등장배경">등장배경<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#등장배경" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>점점 빠르고 작은 모델에 대한 요구 증가</p>
<p>효율성과 정확도의 trade-off를 통해 모델 사이즈를 줄이는 것이 일반적</p>
<p>하지만 모델을 어떻게 압축해야 하는지 불분명</p>
<p>더 높은 정확도와 효율성을 가지면서 ConvNet의 크기를 키우는 방법(Scale Up)은 없을까?</p>
<h3 id="model-scaling">Model Scaling<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#model-scaling" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><img src="../../../../../../vault/resources/Untitled-12-6.png" width="auto" height="auto" alt="Untitled 12 6.png"/></p>
<ul>
<li>Model이 커질수록, 성능이 증가 → 모델의 크기를 키움</li>
<li>모델의 크기를 키우다보면, 더 이상 성능 이점이 없어짐 → ‘잘’ 쌓는 방법이 있을 것이다</li>
<li>어떻게 잘 쌓아야 할까?
<ul>
<li>
<p>Width Scaling : Channel을 크기 주는 것</p>
<ul>
<li>ex) Wide ResNet</li>
<li>작은 모델에서 주로 사용됨(MobileNet, MnasNet)</li>
<li>더 wide한 네트워크는 미세한 특징을 잘 잡아내는 경향이 있음</li>
<li>그러나 극단적으로 얕은 모델은 High-level의 특징을 잘 잡아내지 못하는 경향이 있음</li>
</ul>
</li>
<li>
<p>Depth Scaling : CNN을 더 깊게 쌓는 것</p>
<ul>
<li>ex) ResNet</li>
<li>많은 ConvNet에서 쓰이는 방법(DenseNet, Inception-v4)</li>
<li>깊은 ConvNet은 더 풍부하고 복잡한 특징들을 잡아낼 수 있고 새로운 Task에도 잘 일반화 됨</li>
<li>그러나 Gradient vanishing 문제로 깊어질수록 학습이 어려움</li>
</ul>
</li>
<li>
<p>Resolution Scaling : 더 큰 Image를 사용하는 것</p>
<ul>
<li>고화질의 이미지를 사용하면 ConvNet은 미세한 패턴을 잘 잡아낼 수 있음</li>
</ul>
</li>
<li>
<p>Compound Scaling : 위 3개의 Scaling을 모두 사용하는 것</p>
</li>
</ul>
</li>
</ul>
<h3 id="better-accuracy--efficiency">Better Accuracy &amp; Efficiency<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#better-accuracy--efficiency" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><img src="../../../../../../vault/resources/Untitled-13-6.png" width="auto" height="auto" alt="Untitled 13 6.png"/></p>
<p>Model의 Accuracy를 최대화하는 d, w, r을 찾는게 목표</p>
<p><img src="../../../../../../vault/resources/Untitled-14-5.png" width="auto" height="auto" alt="Untitled 14 5.png"/></p>
<ul>
<li>Scale Factors
<ul>
<li>d : Model의 depth를 조절하는 Factor</li>
<li>w : Model의 Channel을 조절하는 Factor</li>
<li>r : Model의 Resolution을 조절하는 Factor</li>
</ul>
</li>
</ul>
<p><img src="../../../../../../vault/resources/Untitled-15-5.png" width="auto" height="auto" alt="Untitled 15 5.png"/></p>
<p>Model의 Memory는 Target의 Memory보다 작거나 같아야한다</p>
<p><img src="../../../../../../vault/resources/Untitled-16-5.png" width="auto" height="auto" alt="Untitled 16 5.png"/></p>
<p>Model의 FLOPS는 Target의 FLOPS보다 작거나 같아야 한다</p>
<p><img src="../../../../../../vault/resources/Untitled-17-5.png" width="auto" height="auto" alt="Untitled 17 5.png"/></p>
<p>각 Factor를 증가시킬 때(다른 Factor는 통제) FLOPS 증가 대비 ImageNet Top-1 Accuracy(%)</p>
<p><img src="../../../../../../vault/resources/Untitled-18-5.png" width="auto" height="auto" alt="Untitled 18 5.png"/></p>
<p>d,r을 변화시키면서 확인한 FLOPS 증가 대비 Top1 Accuracy(%)</p>
<ul>
<li>효율적인 Model을 만들기 위해서는 d, w, r을 모두 적절히 변화시키는 Compound Scaling이 필요함을 실험적으로 증명</li>
</ul>
<h2 id="efficientdet-1">EfficientDet<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#efficientdet-1" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote class="callout info" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>EfficientDet: Scalable and Efficient Object Detection </p></div>
                  
                </div>
<div class="callout-content">
<div class="callout-content-inner">
<p>Model efficiency has become increasingly important in computer vision.<br/>
<a href="https://arxiv.org/abs/1911.09070" class="external">https://arxiv.org/abs/1911.09070<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
</div>
</div>
</blockquote>
<h3 id="motivation-1">Motivation<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#motivation-1" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>자원의 자약이 있는 상태에서 더 높은 정확도와 효율성을 가진 Detection 구조를 만드는 것이 가능할까?</p>
<p>EfficientNet의 아이디어는 Detection Task에도 적용 가능</p>
<p>Yolo나 SSD같이 1 Stage Detector에 속함</p>
<h3 id="기존-detection-model들의-문제와-해결방법">기존 Detection Model들의 문제와 해결방법<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#기존-detection-model들의-문제와-해결방법" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>
<p>Efficient Multi-scale featrue fusion</p>
<ul>
<li>
<p>Neck에서 Channel별 Resolition을 맞춰 Simple Summantion만 했음</p>
</li>
<li>
<p>단순합을 하는 것이 올바를까? → BiFPN 구조 제안</p>
<p><img src="../../../../../../vault/resources/Untitled-19-5.png" width="auto" height="auto" alt="Untitled 19 5.png"/></p>
</li>
</ul>
</li>
<li>
<p>Model Scaling</p>
<p><img src="../../../../../../vault/resources/Untitled-20-5.png" width="auto" height="auto" alt="Untitled 20 5.png"/></p>
<ul>
<li>큰 Backbone, 큰 Image Size에 집중했음</li>
<li>EfficientDet은 정확도와 효율을 모두 높일 수 있는 모델을 찾고자 함
<ul>
<li>EfficientNet과 같은 Compound Scaling 방식 제안</li>
</ul>
</li>
<li>EfficientNet B0~B6을 Backbone으로 사용</li>
<li>BiFPN Network
<ul>
<li>
<p>네트워크의 width(=#channels)와 depth(=#layers)를 compound 계수에 따라 증가시킴(grid search)</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="../../../../../../vault/resources/Untitled-21-5.png" width="auto" height="auto" alt="Untitled 21 5.png"/></p>
<hr/>
<p><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/Week-10/9강-Checkpoint" class="internal alias" data-slug="vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/Week-10/9강-Checkpoint">9강 Checkpoint</a></p>
<p><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/Week-10/Object-detection-꿀팁/Object-detection-꿀팁" class="internal alias" data-slug="vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/Week-10/Object-detection-꿀팁/Object-detection-꿀팁">Object detection 꿀팁</a></p></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div class="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false,&quot;enableRadial&quot;:false}"></div><button class="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div class="global-graph-outer"><div class="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.2,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true,&quot;enableRadial&quot;:true}"></div></div></div><div class="toc desktop-only"><button type="button" class="toc-header" aria-controls="toc-content" aria-expanded="true"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><ul class="toc-content overflow" id="list-1"><li class="depth-0"><a href="#object-detection-library" data-for="object-detection-library">Object Detection Library</a></li><li class="depth-1"><a href="#overview" data-for="overview">Overview</a></li><li class="depth-1"><a href="#mmdetection" data-for="mmdetection">MMDetection</a></li><li class="depth-2"><a href="#two-stage-detector의-pipeline" data-for="two-stage-detector의-pipeline">Two-Stage Detector의 Pipeline</a></li><li class="depth-2"><a href="#mmdetection-2stage-model-pipeline" data-for="mmdetection-2stage-model-pipeline">MMDetection 2Stage Model Pipeline</a></li><li class="depth-1"><a href="#detectron2" data-for="detectron2">Detectron2</a></li><li class="depth-2"><a href="#pipeline" data-for="pipeline">PipeLine</a></li><li class="depth-0"><a href="#neck" data-for="neck">Neck</a></li><li class="depth-1"><a href="#overview-1" data-for="overview-1">Overview</a></li><li class="depth-2"><a href="#neck은-무엇인가" data-for="neck은-무엇인가">Neck은 무엇인가?</a></li><li class="depth-2"><a href="#2-stage-pipline" data-for="2-stage-pipline">2-Stage Pipline</a></li><li class="depth-2"><a href="#왜-마지막-feature-map-만을-사용해야하는가" data-for="왜-마지막-feature-map-만을-사용해야하는가">왜 마지막 feature map 만을 사용해야하는가?</a></li><li class="depth-1"><a href="#fpnfeature-pyramid-network" data-for="fpnfeature-pyramid-network">FPN(Feature Pyramid Network)</a></li><li class="depth-2"><a href="#pipeline-1" data-for="pipeline-1">Pipeline</a></li><li class="depth-2"><a href="#stage-mapping" data-for="stage-mapping">Stage Mapping</a></li><li class="depth-1"><a href="#panetpath-aggregation-network" data-for="panetpath-aggregation-network">PANet(Path Aggregation Network)</a></li><li class="depth-2"><a href="#fpn의-단점" data-for="fpn의-단점">FPN의 단점</a></li><li class="depth-2"><a href="#adaptive-feature-pooling" data-for="adaptive-feature-pooling">Adaptive Feature Pooling</a></li><li class="depth-1"><a href="#detectrors" data-for="detectrors">DetectroRS</a></li><li class="depth-2"><a href="#motivation" data-for="motivation">Motivation</a></li><li class="depth-2"><a href="#rfprecursive-feature-pyramid" data-for="rfprecursive-feature-pyramid">RFP(Recursive Feature Pyramid)</a></li><li class="depth-2"><a href="#atrous-convolutionor-dilated-convolution" data-for="atrous-convolutionor-dilated-convolution">Atrous Convolution(or dilated convolution)</a></li><li class="depth-2"><a href="#asppatrous-spatial-pyramid-pooling" data-for="asppatrous-spatial-pyramid-pooling">ASPP(Atrous Spatial Pyramid Pooling)</a></li><li class="depth-1"><a href="#bifpnefficientdet" data-for="bifpnefficientdet">BiFPN(EfficientDet)</a></li><li class="depth-2"><a href="#weighted-featrue-fusion" data-for="weighted-featrue-fusion">Weighted Featrue Fusion</a></li><li class="depth-1"><a href="#nasfpn" data-for="nasfpn">NasFPN</a></li><li class="depth-1"><a href="#augfpn" data-for="augfpn">AugFPN</a></li><li class="depth-2"><a href="#기존-fpn의-문제점" data-for="기존-fpn의-문제점">기존 FPN의 문제점</a></li><li class="depth-2"><a href="#residual-featrue-augmenmtation" data-for="residual-featrue-augmenmtation">Residual Featrue Augmenmtation</a></li><li class="depth-2"><a href="#soft-roi-selection" data-for="soft-roi-selection">Soft ROI Selection</a></li><li class="depth-0"><a href="#1-stage-detectors" data-for="1-stage-detectors">1 Stage Detectors</a></li><li class="depth-1"><a href="#background--history" data-for="background--history">Background &amp; History</a></li><li class="depth-2"><a href="#2-stage-detector" data-for="2-stage-detector">2 Stage Detector</a></li><li class="depth-2"><a href="#1-stage-detector" data-for="1-stage-detector">1 Stage Detector</a></li><li class="depth-2"><a href="#history" data-for="history">History</a></li><li class="depth-1"><a href="#yolo-v1you-only-look-once" data-for="yolo-v1you-only-look-once">Yolo v1(You Only Look Once)</a></li><li class="depth-2"><a href="#history-1" data-for="history-1">History</a></li><li class="depth-2"><a href="#pipeline-2" data-for="pipeline-2">Pipeline</a></li><li class="depth-2"><a href="#network-architecture" data-for="network-architecture">Network Architecture</a></li><li class="depth-2"><a href="#pipeline-3" data-for="pipeline-3">Pipeline</a></li><li class="depth-2"><a href="#loss" data-for="loss">Loss</a></li><li class="depth-2"><a href="#장점" data-for="장점">장점</a></li><li class="depth-2"><a href="#단점" data-for="단점">단점</a></li><li class="depth-1"><a href="#ssd" data-for="ssd">SSD</a></li><li class="depth-2"><a href="#yolo-vs-ssd" data-for="yolo-vs-ssd">Yolo vs SSD</a></li><li class="depth-2"><a href="#pipeline-4" data-for="pipeline-4">Pipeline</a></li><li class="depth-2"><a href="#training" data-for="training">Training</a></li><li class="depth-2"><a href="#loss-1" data-for="loss-1">Loss</a></li><li class="depth-1"><a href="#yolo-follow-up" data-for="yolo-follow-up">YOLO Follow-up</a></li><li class="depth-2"><a href="#yolo-v2" data-for="yolo-v2">Yolo v2</a></li><li class="depth-2"><a href="#yolo-v3" data-for="yolo-v3">Yolo v3</a></li><li class="depth-1"><a href="#retinanet" data-for="retinanet">RetinaNet</a></li><li class="depth-2"><a href="#1-stage-detector의-고질적-문제" data-for="1-stage-detector의-고질적-문제">1 Stage Detector의 고질적 문제</a></li><li class="depth-2"><a href="#concept" data-for="concept">Concept</a></li><li class="depth-0"><a href="#efficientdet" data-for="efficientdet">EfficientDet</a></li><li class="depth-1"><a href="#efficientnet" data-for="efficientnet">EfficientNet</a></li><li class="depth-2"><a href="#등장배경" data-for="등장배경">등장배경</a></li><li class="depth-2"><a href="#model-scaling" data-for="model-scaling">Model Scaling</a></li><li class="depth-2"><a href="#better-accuracy--efficiency" data-for="better-accuracy--efficiency">Better Accuracy &amp; Efficiency</a></li><li class="depth-1"><a href="#efficientdet-1" data-for="efficientdet-1">EfficientDet</a></li><li class="depth-2"><a href="#motivation-1" data-for="motivation-1">Motivation</a></li><li class="depth-2"><a href="#기존-detection-model들의-문제와-해결방법" data-for="기존-detection-model들의-문제와-해결방법">기존 Detection Model들의 문제와 해결방법</a></li><li class="overflow-end"></li></ul></div><div class="backlinks"><h3>Backlinks</h3><ul id="list-2" class="overflow"><li><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/BiFPN(Neck,-EfficientDet)/BiFPN(Neck,-EfficientDet)" class="internal">BiFPN(Neck, EfficientDet)</a></li><li><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/DetectroRS/DetectroRS" class="internal">DetectroRS</a></li><li><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/FPN(Feature-Pyramid-Network)/FPN(Feature-Pyramid-Network)" class="internal">FPN(Feature Pyramid Network)</a></li><li><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/Naver-Connect---Boostcamp-AI-Tech-4기/Naver-Connect---Boostcamp-AI-Tech-4기" class="internal">Naver Connect - Boostcamp AI Tech 4기</a></li><li><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/Neck/Neck" class="internal">Neck</a></li><li><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/PANet(Path-Aggregation-Network)/PANet(Path-Aggregation-Network)" class="internal">PANet(Path Aggregation Network)</a></li><li><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/RetinaNet/RetinaNet" class="internal">RetinaNet</a></li><li><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/SSD(Single-Shot-Multibox-Detector)/SSD(Single-Shot-Multibox-Detector)" class="internal">SSD(Single Shot Multibox Detector)</a></li><li><a href="../../../../../../vault/Notion/DB/DB-Blog-Post/Yolo-v1(You-Only-Look-Once)/Yolo-v1(You-Only-Look-Once)" class="internal">Yolo v1(You Only Look Once)</a></li><li class="overflow-end"></li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.5.1</a> © 2025</p><ul><li><a href="https://github.com/404Vector/404Vector">GitHub</a></li></ul></footer></div></div></body><script type="application/javascript">function n(){let t=this.parentElement;t.classList.toggle("is-collapsed");let e=t.getElementsByClassName("callout-content")[0];if(!e)return;let l=t.classList.contains("is-collapsed");e.style.gridTemplateRows=l?"0fr":"1fr"}function c(){let t=document.getElementsByClassName("callout is-collapsible");for(let e of t){let l=e.getElementsByClassName("callout-title")[0],s=e.getElementsByClassName("callout-content")[0];if(!l||!s)continue;l.addEventListener("click",n),window.addCleanup(()=>l.removeEventListener("click",n));let o=e.classList.contains("is-collapsed");s.style.gridTemplateRows=o?"0fr":"1fr"}}document.addEventListener("nav",c);
</script><script type="module">function f(i,e){if(!i)return;function r(o){o.target===this&&(o.preventDefault(),o.stopPropagation(),e())}function t(o){o.key.startsWith("Esc")&&(o.preventDefault(),e())}i?.addEventListener("click",r),window.addCleanup(()=>i?.removeEventListener("click",r)),document.addEventListener("keydown",t),window.addCleanup(()=>document.removeEventListener("keydown",t))}function y(i){for(;i.firstChild;)i.removeChild(i.firstChild)}var h=class{constructor(e,r){this.container=e;this.content=r;this.setupEventListeners(),this.setupNavigationControls(),this.resetTransform()}isDragging=!1;startPan={x:0,y:0};currentPan={x:0,y:0};scale=1;MIN_SCALE=.5;MAX_SCALE=3;cleanups=[];setupEventListeners(){let e=this.onMouseDown.bind(this),r=this.onMouseMove.bind(this),t=this.onMouseUp.bind(this),o=this.resetTransform.bind(this);this.container.addEventListener("mousedown",e),document.addEventListener("mousemove",r),document.addEventListener("mouseup",t),window.addEventListener("resize",o),this.cleanups.push(()=>this.container.removeEventListener("mousedown",e),()=>document.removeEventListener("mousemove",r),()=>document.removeEventListener("mouseup",t),()=>window.removeEventListener("resize",o))}cleanup(){for(let e of this.cleanups)e()}setupNavigationControls(){let e=document.createElement("div");e.className="mermaid-controls";let r=this.createButton("+",()=>this.zoom(.1)),t=this.createButton("-",()=>this.zoom(-.1)),o=this.createButton("Reset",()=>this.resetTransform());e.appendChild(t),e.appendChild(o),e.appendChild(r),this.container.appendChild(e)}createButton(e,r){let t=document.createElement("button");return t.textContent=e,t.className="mermaid-control-button",t.addEventListener("click",r),window.addCleanup(()=>t.removeEventListener("click",r)),t}onMouseDown(e){e.button===0&&(this.isDragging=!0,this.startPan={x:e.clientX-this.currentPan.x,y:e.clientY-this.currentPan.y},this.container.style.cursor="grabbing")}onMouseMove(e){this.isDragging&&(e.preventDefault(),this.currentPan={x:e.clientX-this.startPan.x,y:e.clientY-this.startPan.y},this.updateTransform())}onMouseUp(){this.isDragging=!1,this.container.style.cursor="grab"}zoom(e){let r=Math.min(Math.max(this.scale+e,this.MIN_SCALE),this.MAX_SCALE),t=this.content.getBoundingClientRect(),o=t.width/2,n=t.height/2,c=r-this.scale;this.currentPan.x-=o*c,this.currentPan.y-=n*c,this.scale=r,this.updateTransform()}updateTransform(){this.content.style.transform=`translate(${this.currentPan.x}px, ${this.currentPan.y}px) scale(${this.scale})`}resetTransform(){this.scale=1;let e=this.content.querySelector("svg");this.currentPan={x:e.getBoundingClientRect().width/2,y:e.getBoundingClientRect().height/2},this.updateTransform()}},C=["--secondary","--tertiary","--gray","--light","--lightgray","--highlight","--dark","--darkgray","--codeFont"],E;document.addEventListener("nav",async()=>{let e=document.querySelector(".center").querySelectorAll("code.mermaid");if(e.length===0)return;E||=await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.esm.min.mjs");let r=E.default,t=new WeakMap;for(let n of e)t.set(n,n.innerText);async function o(){for(let s of e){s.removeAttribute("data-processed");let a=t.get(s);a&&(s.innerHTML=a)}let n=C.reduce((s,a)=>(s[a]=window.getComputedStyle(document.documentElement).getPropertyValue(a),s),{}),c=document.documentElement.getAttribute("saved-theme")==="dark";r.initialize({startOnLoad:!1,securityLevel:"loose",theme:c?"dark":"base",themeVariables:{fontFamily:n["--codeFont"],primaryColor:n["--light"],primaryTextColor:n["--darkgray"],primaryBorderColor:n["--tertiary"],lineColor:n["--darkgray"],secondaryColor:n["--secondary"],tertiaryColor:n["--tertiary"],clusterBkg:n["--light"],edgeLabelBackground:n["--highlight"]}}),await r.run({nodes:e})}await o(),document.addEventListener("themechange",o),window.addCleanup(()=>document.removeEventListener("themechange",o));for(let n=0;n<e.length;n++){let v=function(){let g=l.querySelector("#mermaid-space"),m=l.querySelector(".mermaid-content");if(!m)return;y(m);let w=c.querySelector("svg").cloneNode(!0);m.appendChild(w),l.classList.add("active"),g.style.cursor="grab",u=new h(g,m)},M=function(){l.classList.remove("active"),u?.cleanup(),u=null},c=e[n],s=c.parentElement,a=s.querySelector(".clipboard-button"),d=s.querySelector(".expand-button"),p=window.getComputedStyle(a),L=a.offsetWidth+parseFloat(p.marginLeft||"0")+parseFloat(p.marginRight||"0");d.style.right=`calc(${L}px + 0.3rem)`,s.prepend(d);let l=s.querySelector("#mermaid-container");if(!l)return;let u=null;d.addEventListener("click",v),f(l,M),window.addCleanup(()=>{u?.cleanup(),d.removeEventListener("click",v)})}});
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="../../../../../../postscript.js" type="module"></script></html>