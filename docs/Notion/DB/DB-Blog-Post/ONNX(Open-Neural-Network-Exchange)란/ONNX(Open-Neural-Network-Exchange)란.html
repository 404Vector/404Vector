<!DOCTYPE html>
<html lang="en"><head><title>ONNX(Open Neural Network Exchange)란</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;family=IBM Plex Mono:wght@400;600&amp;display=swap"/><link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin="anonymous"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="HyeongSeok Kim's Vault"/><meta property="og:title" content="ONNX(Open Neural Network Exchange)란"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="ONNX(Open Neural Network Exchange)란"/><meta name="twitter:description" content="참조 개요 ONNX(Open Neural Network Exchange)란? ONNX로 변환하면 실제로 어떤 결과물을 얻을까? 무슨 변환이 이루어질까? PyTorch Model을 ONNX Model로 변환하기 ONNX의 opset_version 마치며 참조 onnx.ai/ chat.openai.com/ gaussian37.github.io/dl-pytorch-deploy/#onnx에-shape-정보-저장-1 tech.kakaopay.com/post/model-serving-framework/ tutorials.pytorch.kr/..."/><meta property="og:description" content="참조 개요 ONNX(Open Neural Network Exchange)란? ONNX로 변환하면 실제로 어떤 결과물을 얻을까? 무슨 변환이 이루어질까? PyTorch Model을 ONNX Model로 변환하기 ONNX의 opset_version 마치며 참조 onnx.ai/ chat.openai.com/ gaussian37.github.io/dl-pytorch-deploy/#onnx에-shape-정보-저장-1 tech.kakaopay.com/post/model-serving-framework/ tutorials.pytorch.kr/..."/><meta property="og:image:alt" content="참조 개요 ONNX(Open Neural Network Exchange)란? ONNX로 변환하면 실제로 어떤 결과물을 얻을까? 무슨 변환이 이루어질까? PyTorch Model을 ONNX Model로 변환하기 ONNX의 opset_version 마치며 참조 onnx.ai/ chat.openai.com/ gaussian37.github.io/dl-pytorch-deploy/#onnx에-shape-정보-저장-1 tech.kakaopay.com/post/model-serving-framework/ tutorials.pytorch.kr/..."/><meta property="twitter:domain" content="quartz.jzhao.xyz"/><meta property="og:url" content="https://quartz.jzhao.xyz/Notion/DB/DB-Blog-Post/ONNX(Open-Neural-Network-Exchange)란/ONNX(Open-Neural-Network-Exchange)란"/><meta property="twitter:url" content="https://quartz.jzhao.xyz/Notion/DB/DB-Blog-Post/ONNX(Open-Neural-Network-Exchange)란/ONNX(Open-Neural-Network-Exchange)란"/><link rel="icon" href="../../../../static/icon.png"/><meta name="description" content="참조 개요 ONNX(Open Neural Network Exchange)란? ONNX로 변환하면 실제로 어떤 결과물을 얻을까? 무슨 변환이 이루어질까? PyTorch Model을 ONNX Model로 변환하기 ONNX의 opset_version 마치며 참조 onnx.ai/ chat.openai.com/ gaussian37.github.io/dl-pytorch-deploy/#onnx에-shape-정보-저장-1 tech.kakaopay.com/post/model-serving-framework/ tutorials.pytorch.kr/..."/><meta name="generator" content="Quartz"/><link href="../../../../index.css" rel="stylesheet" type="text/css" spa-preserve/><style>.expand-button {
  position: absolute;
  display: flex;
  float: right;
  padding: 0.4rem;
  margin: 0.3rem;
  right: 0;
  color: var(--gray);
  border-color: var(--dark);
  background-color: var(--light);
  border: 1px solid;
  border-radius: 5px;
  opacity: 0;
  transition: 0.2s;
}
.expand-button > svg {
  fill: var(--light);
  filter: contrast(0.3);
}
.expand-button:hover {
  cursor: pointer;
  border-color: var(--secondary);
}
.expand-button:focus {
  outline: 0;
}

pre:hover > .expand-button {
  opacity: 1;
  transition: 0.2s;
}

#mermaid-container {
  position: fixed;
  contain: layout;
  z-index: 999;
  left: 0;
  top: 0;
  width: 100vw;
  height: 100vh;
  overflow: hidden;
  display: none;
  backdrop-filter: blur(4px);
  background: rgba(0, 0, 0, 0.5);
}
#mermaid-container.active {
  display: inline-block;
}
#mermaid-container > #mermaid-space {
  border: 1px solid var(--lightgray);
  background-color: var(--light);
  border-radius: 5px;
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  height: 80vh;
  width: 80vw;
  overflow: hidden;
}
#mermaid-container > #mermaid-space > .mermaid-content {
  padding: 2rem;
  position: relative;
  transform-origin: 0 0;
  transition: transform 0.1s ease;
  overflow: visible;
  min-height: 200px;
  min-width: 200px;
}
#mermaid-container > #mermaid-space > .mermaid-content pre {
  margin: 0;
  border: none;
}
#mermaid-container > #mermaid-space > .mermaid-content svg {
  max-width: none;
  height: auto;
}
#mermaid-container > #mermaid-space > .mermaid-controls {
  position: absolute;
  bottom: 20px;
  right: 20px;
  display: flex;
  gap: 8px;
  padding: 8px;
  background: var(--light);
  border: 1px solid var(--lightgray);
  border-radius: 6px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  z-index: 2;
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 32px;
  height: 32px;
  padding: 0;
  border: 1px solid var(--lightgray);
  background: var(--light);
  color: var(--dark);
  border-radius: 4px;
  cursor: pointer;
  font-size: 16px;
  font-family: var(--bodyFont);
  transition: all 0.2s ease;
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:hover {
  background: var(--lightgray);
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:active {
  transform: translateY(1px);
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:nth-child(2) {
  width: auto;
  padding: 0 12px;
  font-size: 14px;
}
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,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 */</style><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../../../../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../../../../static/contentIndex.json").then(data => data.json())</script><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="https://quartz.jzhao.xyz/index.xml"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image" content="https://quartz.jzhao.xyz/Notion/DB/DB-Blog-Post/ONNX(Open-Neural-Network-Exchange)란/ONNX(Open-Neural-Network-Exchange)란-og-image.webp"/><meta property="og:image:url" content="https://quartz.jzhao.xyz/Notion/DB/DB-Blog-Post/ONNX(Open-Neural-Network-Exchange)란/ONNX(Open-Neural-Network-Exchange)란-og-image.webp"/><meta name="twitter:image" content="https://quartz.jzhao.xyz/Notion/DB/DB-Blog-Post/ONNX(Open-Neural-Network-Exchange)란/ONNX(Open-Neural-Network-Exchange)란-og-image.webp"/><meta property="og:image:type" content="image/.webp"/></head><body data-slug="Notion/DB/DB-Blog-Post/ONNX(Open-Neural-Network-Exchange)란/ONNX(Open-Neural-Network-Exchange)란"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href="../../../..">HyeongSeok Kim's Vault</a></h2><div class="spacer mobile-only"></div><div class="flex-component" style="flex-direction: row; flex-wrap: nowrap; gap: 1rem;"><div style="flex-grow: 1; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><div class="search"><button class="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div class="search-container"><div class="search-space"><input autocomplete="off" class="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div class="search-layout" data-preview="true"></div></div></div></div></div><div style="flex-grow: 0; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><button class="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div style="flex-grow: 0; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><button class="readermode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="readerIcon" fill="currentColor" stroke="currentColor" stroke-width="0.2" stroke-linecap="round" stroke-linejoin="round" width="64px" height="64px" viewBox="0 0 24 24" aria-label="Reader mode"><title>Reader mode</title><g transform="translate(-1.8, -1.8) scale(1.15, 1.2)"><path d="M8.9891247,2.5 C10.1384702,2.5 11.2209868,2.96705384 12.0049645,3.76669482 C12.7883914,2.96705384 13.8709081,2.5 15.0202536,2.5 L18.7549359,2.5 C19.1691495,2.5 19.5049359,2.83578644 19.5049359,3.25 L19.5046891,4.004 L21.2546891,4.00457396 C21.6343849,4.00457396 21.9481801,4.28672784 21.9978425,4.6528034 L22.0046891,4.75457396 L22.0046891,20.25 C22.0046891,20.6296958 21.7225353,20.943491 21.3564597,20.9931534 L21.2546891,21 L2.75468914,21 C2.37499337,21 2.06119817,20.7178461 2.01153575,20.3517706 L2.00468914,20.25 L2.00468914,4.75457396 C2.00468914,4.37487819 2.28684302,4.061083 2.65291858,4.01142057 L2.75468914,4.00457396 L4.50368914,4.004 L4.50444233,3.25 C4.50444233,2.87030423 4.78659621,2.55650904 5.15267177,2.50684662 L5.25444233,2.5 L8.9891247,2.5 Z M4.50368914,5.504 L3.50468914,5.504 L3.50468914,19.5 L10.9478955,19.4998273 C10.4513189,18.9207296 9.73864328,18.5588115 8.96709342,18.5065584 L8.77307039,18.5 L5.25444233,18.5 C4.87474657,18.5 4.56095137,18.2178461 4.51128895,17.8517706 L4.50444233,17.75 L4.50368914,5.504 Z M19.5049359,17.75 C19.5049359,18.1642136 19.1691495,18.5 18.7549359,18.5 L15.2363079,18.5 C14.3910149,18.5 13.5994408,18.8724714 13.0614828,19.4998273 L20.5046891,19.5 L20.5046891,5.504 L19.5046891,5.504 L19.5049359,17.75 Z M18.0059359,3.999 L15.0202536,4 L14.8259077,4.00692283 C13.9889509,4.06666544 13.2254227,4.50975805 12.7549359,5.212 L12.7549359,17.777 L12.7782651,17.7601316 C13.4923805,17.2719483 14.3447024,17 15.2363079,17 L18.0059359,16.999 L18.0056891,4.798 L18.0033792,4.75457396 L18.0056891,4.71 L18.0059359,3.999 Z M8.9891247,4 L6.00368914,3.999 L6.00599909,4.75457396 L6.00599909,4.75457396 L6.00368914,4.783 L6.00368914,16.999 L8.77307039,17 C9.57551536,17 10.3461406,17.2202781 11.0128313,17.6202194 L11.2536891,17.776 L11.2536891,5.211 C10.8200889,4.56369974 10.1361548,4.13636104 9.37521067,4.02745763 L9.18347055,4.00692283 L8.9891247,4 Z"></path></g></svg></button></div></div><div class="explorer" data-behavior="link" data-collapsed="collapsed" data-savestate="true" data-data-fns="{&quot;order&quot;:[&quot;filter&quot;,&quot;map&quot;,&quot;sort&quot;],&quot;sortFn&quot;:&quot;(a,b)=>!a.isFolder&amp;&amp;!b.isFolder||a.isFolder&amp;&amp;b.isFolder?a.displayName.localeCompare(b.displayName,void 0,{numeric:!0,sensitivity:\&quot;base\&quot;}):!a.isFolder&amp;&amp;b.isFolder?1:-1&quot;,&quot;filterFn&quot;:&quot;node=>node.slugSegment!==\&quot;tags\&quot;&quot;,&quot;mapFn&quot;:&quot;node=>node&quot;}"><button type="button" class="explorer-toggle mobile-explorer hide-until-loaded" data-mobile="true" aria-controls="explorer-content"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-menu"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg></button><button type="button" class="title-button explorer-toggle desktop-explorer" data-mobile="false" aria-expanded="true"><h2>Explorer</h2><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div class="explorer-content" aria-expanded="false"><ul class="explorer-ul overflow" id="list-0"><li class="overflow-end"></li></ul></div><template id="template-file"><li><a href="#"></a></li></template><template id="template-folder"><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div><button class="folder-button"><span class="folder-title"></span></button></div></div><div class="folder-outer"><ul class="content"></ul></div></li></template></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../../../../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../Notion/">Notion</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../Notion/DB/">DB</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../Notion/DB/DB-Blog-Post/">DB Blog Post</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../../Notion/DB/DB-Blog-Post/ONNX(Open-Neural-Network-Exchange)란/">ONNX(Open Neural Network Exchange)란</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>ONNX(Open Neural Network Exchange)란</a></div></nav><h1 class="article-title">ONNX(Open Neural Network Exchange)란</h1><p show-comma="true" class="content-meta"><time datetime="2025-06-16T14:48:10.697Z">Jun 16, 2025</time><span>14 min read</span></p></div></div><article class="popover-hint"><ul>
<li><a href="#%EC%B0%B8%EC%A1%B0" class="internal alias">참조</a></li>
<li><a href="#%EA%B0%9C%EC%9A%94" class="internal alias">개요</a></li>
<li><a href="#onnxopen-neural-network-exchange%EB%9E%80" class="internal alias">ONNX(Open Neural Network Exchange)란?</a></li>
<li><a href="#onnx%EB%A1%9C-%EB%B3%80%ED%99%98%ED%95%98%EB%A9%B4-%EC%8B%A4%EC%A0%9C%EB%A1%9C-%EC%96%B4%EB%96%A4-%EA%B2%B0%EA%B3%BC%EB%AC%BC%EC%9D%84-%EC%96%BB%EC%9D%84%EA%B9%8C" class="internal alias">ONNX로 변환하면 실제로 어떤 결과물을 얻을까?</a></li>
<li><a href="#%EB%AC%B4%EC%8A%A8-%EB%B3%80%ED%99%98%EC%9D%B4-%EC%9D%B4%EB%A3%A8%EC%96%B4%EC%A7%88%EA%B9%8C" class="internal alias">무슨 변환이 이루어질까?</a></li>
<li><a href="#pytorch-model%EC%9D%84-onnx-model%EB%A1%9C-%EB%B3%80%ED%99%98%ED%95%98%EA%B8%B0" class="internal alias">PyTorch Model을 ONNX Model로 변환하기</a></li>
<li><a href="#onnx%EC%9D%98-opset_version" class="internal alias">ONNX의 opset_version</a></li>
<li><a href="#%EB%A7%88%EC%B9%98%EB%A9%B0" class="internal alias">마치며</a></li>
</ul>
<hr/>
<h2 id="참조">참조<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#참조" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p><a href="https://onnx.ai/" class="external">https://onnx.ai/<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p><a href="https://chat.openai.com/" class="external">https://chat.openai.com/<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p><a href="https://gaussian37.github.io/dl-pytorch-deploy/#onnx%EC%97%90-shape-%EC%A0%95%EB%B3%B4-%EC%A0%80%EC%9E%A5-1" class="external">https://gaussian37.github.io/dl-pytorch-deploy/#onnx에-shape-정보-저장-1<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p><a href="https://tech.kakaopay.com/post/model-serving-framework/" class="external">https://tech.kakaopay.com/post/model-serving-framework/<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p><a href="https://tutorials.pytorch.kr/advanced/super_resolution_with_onnxruntime.html" class="external">https://tutorials.pytorch.kr/advanced/super_resolution_with_onnxruntime.html<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p><a href="https://onnx.ai/onnx/index.html" class="external">https://onnx.ai/onnx/index.html<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<h2 id="개요">개요<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#개요" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>최근, 회사에서 서비스화를 진행하는 AI 모델의 경량화를 맡게 되었습니다. 모델은 Nvidia GPU를 사용하는 서버에서 구동될 예정이어서 <a href="https://developer.nvidia.com/tensorrt" class="external">TensorRT<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>로 모델을 경량화 하는 것으로 방향을 잡았습니다.</p>
<p>TensorRT를 사용하여 경량화 하기 위해서는 우선 모델을 ONNX로 변환해야 할 필요가 있었습니다. 물론, 현재 Torch-TensorRT라는 것이 있긴 하지만, 제가 원하는 Int8 양자화 기능을 찾지 못했습니다. 때문에 겸사겸사 ONNX에 대하여 스터디해 보았습니다.</p>
<h2 id="onnxopen-neural-network-exchange란">ONNX(Open Neural Network Exchange)란?<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#onnxopen-neural-network-exchange란" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<blockquote>
<p><strong>ONNX는 ML Model을 표현하기 위한 Format의 한 종류이며, <a href="https://github.com/onnx" class="external">Open Source<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>로 공개되어 있습니다.</strong><br/>
AI 개발자가 다양한 프레임워크, 도구, 런타임 및 컴파일러와 함께 모델을 사용할 수 있도록 공통 연산자 세트(기계 학습 및 딥 러닝 모델의 빌딩 블록)와 공통 파일 형식을 정의합니다.</p>
</blockquote>
<p>세상에는 현재 많은 ML/DL Framework(ex: Pytorch, TensorFlow, Caffe)가 존재합니다. 우리는 이 Framework을 토대로 모델을 훈련하고, 그 결과 훈련된 모델을 얻습니다.</p>
<p>여기서 ‘훈련된 모델’은 어떤 Framework를 사용해서 훈련했느냐에 따라서 그 내부적인 구조와 구현도 제각각입니다. 똑같은 Resnet50 아키텍처라도 Framework간에 서로 호환되지 않습니다. 예를 들어 Pytorch에서 훈련한 Resnet50을 TensorFlow에서는 사용할 수 없습니다.</p>
<p>하지만, 서로에게 약속된 공용 포맷이 있다면 변환을 통해 사용할 수 있을 것입니다.<br/>
==예) Pytorch Resnet50 → ( 어떤 공용 포맷 ) → TensorFlow Resnet50</p>
<ul>
<li>ONNX는 위 예시에서의 ‘어떤 공용 포맷’ 역할을 해줍니다.<br/>
==</li>
</ul>
<p><img src="../../../../resources/Untitled-2.png" width="auto" height="auto" alt="Untitled 2.png"/></p>
<p>ONNX는 딥러닝 모델을 표준화된 형식으로 표현하고 공유할 수 있게 해주는 오픈소스 프로젝트입니다. ONNX는 다양한 딥러닝 프레임워크 간에 모델을 쉽게 변환하고 공유할 수 있도록 함으로써, 다른 프레임워크를 사용하는 환경에서 모델의 이식성을 높일 수 있습니다.</p>
<p>ONNX는 딥러닝 모델을 표현하는데 사용되는 중간 표현(Intermediate Representation) 형식입니다. 이 중간 표현은 모델의 아키텍처, 가중치, 그래프 연산 등을 포함하고 있어 다양한 딥러닝 프레임워크에서 해석할 수 있습니다. ONNX를 사용하면 훈련된 모델을 변환하고, 추론 엔진에서 실행하고, 다른 프레임워크로 내보낼 수 있습니다.</p>
<h2 id="onnx로-변환하면-실제로-어떤-결과물을-얻을까">ONNX로 변환하면 실제로 어떤 결과물을 얻을까?<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#onnx로-변환하면-실제로-어떤-결과물을-얻을까" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>우리가 기존에 모델을 불러와 사용할 때 두 가지가 필요합니다.</p>
<ol>
<li>
<p>모델의 아키텍쳐의 정보(ex: Resnet50.py)</p>
</li>
<li>
<p>그 아키텍처의 Weight 파일(ex: Resnet.50_epoch10.pth</p>
</li>
</ol>
<p><strong>그러나 ONNX로 변환하면 이 두 가지가 합쳐져서 .onnx 파일 하나만 생성됩니다.</strong></p>
<h2 id="무슨-변환이-이루어질까">무슨 변환이 이루어질까?<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#무슨-변환이-이루어질까" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>우리가 만약 PyTorch로 훈련한 Resnet18을 ONNX로 변환한다면, 내부적으로는 어떤 일을 하는 것일까요? ONNX는 ‘공용 포맷’ 입니다. 따라서 어떤 Framework의 코드도 사용할 수 없습니다. 특정 Framework의 코드를 사용한다면, 이미 공용이 아니고 해당 Framework에 종속된 것이니까요. 따라서 ONNX로 변환할 시에는 우리가 만든 모델의 아키텍처를 하나 하나 뜯어서 ONNX가 자체적으로 제공하는 Operator로 변환하는 작업을 합니다.</p>
<p>우리가 직접 Resnet을 구현해야 한다면 대부분 Residual Block을 구현한 뒤, Residual Block을 가져와 Resnet을 종류별로 구현할 것입니다. 이렇게 해야 코드가 늘어나는 것을 피할 수 있고, 쓰는 우리도 편리하고, 이해하기도 편합니다. <a href="https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py" class="external">이곳<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>을 보시면 TorchVision의 Resnet18에 대한 구현을 볼 수 있습니다.</p>
<p>이 이야기를 한 이유는 ONNX로 변환한 결과는 위 모듈 구조들이 모두 사라지고, 연산을 위한 Operator들 간의 Graph가 남기 때문입니다. <a href="https://github.com/onnx/models/blob/main/vision/classification/resnet/model/resnet18-v1-7.onnx" class="external">이곳<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>에는 Resnet18을 onnx로 변환한 모델이 있습니다. 이 파일을 다운로드한 뒤, <a href="https://netron.app/" class="external">Netron<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>이라는 ONNX Viewer로 열어보면 아래와 같은 구조를 볼 수 있습니다.</p>
<p><img src="../../../../resources/Untitled-1-2.png" width="auto" height="auto" alt="Untitled 1 2.png"/></p>
<p><strong>이 결과를 통해 알 수 있는 점은 다음과 같습니다.</strong></p>
<ol>
<li>ONNX로 변환하면, 사람이 짜놓은 모듈 구조들이 모두 무너진다.</li>
<li>모델이 복잡해질수록 ONNX 파일만 보고 모델의 구조를 파악하는 것은 어려울 것이다.</li>
<li>ONNX를 다시 변환 전의 상태로 변환할 수 없다.
<ol>
<li>
<p>Resnet18.onnx를 가지고 TorchVision의 Resnet18처럼 모듈화된 아키텍처를 만들 수 없다.</p>
</li>
</ol>
</li>
</ol>
<p>따라서, ONNX 변환을 통해 다양한 Framework에서 사용할 수 있다고 할지라도, 이는 Inference만 해당될 것입니다. (사실 Inference가 가능하다는 것은 Train도 가능하다는 것을 의미하지만, 모델을 ONNX 변환한 뒤 훈련할 이유는 없다고 생각합니다)</p>
<h2 id="pytorch-model을-onnx-model로-변환하기"><strong>PyTorch Model을 ONNX Model로 변환하기</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pytorch-model을-onnx-model로-변환하기" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>아래 코드는 Pytorch 공식 문서에서 제공하는 것으로, Super Resolution Model을 ONNX로 export 하는 예시를 보여줍니다.</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span># 필요한 import문</span></span>
<span data-line><span>import io</span></span>
<span data-line><span>import numpy as np</span></span>
<span data-line><span>import torch.utils.model_zoo as model_zoo</span></span>
<span data-line><span>import torch.onnx</span></span>
<span data-line><span>import torch.nn as nn</span></span>
<span data-line><span>import torch.nn.init as init</span></span>
<span data-line> </span>
<span data-line> </span>
<span data-line><span># PyTorch에서 구현된 초해상도 모델</span></span>
<span data-line><span>class SuperResolutionNet(nn.Module):</span></span>
<span data-line><span>    def __init__(self, upscale_factor, inplace=False):</span></span>
<span data-line><span>        super(SuperResolutionNet, self).__init__()</span></span>
<span data-line> </span>
<span data-line><span>        self.relu = nn.ReLU(inplace=inplace)</span></span>
<span data-line><span>        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))</span></span>
<span data-line><span>        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))</span></span>
<span data-line><span>        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))</span></span>
<span data-line><span>        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))</span></span>
<span data-line><span>        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)</span></span>
<span data-line> </span>
<span data-line><span>        self._initialize_weights()</span></span>
<span data-line> </span>
<span data-line><span>    def forward(self, x):</span></span>
<span data-line><span>        x = self.relu(self.conv1(x))</span></span>
<span data-line><span>        x = self.relu(self.conv2(x))</span></span>
<span data-line><span>        x = self.relu(self.conv3(x))</span></span>
<span data-line><span>        x = self.pixel_shuffle(self.conv4(x))</span></span>
<span data-line><span>        return x</span></span>
<span data-line> </span>
<span data-line><span>    def _initialize_weights(self):</span></span>
<span data-line><span>        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))</span></span>
<span data-line><span>        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))</span></span>
<span data-line><span>        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))</span></span>
<span data-line><span>        init.orthogonal_(self.conv4.weight)</span></span>
<span data-line> </span>
<span data-line><span># 위에서 정의된 모델을 사용하여 초해상도 모델 생성</span></span>
<span data-line><span>torch_model = SuperResolutionNet(upscale_factor=3)</span></span>
<span data-line> </span>
<span data-line><span># 미리 학습된 가중치를 읽어옵니다</span></span>
<span data-line><span>model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'</span></span>
<span data-line><span>batch_size = 1    # 임의의 수</span></span>
<span data-line> </span>
<span data-line><span># 모델을 미리 학습된 가중치로 초기화합니다</span></span>
<span data-line><span>map_location = lambda storage, loc: storage</span></span>
<span data-line><span>if torch.cuda.is_available():</span></span>
<span data-line><span>    map_location = None</span></span>
<span data-line><span>torch_model.load_state_dict(model_zoo.load_url(model_url, map_location=map_location))</span></span>
<span data-line> </span>
<span data-line><span># 모델을 추론 모드로 전환합니다</span></span>
<span data-line><span>torch_model.eval()</span></span>
<span data-line> </span>
<span data-line><span># 모델에 대한 입력값</span></span>
<span data-line><span>x = torch.randn(batch_size, 1, 224, 224, requires_grad=True)</span></span>
<span data-line><span>torch_out = torch_model(x)</span></span>
<span data-line> </span>
<span data-line><span># 모델 변환</span></span>
<span data-line><span>torch.onnx.export(torch_model,               # 실행될 모델</span></span>
<span data-line><span>                  x,                         # 모델 입력값 (튜플 또는 여러 입력값들도 가능)</span></span>
<span data-line><span>                  &quot;super_resolution.onnx&quot;,   # 모델 저장 경로 (파일 또는 파일과 유사한 객체 모두 가능)</span></span>
<span data-line><span>                  export_params=True,        # 모델 파일 안에 학습된 모델 가중치를 저장할지의 여부</span></span>
<span data-line><span>                  opset_version=10,          # 모델을 변환할 때 사용할 ONNX 버전</span></span>
<span data-line><span>                  do_constant_folding=True,  # 최적화시 상수폴딩을 사용할지의 여부</span></span>
<span data-line><span>                  input_names = ['input'],   # 모델의 입력값을 가리키는 이름</span></span>
<span data-line><span>                  output_names = ['output'], # 모델의 출력값을 가리키는 이름</span></span>
<span data-line><span>                  dynamic_axes={'input' : {0 : 'batch_size'},    # 가변적인 길이를 가진 차원</span></span>
<span data-line><span>                                'output' : {0 : 'batch_size'}})</span></span></code></pre></figure>
<p>위 과정을 요약하면 다음과 같습니다.</p>
<ol>
<li>Pytorch 모델 인스턴스를 생성하고, 학습된 가중치를 모델에 로드한다.</li>
<li>모델 입력 값을 선언한다.</li>
<li>모델을 추론 모드로 전환하고, 선언한 입력 값을 1회 인퍼런스 한다.</li>
<li>모델 인스턴스와 모델 입력 값을 파라미터로 onnx로 export 한다.</li>
</ol>
<h2 id="onnx의-opset_version">ONNX의 opset_version<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#onnx의-opset_version" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>위 과정에서 눈여겨 볼 부분은 onnx로 export하는 부분입니다. 잘 보면 파라미터 중에 아래와 같은 문구가 있습니다.</p>
<p><code>opset_version=10, # 모델을 변환할 때 사용할 ONNX 버전</code></p>
<p>ONNX 변환에 별도로 버전을 파라미터로 준다니, 버전은 높으면 무조건 좋은 것이 아닐까요? 해답은 공식 문서에 있었습니다. <a href="https://onnx.ai/onnx/operators/" class="external">이곳<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>에는 ONNX가 제공하는 Operator가 있습니다. 아래 Table은 그 일부를 발췌한 것입니다.</p>








































<div class="table-container"><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td>operator</td><td>versions</td><td>differences</td></tr><tr><td><a href="https://onnx.ai/onnx/operators/onnx__Abs.html#l-onnx-doc-abs" class="external">Abs<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td><td><a href="https://onnx.ai/onnx/operators/onnx__Abs.html#l-onnx-op-abs-13" class="external">13<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/onnx__Abs.html#l-onnx-op-abs-6" class="external">6<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/onnx__Abs.html#l-onnx-op-abs-1" class="external">1<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td><td><a href="https://onnx.ai/onnx/operators/text_diff_Abs_6_13.html#l-onnx-op-abs-d6-13" class="external">13/6<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/text_diff_Abs_1_13.html#l-onnx-op-abs-d1-13" class="external">13/1<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/text_diff_Abs_1_6.html#l-onnx-op-abs-d1-6" class="external">6/1<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td></tr><tr><td><a href="https://onnx.ai/onnx/operators/onnx__Acos.html#l-onnx-doc-acos" class="external">Acos<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td><td><a href="https://onnx.ai/onnx/operators/onnx__Acos.html#l-onnx-op-acos-7" class="external">7<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td><td></td></tr><tr><td><a href="https://onnx.ai/onnx/operators/onnx__Acosh.html#l-onnx-doc-acosh" class="external">Acosh<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td><td><a href="https://onnx.ai/onnx/operators/onnx__Acosh.html#l-onnx-op-acosh-9" class="external">9<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td><td></td></tr><tr><td><a href="https://onnx.ai/onnx/operators/onnx__Add.html#l-onnx-doc-add" class="external">Add<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td><td><a href="https://onnx.ai/onnx/operators/onnx__Add.html#l-onnx-op-add-14" class="external">14<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/onnx__Add.html#l-onnx-op-add-13" class="external">13<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/onnx__Add.html#l-onnx-op-add-7" class="external">7<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/onnx__Add.html#l-onnx-op-add-6" class="external">6<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/onnx__Add.html#l-onnx-op-add-1" class="external">1<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td><td><a href="https://onnx.ai/onnx/operators/text_diff_Add_13_14.html#l-onnx-op-add-d13-14" class="external">14/13<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/text_diff_Add_7_14.html#l-onnx-op-add-d7-14" class="external">14/7<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/text_diff_Add_7_13.html#l-onnx-op-add-d7-13" class="external">13/7<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/text_diff_Add_6_14.html#l-onnx-op-add-d6-14" class="external">14/6<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/text_diff_Add_6_13.html#l-onnx-op-add-d6-13" class="external">13/6<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/text_diff_Add_6_7.html#l-onnx-op-add-d6-7" class="external">7/6<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/text_diff_Add_1_14.html#l-onnx-op-add-d1-14" class="external">14/1<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/text_diff_Add_1_13.html#l-onnx-op-add-d1-13" class="external">13/1<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/text_diff_Add_1_7.html#l-onnx-op-add-d1-7" class="external">7/1<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/text_diff_Add_1_6.html#l-onnx-op-add-d1-6" class="external">6/1<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td></tr><tr><td><a href="https://onnx.ai/onnx/operators/onnx__And.html#l-onnx-doc-and" class="external">And<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td><td><a href="https://onnx.ai/onnx/operators/onnx__And.html#l-onnx-op-and-7" class="external">7<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, <a href="https://onnx.ai/onnx/operators/onnx__And.html#l-onnx-op-and-1" class="external">1<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td><td><a href="https://onnx.ai/onnx/operators/text_diff_And_1_7.html#l-onnx-op-and-d1-7" class="external">7/1<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></td></tr></tbody></table></div>
<p>앞서 ONNX의 변환은 해당 Framework의 operator를 ONNX operator로 변환하는 과정이라고 설명드렸습니다. 이것은 즉 <strong>ONNX가 지원하지 않는 Operator를 모델에서 사용했다면 변환할 수 없다는 것을 의미합니다.</strong> Table을 쭉 훑어보면, <a href="https://onnx.ai/onnx/operators/onnx__DeformConv.html#l-onnx-doc-deformconv" class="external">DeformConv Operator(deformable convolution)<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>의 경우 19 버전에서 추가되었으므로, 그 이전 버전으로는 변환할 수 없습니다.</p>
<p>또한 Table의 우측 Column은 같은 Operator라도 버전에 따라서 차이가 존재할 수 있음을 암시합니다. <a href="https://onnx.ai/onnx/operators/text_diff_Abs_6_13.html#l-onnx-op-abs-d6-13" class="external">이 링크<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>는 위 Table에서 Abs operator의 13과 6 버전의 차이에 관해 설명된 글입니다. 내부 구현이 조금 달라진 것을 알 수 있습니다. 따라서 <strong>opset_version에 따라 모델의 성능이 달라질 수 있다는 것을 알 수 있는 부분입니다.</strong></p>
<h2 id="마치며">마치며<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#마치며" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>이번 포스팅에서는 ONNX의 기초 개념과 onnx 파일 내부가 어떻게 되어 있는지 알아보았고 Pytorch 모델을 ONNX로 변환하는 코드에서 “opset_version”이 의미하는 것이 무엇인지를 다뤄보았습니다.</p>
<p>PyTorch를 배우면서 느꼈던 생각이<br/>
<em>“작은 모델이라면 상관 없지만 복잡하고 큰 모델일수록 여러 script의 모듈을 참조하고 혹은 추가 패키지까지 설치하게 되는데 서빙하는 단에서 이 종속성을 모두 챙겨야 한다면 너무 불편할 것 같다”</em><br/>
였습니다.</p>
<p>하지만 현업에서 ONNX로 export하여 서빙하는 곳들이 있다는 것을 알게 되었고, 이번에 ONNX에 대해 공부하게 되면서 그 이유를 조금이나마 알게 된 것 같습니다.</p>
<p>ONNX로 변환하게 되면 더 이상 수정하기 어려운 상태가 되지만 별도로 다른 부속품들을 챙길 필요 없이 onnx 파일과 파일을 Inference 할 수 있는 Engine만 있으면 되기 때문입니다.</p>
<p>ONNX에는 <a href="https://onnxruntime.ai/" class="external">ONNX-Runtime<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>이라는 강력한 인퍼런스 엔진이 있는데, 이것도 굉장히 매력적인 프로젝트라고 느껴집니다. 때문에 다음에 기회가 되면 다뤄보고 싶습니다.</p></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div class="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false,&quot;enableRadial&quot;:false}"></div><button class="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div class="global-graph-outer"><div class="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.2,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true,&quot;enableRadial&quot;:true}"></div></div></div><div class="toc desktop-only"><button type="button" class="toc-header" aria-controls="toc-content" aria-expanded="true"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><ul class="toc-content overflow" id="list-1"><li class="depth-0"><a href="#참조" data-for="참조">참조</a></li><li class="depth-0"><a href="#개요" data-for="개요">개요</a></li><li class="depth-0"><a href="#onnxopen-neural-network-exchange란" data-for="onnxopen-neural-network-exchange란">ONNX(Open Neural Network Exchange)란?</a></li><li class="depth-0"><a href="#onnx로-변환하면-실제로-어떤-결과물을-얻을까" data-for="onnx로-변환하면-실제로-어떤-결과물을-얻을까">ONNX로 변환하면 실제로 어떤 결과물을 얻을까?</a></li><li class="depth-0"><a href="#무슨-변환이-이루어질까" data-for="무슨-변환이-이루어질까">무슨 변환이 이루어질까?</a></li><li class="depth-0"><a href="#pytorch-model을-onnx-model로-변환하기" data-for="pytorch-model을-onnx-model로-변환하기">PyTorch Model을 ONNX Model로 변환하기</a></li><li class="depth-0"><a href="#onnx의-opset_version" data-for="onnx의-opset_version">ONNX의 opset_version</a></li><li class="depth-0"><a href="#마치며" data-for="마치며">마치며</a></li><li class="overflow-end"></li></ul></div><div class="backlinks"><h3>Backlinks</h3><ul id="list-2" class="overflow"><li><a href="../../../../Notion/DB/DB-Blog-Post/ONNX-Runtime은-무엇일까/ONNX-Runtime은-무엇일까" class="internal">ONNX-Runtime은 무엇일까</a></li><li><a href="../../../../Notion/DB/DB-Blog-Post/글또-8기/글또-8기" class="internal">글또 8기</a></li><li><a href="../../../../Notion/DB/DB-Blog-Post/글또-8기/글또-8기를-마치며/글또-8기를-마치며" class="internal">글또 8기를 마치며</a></li><li><a href="../../../../Notion/HyeongSeok-Kim’s-Notion/HyeongSeok-Kim’s-Notion" class="internal">HyeongSeok Kim’s Notion</a></li><li><a href="../../../../" class="internal">Main</a></li><li class="overflow-end"></li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.5.1</a> © 2025</p><ul><li><a href="https://github.com/404Vector/404Vector">GitHub</a></li></ul></footer></div></div></body><script type="application/javascript">function n(){let t=this.parentElement;t.classList.toggle("is-collapsed");let e=t.getElementsByClassName("callout-content")[0];if(!e)return;let l=t.classList.contains("is-collapsed");e.style.gridTemplateRows=l?"0fr":"1fr"}function c(){let t=document.getElementsByClassName("callout is-collapsible");for(let e of t){let l=e.getElementsByClassName("callout-title")[0],s=e.getElementsByClassName("callout-content")[0];if(!l||!s)continue;l.addEventListener("click",n),window.addCleanup(()=>l.removeEventListener("click",n));let o=e.classList.contains("is-collapsed");s.style.gridTemplateRows=o?"0fr":"1fr"}}document.addEventListener("nav",c);
</script><script type="module">function f(i,e){if(!i)return;function r(o){o.target===this&&(o.preventDefault(),o.stopPropagation(),e())}function t(o){o.key.startsWith("Esc")&&(o.preventDefault(),e())}i?.addEventListener("click",r),window.addCleanup(()=>i?.removeEventListener("click",r)),document.addEventListener("keydown",t),window.addCleanup(()=>document.removeEventListener("keydown",t))}function y(i){for(;i.firstChild;)i.removeChild(i.firstChild)}var h=class{constructor(e,r){this.container=e;this.content=r;this.setupEventListeners(),this.setupNavigationControls(),this.resetTransform()}isDragging=!1;startPan={x:0,y:0};currentPan={x:0,y:0};scale=1;MIN_SCALE=.5;MAX_SCALE=3;cleanups=[];setupEventListeners(){let e=this.onMouseDown.bind(this),r=this.onMouseMove.bind(this),t=this.onMouseUp.bind(this),o=this.resetTransform.bind(this);this.container.addEventListener("mousedown",e),document.addEventListener("mousemove",r),document.addEventListener("mouseup",t),window.addEventListener("resize",o),this.cleanups.push(()=>this.container.removeEventListener("mousedown",e),()=>document.removeEventListener("mousemove",r),()=>document.removeEventListener("mouseup",t),()=>window.removeEventListener("resize",o))}cleanup(){for(let e of this.cleanups)e()}setupNavigationControls(){let e=document.createElement("div");e.className="mermaid-controls";let r=this.createButton("+",()=>this.zoom(.1)),t=this.createButton("-",()=>this.zoom(-.1)),o=this.createButton("Reset",()=>this.resetTransform());e.appendChild(t),e.appendChild(o),e.appendChild(r),this.container.appendChild(e)}createButton(e,r){let t=document.createElement("button");return t.textContent=e,t.className="mermaid-control-button",t.addEventListener("click",r),window.addCleanup(()=>t.removeEventListener("click",r)),t}onMouseDown(e){e.button===0&&(this.isDragging=!0,this.startPan={x:e.clientX-this.currentPan.x,y:e.clientY-this.currentPan.y},this.container.style.cursor="grabbing")}onMouseMove(e){this.isDragging&&(e.preventDefault(),this.currentPan={x:e.clientX-this.startPan.x,y:e.clientY-this.startPan.y},this.updateTransform())}onMouseUp(){this.isDragging=!1,this.container.style.cursor="grab"}zoom(e){let r=Math.min(Math.max(this.scale+e,this.MIN_SCALE),this.MAX_SCALE),t=this.content.getBoundingClientRect(),o=t.width/2,n=t.height/2,c=r-this.scale;this.currentPan.x-=o*c,this.currentPan.y-=n*c,this.scale=r,this.updateTransform()}updateTransform(){this.content.style.transform=`translate(${this.currentPan.x}px, ${this.currentPan.y}px) scale(${this.scale})`}resetTransform(){this.scale=1;let e=this.content.querySelector("svg");this.currentPan={x:e.getBoundingClientRect().width/2,y:e.getBoundingClientRect().height/2},this.updateTransform()}},C=["--secondary","--tertiary","--gray","--light","--lightgray","--highlight","--dark","--darkgray","--codeFont"],E;document.addEventListener("nav",async()=>{let e=document.querySelector(".center").querySelectorAll("code.mermaid");if(e.length===0)return;E||=await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.esm.min.mjs");let r=E.default,t=new WeakMap;for(let n of e)t.set(n,n.innerText);async function o(){for(let s of e){s.removeAttribute("data-processed");let a=t.get(s);a&&(s.innerHTML=a)}let n=C.reduce((s,a)=>(s[a]=window.getComputedStyle(document.documentElement).getPropertyValue(a),s),{}),c=document.documentElement.getAttribute("saved-theme")==="dark";r.initialize({startOnLoad:!1,securityLevel:"loose",theme:c?"dark":"base",themeVariables:{fontFamily:n["--codeFont"],primaryColor:n["--light"],primaryTextColor:n["--darkgray"],primaryBorderColor:n["--tertiary"],lineColor:n["--darkgray"],secondaryColor:n["--secondary"],tertiaryColor:n["--tertiary"],clusterBkg:n["--light"],edgeLabelBackground:n["--highlight"]}}),await r.run({nodes:e})}await o(),document.addEventListener("themechange",o),window.addCleanup(()=>document.removeEventListener("themechange",o));for(let n=0;n<e.length;n++){let v=function(){let g=l.querySelector("#mermaid-space"),m=l.querySelector(".mermaid-content");if(!m)return;y(m);let w=c.querySelector("svg").cloneNode(!0);m.appendChild(w),l.classList.add("active"),g.style.cursor="grab",u=new h(g,m)},M=function(){l.classList.remove("active"),u?.cleanup(),u=null},c=e[n],s=c.parentElement,a=s.querySelector(".clipboard-button"),d=s.querySelector(".expand-button"),p=window.getComputedStyle(a),L=a.offsetWidth+parseFloat(p.marginLeft||"0")+parseFloat(p.marginRight||"0");d.style.right=`calc(${L}px + 0.3rem)`,s.prepend(d);let l=s.querySelector("#mermaid-container");if(!l)return;let u=null;d.addEventListener("click",v),f(l,M),window.addCleanup(()=>{u?.cleanup(),d.removeEventListener("click",v)})}});
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="../../../../postscript.js" type="module"></script></html>