<!DOCTYPE html>
<html lang="en"><head><title>Kaggle - Intro to Machine Learning 번역</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;family=IBM Plex Mono:wght@400;600&amp;display=swap"/><link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin="anonymous"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="HyeongSeok Kim's Vault"/><meta property="og:title" content="Kaggle - Intro to Machine Learning 번역"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Kaggle - Intro to Machine Learning 번역"/><meta name="twitter:description" content="참조 Kaggle - Intro to Machine Learning [[#How Models Work []] [[#Basic Data Exploration []] [[#Your First Machine Learning Model []] [[#Model Validation []] [[#Underfitting and Overfitting []] [[#Random Forests []] 참조 www.kaggle.com/code/dansbecker/how-models-work www.kaggle.com/code/dansbecker/basi..."/><meta property="og:description" content="참조 Kaggle - Intro to Machine Learning [[#How Models Work []] [[#Basic Data Exploration []] [[#Your First Machine Learning Model []] [[#Model Validation []] [[#Underfitting and Overfitting []] [[#Random Forests []] 참조 www.kaggle.com/code/dansbecker/how-models-work www.kaggle.com/code/dansbecker/basi..."/><meta property="og:image:alt" content="참조 Kaggle - Intro to Machine Learning [[#How Models Work []] [[#Basic Data Exploration []] [[#Your First Machine Learning Model []] [[#Model Validation []] [[#Underfitting and Overfitting []] [[#Random Forests []] 참조 www.kaggle.com/code/dansbecker/how-models-work www.kaggle.com/code/dansbecker/basi..."/><meta property="twitter:domain" content="quartz.jzhao.xyz"/><meta property="og:url" content="https://quartz.jzhao.xyz/Notion/DB/DB-Blog-Post/Kaggle---Intro-to-Machine-Learning-번역"/><meta property="twitter:url" content="https://quartz.jzhao.xyz/Notion/DB/DB-Blog-Post/Kaggle---Intro-to-Machine-Learning-번역"/><link rel="icon" href="../../../static/icon.png"/><meta name="description" content="참조 Kaggle - Intro to Machine Learning [[#How Models Work []] [[#Basic Data Exploration []] [[#Your First Machine Learning Model []] [[#Model Validation []] [[#Underfitting and Overfitting []] [[#Random Forests []] 참조 www.kaggle.com/code/dansbecker/how-models-work www.kaggle.com/code/dansbecker/basi..."/><meta name="generator" content="Quartz"/><link href="../../../index.css" rel="stylesheet" type="text/css" spa-preserve/><style>.expand-button {
  position: absolute;
  display: flex;
  float: right;
  padding: 0.4rem;
  margin: 0.3rem;
  right: 0;
  color: var(--gray);
  border-color: var(--dark);
  background-color: var(--light);
  border: 1px solid;
  border-radius: 5px;
  opacity: 0;
  transition: 0.2s;
}
.expand-button > svg {
  fill: var(--light);
  filter: contrast(0.3);
}
.expand-button:hover {
  cursor: pointer;
  border-color: var(--secondary);
}
.expand-button:focus {
  outline: 0;
}

pre:hover > .expand-button {
  opacity: 1;
  transition: 0.2s;
}

#mermaid-container {
  position: fixed;
  contain: layout;
  z-index: 999;
  left: 0;
  top: 0;
  width: 100vw;
  height: 100vh;
  overflow: hidden;
  display: none;
  backdrop-filter: blur(4px);
  background: rgba(0, 0, 0, 0.5);
}
#mermaid-container.active {
  display: inline-block;
}
#mermaid-container > #mermaid-space {
  border: 1px solid var(--lightgray);
  background-color: var(--light);
  border-radius: 5px;
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  height: 80vh;
  width: 80vw;
  overflow: hidden;
}
#mermaid-container > #mermaid-space > .mermaid-content {
  padding: 2rem;
  position: relative;
  transform-origin: 0 0;
  transition: transform 0.1s ease;
  overflow: visible;
  min-height: 200px;
  min-width: 200px;
}
#mermaid-container > #mermaid-space > .mermaid-content pre {
  margin: 0;
  border: none;
}
#mermaid-container > #mermaid-space > .mermaid-content svg {
  max-width: none;
  height: auto;
}
#mermaid-container > #mermaid-space > .mermaid-controls {
  position: absolute;
  bottom: 20px;
  right: 20px;
  display: flex;
  gap: 8px;
  padding: 8px;
  background: var(--light);
  border: 1px solid var(--lightgray);
  border-radius: 6px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  z-index: 2;
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 32px;
  height: 32px;
  padding: 0;
  border: 1px solid var(--lightgray);
  background: var(--light);
  color: var(--dark);
  border-radius: 4px;
  cursor: pointer;
  font-size: 16px;
  font-family: var(--bodyFont);
  transition: all 0.2s ease;
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:hover {
  background: var(--lightgray);
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:active {
  transform: translateY(1px);
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:nth-child(2) {
  width: auto;
  padding: 0 12px;
  font-size: 14px;
}
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJzb3VyY2VSb290IjoiL2hvbWUvcnVubmVyL3dvcmsvdmF1bHQuaHllb25nc2Vvay1raW0vdmF1bHQuaHllb25nc2Vvay1raW0vcXVhcnR6L3F1YXJ0ei9jb21wb25lbnRzL3N0eWxlcyIsInNvdXJjZXMiOlsibWVybWFpZC5pbmxpbmUuc2NzcyJdLCJuYW1lcyI6W10sIm1hcHBpbmdzIjoiQUFBQTtFQUNFO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBOztBQUVBO0VBQ0U7RUFDQTs7QUFHRjtFQUNFO0VBQ0E7O0FBR0Y7RUFDRTs7O0FBS0Y7RUFDRTtFQUNBOzs7QUFJSjtFQUNFO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7O0FBRUE7RUFDRTs7QUFHRjtFQUNFO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBOztBQUVBO0VBQ0U7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7O0FBRUE7RUFDRTtFQUNBOztBQUdGO0VBQ0U7RUFDQTs7QUFJSjtFQUNFO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7O0FBRUE7RUFDRTtFQUNBO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBO0VBQ0E7RUFDQTtFQUNBOztBQUVBO0VBQ0U7O0FBR0Y7RUFDRTs7QUFJRjtFQUNFO0VBQ0E7RUFDQSIsInNvdXJjZXNDb250ZW50IjpbIi5leHBhbmQtYnV0dG9uIHtcbiAgcG9zaXRpb246IGFic29sdXRlO1xuICBkaXNwbGF5OiBmbGV4O1xuICBmbG9hdDogcmlnaHQ7XG4gIHBhZGRpbmc6IDAuNHJlbTtcbiAgbWFyZ2luOiAwLjNyZW07XG4gIHJpZ2h0OiAwOyAvLyBOT1RFOiByaWdodCB3aWxsIGJlIHNldCBpbiBtZXJtYWlkLmlubGluZS50c1xuICBjb2xvcjogdmFyKC0tZ3JheSk7XG4gIGJvcmRlci1jb2xvcjogdmFyKC0tZGFyayk7XG4gIGJhY2tncm91bmQtY29sb3I6IHZhcigtLWxpZ2h0KTtcbiAgYm9yZGVyOiAxcHggc29saWQ7XG4gIGJvcmRlci1yYWRpdXM6IDVweDtcbiAgb3BhY2l0eTogMDtcbiAgdHJhbnNpdGlvbjogMC4ycztcblxuICAmID4gc3ZnIHtcbiAgICBmaWxsOiB2YXIoLS1saWdodCk7XG4gICAgZmlsdGVyOiBjb250cmFzdCgwLjMpO1xuICB9XG5cbiAgJjpob3ZlciB7XG4gICAgY3Vyc29yOiBwb2ludGVyO1xuICAgIGJvcmRlci1jb2xvcjogdmFyKC0tc2Vjb25kYXJ5KTtcbiAgfVxuXG4gICY6Zm9jdXMge1xuICAgIG91dGxpbmU6IDA7XG4gIH1cbn1cblxucHJlIHtcbiAgJjpob3ZlciA+IC5leHBhbmQtYnV0dG9uIHtcbiAgICBvcGFjaXR5OiAxO1xuICAgIHRyYW5zaXRpb246IDAuMnM7XG4gIH1cbn1cblxuI21lcm1haWQtY29udGFpbmVyIHtcbiAgcG9zaXRpb246IGZpeGVkO1xuICBjb250YWluOiBsYXlvdXQ7XG4gIHotaW5kZXg6IDk5OTtcbiAgbGVmdDogMDtcbiAgdG9wOiAwO1xuICB3aWR0aDogMTAwdnc7XG4gIGhlaWdodDogMTAwdmg7XG4gIG92ZXJmbG93OiBoaWRkZW47XG4gIGRpc3BsYXk6IG5vbmU7XG4gIGJhY2tkcm9wLWZpbHRlcjogYmx1cig0cHgpO1xuICBiYWNrZ3JvdW5kOiByZ2JhKDAsIDAsIDAsIDAuNSk7XG5cbiAgJi5hY3RpdmUge1xuICAgIGRpc3BsYXk6IGlubGluZS1ibG9jaztcbiAgfVxuXG4gICYgPiAjbWVybWFpZC1zcGFjZSB7XG4gICAgYm9yZGVyOiAxcHggc29saWQgdmFyKC0tbGlnaHRncmF5KTtcbiAgICBiYWNrZ3JvdW5kLWNvbG9yOiB2YXIoLS1saWdodCk7XG4gICAgYm9yZGVyLXJhZGl1czogNXB4O1xuICAgIHBvc2l0aW9uOiBmaXhlZDtcbiAgICB0b3A6IDUwJTtcbiAgICBsZWZ0OiA1MCU7XG4gICAgdHJhbnNmb3JtOiB0cmFuc2xhdGUoLTUwJSwgLTUwJSk7XG4gICAgaGVpZ2h0OiA4MHZoO1xuICAgIHdpZHRoOiA4MHZ3O1xuICAgIG92ZXJmbG93OiBoaWRkZW47XG5cbiAgICAmID4gLm1lcm1haWQtY29udGVudCB7XG4gICAgICBwYWRkaW5nOiAycmVtO1xuICAgICAgcG9zaXRpb246IHJlbGF0aXZlO1xuICAgICAgdHJhbnNmb3JtLW9yaWdpbjogMCAwO1xuICAgICAgdHJhbnNpdGlvbjogdHJhbnNmb3JtIDAuMXMgZWFzZTtcbiAgICAgIG92ZXJmbG93OiB2aXNpYmxlO1xuICAgICAgbWluLWhlaWdodDogMjAwcHg7XG4gICAgICBtaW4td2lkdGg6IDIwMHB4O1xuXG4gICAgICBwcmUge1xuICAgICAgICBtYXJnaW46IDA7XG4gICAgICAgIGJvcmRlcjogbm9uZTtcbiAgICAgIH1cblxuICAgICAgc3ZnIHtcbiAgICAgICAgbWF4LXdpZHRoOiBub25lO1xuICAgICAgICBoZWlnaHQ6IGF1dG87XG4gICAgICB9XG4gICAgfVxuXG4gICAgJiA+IC5tZXJtYWlkLWNvbnRyb2xzIHtcbiAgICAgIHBvc2l0aW9uOiBhYnNvbHV0ZTtcbiAgICAgIGJvdHRvbTogMjBweDtcbiAgICAgIHJpZ2h0OiAyMHB4O1xuICAgICAgZGlzcGxheTogZmxleDtcbiAgICAgIGdhcDogOHB4O1xuICAgICAgcGFkZGluZzogOHB4O1xuICAgICAgYmFja2dyb3VuZDogdmFyKC0tbGlnaHQpO1xuICAgICAgYm9yZGVyOiAxcHggc29saWQgdmFyKC0tbGlnaHRncmF5KTtcbiAgICAgIGJvcmRlci1yYWRpdXM6IDZweDtcbiAgICAgIGJveC1zaGFkb3c6IDAgMnB4IDRweCByZ2JhKDAsIDAsIDAsIDAuMSk7XG4gICAgICB6LWluZGV4OiAyO1xuXG4gICAgICAubWVybWFpZC1jb250cm9sLWJ1dHRvbiB7XG4gICAgICAgIGRpc3BsYXk6IGZsZXg7XG4gICAgICAgIGFsaWduLWl0ZW1zOiBjZW50ZXI7XG4gICAgICAgIGp1c3RpZnktY29udGVudDogY2VudGVyO1xuICAgICAgICB3aWR0aDogMzJweDtcbiAgICAgICAgaGVpZ2h0OiAzMnB4O1xuICAgICAgICBwYWRkaW5nOiAwO1xuICAgICAgICBib3JkZXI6IDFweCBzb2xpZCB2YXIoLS1saWdodGdyYXkpO1xuICAgICAgICBiYWNrZ3JvdW5kOiB2YXIoLS1saWdodCk7XG4gICAgICAgIGNvbG9yOiB2YXIoLS1kYXJrKTtcbiAgICAgICAgYm9yZGVyLXJhZGl1czogNHB4O1xuICAgICAgICBjdXJzb3I6IHBvaW50ZXI7XG4gICAgICAgIGZvbnQtc2l6ZTogMTZweDtcbiAgICAgICAgZm9udC1mYW1pbHk6IHZhcigtLWJvZHlGb250KTtcbiAgICAgICAgdHJhbnNpdGlvbjogYWxsIDAuMnMgZWFzZTtcblxuICAgICAgICAmOmhvdmVyIHtcbiAgICAgICAgICBiYWNrZ3JvdW5kOiB2YXIoLS1saWdodGdyYXkpO1xuICAgICAgICB9XG5cbiAgICAgICAgJjphY3RpdmUge1xuICAgICAgICAgIHRyYW5zZm9ybTogdHJhbnNsYXRlWSgxcHgpO1xuICAgICAgICB9XG5cbiAgICAgICAgLy8gU3R5bGUgdGhlIHJlc2V0IGJ1dHRvbiBkaWZmZXJlbnRseVxuICAgICAgICAmOm50aC1jaGlsZCgyKSB7XG4gICAgICAgICAgd2lkdGg6IGF1dG87XG4gICAgICAgICAgcGFkZGluZzogMCAxMnB4O1xuICAgICAgICAgIGZvbnQtc2l6ZTogMTRweDtcbiAgICAgICAgfVxuICAgICAgfVxuICAgIH1cbiAgfVxufVxuIl19 */</style><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../../../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../../../static/contentIndex.json").then(data => data.json())</script><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="https://quartz.jzhao.xyz/index.xml"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image" content="https://quartz.jzhao.xyz/Notion/DB/DB-Blog-Post/Kaggle---Intro-to-Machine-Learning-번역-og-image.webp"/><meta property="og:image:url" content="https://quartz.jzhao.xyz/Notion/DB/DB-Blog-Post/Kaggle---Intro-to-Machine-Learning-번역-og-image.webp"/><meta name="twitter:image" content="https://quartz.jzhao.xyz/Notion/DB/DB-Blog-Post/Kaggle---Intro-to-Machine-Learning-번역-og-image.webp"/><meta property="og:image:type" content="image/.webp"/></head><body data-slug="Notion/DB/DB-Blog-Post/Kaggle---Intro-to-Machine-Learning-번역"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href="../../..">HyeongSeok Kim's Vault</a></h2><div class="spacer mobile-only"></div><div class="flex-component" style="flex-direction: row; flex-wrap: nowrap; gap: 1rem;"><div style="flex-grow: 1; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><div class="search"><button class="search-button"><p>Search</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div class="search-container"><div class="search-space"><input autocomplete="off" class="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div class="search-layout" data-preview="true"></div></div></div></div></div><div style="flex-grow: 0; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><button class="darkmode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve" aria-label="Dark mode"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve" aria-label="Light mode"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></button></div><div style="flex-grow: 0; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><button class="readermode"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" class="readerIcon" fill="currentColor" stroke="currentColor" stroke-width="0.2" stroke-linecap="round" stroke-linejoin="round" width="64px" height="64px" viewBox="0 0 24 24" aria-label="Reader mode"><title>Reader mode</title><g transform="translate(-1.8, -1.8) scale(1.15, 1.2)"><path d="M8.9891247,2.5 C10.1384702,2.5 11.2209868,2.96705384 12.0049645,3.76669482 C12.7883914,2.96705384 13.8709081,2.5 15.0202536,2.5 L18.7549359,2.5 C19.1691495,2.5 19.5049359,2.83578644 19.5049359,3.25 L19.5046891,4.004 L21.2546891,4.00457396 C21.6343849,4.00457396 21.9481801,4.28672784 21.9978425,4.6528034 L22.0046891,4.75457396 L22.0046891,20.25 C22.0046891,20.6296958 21.7225353,20.943491 21.3564597,20.9931534 L21.2546891,21 L2.75468914,21 C2.37499337,21 2.06119817,20.7178461 2.01153575,20.3517706 L2.00468914,20.25 L2.00468914,4.75457396 C2.00468914,4.37487819 2.28684302,4.061083 2.65291858,4.01142057 L2.75468914,4.00457396 L4.50368914,4.004 L4.50444233,3.25 C4.50444233,2.87030423 4.78659621,2.55650904 5.15267177,2.50684662 L5.25444233,2.5 L8.9891247,2.5 Z M4.50368914,5.504 L3.50468914,5.504 L3.50468914,19.5 L10.9478955,19.4998273 C10.4513189,18.9207296 9.73864328,18.5588115 8.96709342,18.5065584 L8.77307039,18.5 L5.25444233,18.5 C4.87474657,18.5 4.56095137,18.2178461 4.51128895,17.8517706 L4.50444233,17.75 L4.50368914,5.504 Z M19.5049359,17.75 C19.5049359,18.1642136 19.1691495,18.5 18.7549359,18.5 L15.2363079,18.5 C14.3910149,18.5 13.5994408,18.8724714 13.0614828,19.4998273 L20.5046891,19.5 L20.5046891,5.504 L19.5046891,5.504 L19.5049359,17.75 Z M18.0059359,3.999 L15.0202536,4 L14.8259077,4.00692283 C13.9889509,4.06666544 13.2254227,4.50975805 12.7549359,5.212 L12.7549359,17.777 L12.7782651,17.7601316 C13.4923805,17.2719483 14.3447024,17 15.2363079,17 L18.0059359,16.999 L18.0056891,4.798 L18.0033792,4.75457396 L18.0056891,4.71 L18.0059359,3.999 Z M8.9891247,4 L6.00368914,3.999 L6.00599909,4.75457396 L6.00599909,4.75457396 L6.00368914,4.783 L6.00368914,16.999 L8.77307039,17 C9.57551536,17 10.3461406,17.2202781 11.0128313,17.6202194 L11.2536891,17.776 L11.2536891,5.211 C10.8200889,4.56369974 10.1361548,4.13636104 9.37521067,4.02745763 L9.18347055,4.00692283 L8.9891247,4 Z"></path></g></svg></button></div></div><div class="explorer" data-behavior="link" data-collapsed="collapsed" data-savestate="true" data-data-fns="{&quot;order&quot;:[&quot;filter&quot;,&quot;map&quot;,&quot;sort&quot;],&quot;sortFn&quot;:&quot;(a,b)=>!a.isFolder&amp;&amp;!b.isFolder||a.isFolder&amp;&amp;b.isFolder?a.displayName.localeCompare(b.displayName,void 0,{numeric:!0,sensitivity:\&quot;base\&quot;}):!a.isFolder&amp;&amp;b.isFolder?1:-1&quot;,&quot;filterFn&quot;:&quot;node=>node.slugSegment!==\&quot;tags\&quot;&quot;,&quot;mapFn&quot;:&quot;node=>node&quot;}"><button type="button" class="explorer-toggle mobile-explorer hide-until-loaded" data-mobile="true" aria-controls="explorer-content"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-menu"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg></button><button type="button" class="title-button explorer-toggle desktop-explorer" data-mobile="false" aria-expanded="true"><h2>Explorer</h2><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div class="explorer-content" aria-expanded="false"><ul class="explorer-ul overflow" id="list-0"><li class="overflow-end"></li></ul></div><template id="template-file"><li><a href="#"></a></li></template><template id="template-folder"><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div><button class="folder-button"><span class="folder-title"></span></button></div></div><div class="folder-outer"><ul class="content"></ul></div></li></template></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../../../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../Notion/">Notion</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../Notion/DB/">DB</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../../Notion/DB/DB-Blog-Post/">DB Blog Post</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Kaggle   Intro to Machine Learning 번역</a></div></nav><h1 class="article-title">Kaggle - Intro to Machine Learning 번역</h1><p show-comma="true" class="content-meta"><time datetime="2025-06-17T02:23:14.289Z">Jun 17, 2025</time><span>34 min read</span></p></div></div><article class="popover-hint"><ul>
<li><a href="#%EC%B0%B8%EC%A1%B0" class="internal alias">참조</a></li>
<li><a href="#kaggle---intro-to-machine-learning" class="internal alias">Kaggle - Intro to Machine Learning</a>
<ul>
<li>[[#How Models Work []]</li>
<li>[[#Basic Data Exploration []]</li>
<li>[[#Your First Machine Learning Model []]</li>
<li>[[#Model Validation []]</li>
<li>[[#Underfitting and Overfitting []]</li>
<li>[[#Random Forests []]</li>
</ul>
</li>
</ul>
<hr/>
<h1 id="참조">참조<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#참조" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p><a href="https://www.kaggle.com/code/dansbecker/how-models-work" class="external">https://www.kaggle.com/code/dansbecker/how-models-work<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p><a href="https://www.kaggle.com/code/dansbecker/basic-data-exploration" class="external">https://www.kaggle.com/code/dansbecker/basic-data-exploration<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a><a href="https://www.kaggle.com/code/dansbecker/your-first-machine-learning-model" class="external">https://www.kaggle.com/code/dansbecker/your-first-machine-learning-model<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p><a href="https://www.kaggle.com/code/dansbecker/model-validation" class="external">https://www.kaggle.com/code/dansbecker/model-validation<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p><a href="https://www.kaggle.com/code/dansbecker/underfitting-and-overfitting" class="external">https://www.kaggle.com/code/dansbecker/underfitting-and-overfitting<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p><a href="https://www.kaggle.com/code/dansbecker/random-forests" class="external">https://www.kaggle.com/code/dansbecker/random-forests<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<h1 id="kaggle---intro-to-machine-learning">Kaggle - Intro to Machine Learning<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#kaggle---intro-to-machine-learning" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<h2 id="how-models-work-link">How Models Work [link]<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#how-models-work-link" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h1 id="introduction"><strong>Introduction</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#introduction" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>기계 학습 모델의 작동 방식과 사용 방법에 대한 개요부터 시작하겠습니다. 이전에 통계 모델링이나 머신 러닝을 해본 적이 있다면 기본적으로 느껴질 수 있습니다. 걱정하지 마십시오. 곧 강력한 모델을 구축할 것입니다.</p>
<p>이 과정에서는 다음 시나리오를 진행하면서 모델을 구축하게 됩니다.</p>
<p>당신의 사촌은 부동산 투기로 수백만 달러를 벌었습니다. 데이터 과학에 대한 귀하의 관심 때문에 그는 귀하와 비즈니스 파트너가 되겠다는 제안을 받았습니다. 그는 돈을 공급할 것이고 당신은 다양한 주택의 가치를 예측하는 모델을 제공할 것입니다.</p>
<p>당신은 당신의 사촌에게 그가 과거에 부동산 가치를 어떻게 예측했는지 물었고 그는 단지 직감일 뿐이라고 말했습니다. 그러나 더 많은 질문은 그가 과거에 본 주택에서 가격 패턴을 식별했으며 이러한 패턴을 사용하여 그가 고려 중인 새 주택에 대한 예측을 한다는 것을 보여줍니다.</p>
<p>기계 학습은 동일한 방식으로 작동합니다. 의사 결정 트리라는 모델로 시작하겠습니다. 더 정확한 예측을 제공하는 더 멋진 모델이 있습니다. 그러나 의사 결정 트리는 이해하기 쉽고 데이터 과학에서 일부 최고의 모델을 위한 기본 빌딩 블록입니다.</p>
<p>단순화를 위해 가능한 가장 간단한 의사 결정 트리부터 시작하겠습니다.</p>
<p><a href="http://i.imgur.com/7tsb5b1.png" class="external"><img src="http://i.imgur.com/7tsb5b1.png" alt/><svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p>주택을 두 가지 범주로만 나눕니다. 고려 중인 모든 주택의 예상 가격은 같은 범주에 있는 주택의 과거 평균 가격입니다.</p>
<p>우리는 데이터를 사용하여 주택을 두 그룹으로 나누는 방법을 결정한 다음 다시 각 그룹의 예상 가격을 결정합니다. 데이터에서 패턴을 캡처하는 이 단계를 <strong>피팅</strong> 또는 <strong>훈련</strong> 모델이라고 합니다. 모델을 <strong>적합</strong>하는 데 사용되는 데이터를 <strong>학습 데이터</strong>라고 합니다.</p>
<p>모델이 어떻게 적합했는지에 대한 세부 사항(예: 데이터 분할 방법)은 나중에 저장하기 위해 충분히 복잡합니다. 모델이 적합해지면 새로운 데이터에 적용하여 추가 주택의 <strong>예측</strong> 가격을 산출할 수 있습니다.</p>
<h1 id="improving-the-decision-tree"><strong>Improving the Decision Tree</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#improving-the-decision-tree" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>다음 두 의사결정 트리 중 어느 것이 부동산 교육 데이터를 피팅한 결과일 가능성이 더 높습니까?</p>
<p><a href="http://i.imgur.com/prAjgku.png" class="external"><img src="http://i.imgur.com/prAjgku.png" alt/><svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p>왼쪽의 결정 트리(결정 트리 1)는 침실이 더 많은 주택이 침실이 더 적은 주택보다 더 높은 가격에 판매되는 경향이 있다는 현실을 포착하기 때문에 아마도 더 의미가 있을 것입니다. 이 모델의 가장 큰 단점은 욕실 수, 부지 크기, 위치 등과 같이 주택 가격에 영향을 미치는 대부분의 요소를 포착하지 못한다는 것입니다.</p>
<p>더 많은 “분할”이 있는 트리를 사용하여 더 많은 요인을 캡처할 수 있습니다. 이를 “더 깊은” 트리라고 합니다. 각 주택 부지의 전체 크기도 고려하는 의사 결정 트리는 다음과 같습니다.</p>
<p><a href="http://i.imgur.com/R3ywQsR.png" class="external"><img src="http://i.imgur.com/R3ywQsR.png" alt/><svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p>의사 결정 트리를 추적하고 항상 해당 주택의 특성에 해당하는 경로를 선택하여 주택 가격을 예측합니다. 집의 예상 가격은 트리 맨 아래에 있습니다. 하단에서 예측을 수행하는 지점을 <strong>리프</strong>라고 합니다.</p>
<p>리프의 분할 및 값은 데이터에 의해 결정되므로 작업할 데이터를 확인해야 합니다.</p>
<h2 id="basic-data-exploration-link">Basic Data Exploration [link]<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#basic-data-exploration-link" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h1 id="using-pandas-to-get-familiar-with-your-data"><strong>Using Pandas to Get Familiar With Your Data</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#using-pandas-to-get-familiar-with-your-data" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>기계 학습 프로젝트의 첫 번째 단계는 데이터에 익숙해지는 것입니다. 이를 위해 Pandas 라이브러리를 사용합니다. Pandas는 데이터 과학자가 데이터를 탐색하고 조작하는 데 사용하는 기본 도구입니다. 대부분의 사람들은 코드에서 팬더를 pd로 축약합니다. 우리는 명령으로 이것을합니다.</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>import pandas as pd</span></span></code></pre></figure>
<p>Pandas 라이브러리의 가장 중요한 부분은 DataFrame입니다. DataFrame은 테이블로 생각할 수 있는 데이터 유형을 보유합니다. 이는 Excel의 시트나 SQL 데이터베이스의 테이블과 비슷합니다.</p>
<p>Pandas에는 이러한 유형의 데이터로 수행하려는 대부분의 작업에 대한 강력한 방법이 있습니다.</p>
<p>예를 들어 호주 멜버른의 <a href="https://www.kaggle.com/dansbecker/melbourne-housing-snapshot" class="external">주택 가격에 대한 데이터<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>를 살펴보겠습니다. 실습에서는 아이오와의 주택 가격이 있는 새 데이터 세트에 동일한 프로세스를 적용합니다.</p>
<p>예제(멜버른) 데이터는 <code>**../input/melbourne-housing-snapshot/melb_data.csv**</code> 파일 경로에 있습니다.</p>
<p>다음 명령을 사용하여 데이터를 로드하고 탐색합니다.</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span># save filepath to variable for easier access</span></span>
<span data-line><span>melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'</span></span>
<span data-line><span># read the data and store data in DataFrame titled melbourne_data</span></span>
<span data-line><span>melbourne_data = pd.read_csv(melbourne_file_path) </span></span>
<span data-line><span># print a summary of the data in Melbourne data</span></span>
<span data-line><span>melbourne_data.describe()</span></span></code></pre></figure>
<p>Out[2]:</p>





































































































































































<div class="table-container"><table><thead><tr><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td></td><td>Rooms</td><td>Price</td><td>Distance</td><td>Postcode</td><td>Bedroom2</td><td>Bathroom</td><td>Car</td><td>Landsize</td><td>BuildingArea</td><td>YearBuilt</td><td>Lattitude</td><td>Longtitude</td><td>Propertycount</td></tr><tr><td>count</td><td>13580.000000</td><td>1.358000e+04</td><td>13580.000000</td><td>13580.000000</td><td>13580.000000</td><td>13580.000000</td><td>13518.000000</td><td>13580.000000</td><td>7130.000000</td><td>8205.000000</td><td>13580.000000</td><td>13580.000000</td><td>13580.000000</td></tr><tr><td>mean</td><td>2.937997</td><td>1.075684e+06</td><td>10.137776</td><td>3105.301915</td><td>2.914728</td><td>1.534242</td><td>1.610075</td><td>558.416127</td><td>151.967650</td><td>1964.684217</td><td>-37.809203</td><td>144.995216</td><td>7454.417378</td></tr><tr><td>std</td><td>0.955748</td><td>6.393107e+05</td><td>5.868725</td><td>90.676964</td><td>0.965921</td><td>0.691712</td><td>0.962634</td><td>3990.669241</td><td>541.014538</td><td>37.273762</td><td>0.079260</td><td>0.103916</td><td>4378.581772</td></tr><tr><td>min</td><td>1.000000</td><td>8.500000e+04</td><td>0.000000</td><td>3000.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>0.000000</td><td>1196.000000</td><td>-38.182550</td><td>144.431810</td><td>249.000000</td></tr><tr><td>25%</td><td>2.000000</td><td>6.500000e+05</td><td>6.100000</td><td>3044.000000</td><td>2.000000</td><td>1.000000</td><td>1.000000</td><td>177.000000</td><td>93.000000</td><td>1940.000000</td><td>-37.856822</td><td>144.929600</td><td>4380.000000</td></tr><tr><td>50%</td><td>3.000000</td><td>9.030000e+05</td><td>9.200000</td><td>3084.000000</td><td>3.000000</td><td>1.000000</td><td>2.000000</td><td>440.000000</td><td>126.000000</td><td>1970.000000</td><td>-37.802355</td><td>145.000100</td><td>6555.000000</td></tr><tr><td>75%</td><td>3.000000</td><td>1.330000e+06</td><td>13.000000</td><td>3148.000000</td><td>3.000000</td><td>2.000000</td><td>2.000000</td><td>651.000000</td><td>174.000000</td><td>1999.000000</td><td>-37.756400</td><td>145.058305</td><td>10331.000000</td></tr><tr><td>max</td><td>10.000000</td><td>9.000000e+06</td><td>48.100000</td><td>3977.000000</td><td>20.000000</td><td>8.000000</td><td>10.000000</td><td>433014.000000</td><td>44515.000000</td><td>2018.000000</td><td>-37.408530</td><td>145.526350</td><td>21650.000000</td></tr></tbody></table></div>
<h1 id="interpreting-data-description"><strong>Interpreting Data Description</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#interpreting-data-description" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>결과에는 원본 데이터 세트의 각 열에 대해 8개의 숫자가 표시됩니다. 첫 번째 숫자인 <strong>개수</strong>는 누락되지 않은 값이 있는 행 수를 보여줍니다.</p>
<p>누락된 값은 여러 가지 이유로 발생합니다. 예를 들어 침실이 1개인 집을 측량할 때 침실 2의 크기는 수집되지 않습니다. 누락된 데이터 주제로 다시 돌아오겠습니다.</p>
<p>두 번째 값은 평균인 <strong>평균</strong>입니다. 그 아래 <strong>std</strong>는 값이 수치적으로 얼마나 퍼져 있는지를 측정하는 표준 편차입니다.</p>
<p><strong>min</strong>, <strong>25%</strong>, <strong>50%</strong>, <strong>75%</strong> 및 <strong>max</strong> 값을 해석하려면 각 열을 최저값에서 최고값으로 정렬한다고 상상해 보세요. 첫 번째(가장 작은) 값은 최소값입니다. 목록을 4분의 1로 이동하면 값의 25%보다 크고 값의 75%보다 작은 숫자를 찾을 수 있습니다. 이것이 <strong>25%</strong> 값(‘25번째 백분위수’라고 발음함)입니다. 50번째 및 75번째 백분위수는 유사하게 정의되며 <strong>최대</strong>는 가장 큰 숫자입니다.</p>
<p><strong>(Exercise: Explore Your Data)</strong></p>
<h2 id="your-first-machine-learning-model-link">Your First Machine Learning Model [link]<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#your-first-machine-learning-model-link" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h1 id="selecting-data-for-modeling"><strong>Selecting Data for Modeling</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#selecting-data-for-modeling" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>데이터 세트에 변수가 너무 많아 머리를 감싸거나 멋지게 인쇄할 수 없었습니다. 이 엄청난 양의 데이터를 이해할 수 있는 것으로 어떻게 줄일 수 있습니까?</p>
<p>직관을 사용하여 몇 가지 변수를 선택하여 시작하겠습니다. 이후 과정에서는 변수의 우선 순위를 자동으로 지정하는 통계 기술을 보여줍니다.</p>
<p>변수/열을 선택하려면 데이터 세트의 모든 열 목록을 확인해야 합니다. 이는 DataFrame의 <strong>columns</strong> 속성으로 수행됩니다(아래 코드의 맨 아래 줄).</p>
<p>In [1]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>import pandas as pd</span></span>
<span data-line><span>melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'</span></span>
<span data-line><span>melbourne_data = pd.read_csv(melbourne_file_path) </span></span>
<span data-line><span>melbourne_data.columns</span></span></code></pre></figure>
<p>Out[1]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>`Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',</span></span>
<span data-line><span>       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',</span></span>
<span data-line><span>       'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',</span></span>
<span data-line><span>       'Longtitude', 'Regionname', 'Propertycount'],</span></span>
<span data-line><span>      dtype='object')`</span></span></code></pre></figure>
<p>In [2]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span># The Melbourne data has some missing values (some houses for which some variables weren't recorded.)</span></span>
<span data-line><span># We'll learn to handle missing values in a later tutorial.  </span></span>
<span data-line><span># Your Iowa data doesn't have missing values in the columns you use. </span></span>
<span data-line><span># So we will take the simplest option for now, and drop houses from our data. </span></span>
<span data-line><span># Don't worry about this much for now, though the code is:</span></span>
<span data-line> </span>
<span data-line><span># dropna drops missing values (think of na as &quot;not available&quot;)</span></span>
<span data-line><span>melbourne_data = melbourne_data.dropna(axis=0)</span></span></code></pre></figure>
<p>데이터의 하위 집합을 선택하는 방법에는 여러 가지가 있습니다. <a href="https://www.kaggle.com/learn/pandas" class="external">Pandas 과정<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>에서 이를 자세히 다루지만 지금은 두 가지 접근 방식에 중점을 둘 것입니다.</p>
<ol>
<li>“예측 대상”을 선택하는 데 사용하는 점 표기법</li>
<li>“기능”을 선택하는 데 사용하는 열 목록으로 선택</li>
</ol>
<h2 id="selecting-the-prediction-target"><strong>Selecting The Prediction Target</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#selecting-the-prediction-target" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p><strong>점 표기법</strong>으로 변수를 꺼낼 수 있습니다. 이 단일 열은 <strong>시리즈</strong>에 저장되며, 이는 단일 데이터 열만 있는 DataFrame과 대체로 유사합니다.</p>
<p>점 표기법을 사용하여 <strong>예측 대상</strong>이라고 하는 예측하려는 열을 선택합니다. 규칙에 따라 예측 대상은 <strong>y</strong>라고 합니다.</p>
<p>멜버른 데이터에 집값을 저장하는 데 필요한 코드는 다음과 같습니다.</p>
<p>In [3]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>y = melbourne_data.Price</span></span></code></pre></figure>
<h1 id="choosing-features"><strong>Choosing “Features”</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#choosing-features" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>모델에 입력되고 나중에 예측에 사용되는 열을 “특성”이라고 합니다. 이 경우에는 주택 가격을 결정하는 데 사용되는 열이 됩니다. 경우에 따라 대상을 제외한 모든 열을 기능으로 사용합니다. 다른 경우에는 더 적은 기능으로 더 나을 것입니다.</p>
<p>지금은 몇 가지 기능만 있는 모델을 빌드합니다. 나중에 다른 기능으로 빌드된 모델을 반복하고 비교하는 방법을 볼 수 있습니다.</p>
<p>대괄호 안에 열 이름 목록을 제공하여 여러 기능을 선택합니다. 해당 목록의 각 항목은 문자열(따옴표 포함)이어야 합니다.</p>
<p>다음은 예입니다.</p>
<p>In [4]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']</span></span></code></pre></figure>
<p>관례적으로 이 데이터를 X라고 합니다.</p>
<p>In [5]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>X = melbourne_data[melbourne_features]</span></span></code></pre></figure>
<p>상위 몇 행을 표시하는 describe 방법과 head 방법을 사용하여 주택 가격을 예측하는 데 사용할 데이터를 빠르게 검토해 보겠습니다.</p>
<p>In [6]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>X.describe()</span></span></code></pre></figure>
<p>Out[6]:</p>





















































































<div class="table-container"><table><thead><tr><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td></td><td>Rooms</td><td>Bathroom</td><td>Landsize</td><td>Lattitude</td><td>Longtitude</td></tr><tr><td>count</td><td>6196.000000</td><td>6196.000000</td><td>6196.000000</td><td>6196.000000</td><td>6196.000000</td></tr><tr><td>mean</td><td>2.931407</td><td>1.576340</td><td>471.006940</td><td>-37.807904</td><td>144.990201</td></tr><tr><td>std</td><td>0.971079</td><td>0.711362</td><td>897.449881</td><td>0.075850</td><td>0.099165</td></tr><tr><td>min</td><td>1.000000</td><td>1.000000</td><td>0.000000</td><td>-38.164920</td><td>144.542370</td></tr><tr><td>25%</td><td>2.000000</td><td>1.000000</td><td>152.000000</td><td>-37.855438</td><td>144.926198</td></tr><tr><td>50%</td><td>3.000000</td><td>1.000000</td><td>373.000000</td><td>-37.802250</td><td>144.995800</td></tr><tr><td>75%</td><td>4.000000</td><td>2.000000</td><td>628.000000</td><td>-37.758200</td><td>145.052700</td></tr><tr><td>max</td><td>8.000000</td><td>8.000000</td><td>37000.000000</td><td>-37.457090</td><td>145.526350</td></tr></tbody></table></div>
<p>In [7]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>X.head()</span></span></code></pre></figure>
<p>Out[7]:</p>





























































<div class="table-container"><table><thead><tr><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td></td><td>Rooms</td><td>Bathroom</td><td>Landsize</td><td>Lattitude</td><td>Longtitude</td></tr><tr><td>1</td><td>2</td><td>1.0</td><td>156.0</td><td>-37.8079</td><td>144.9934</td></tr><tr><td>2</td><td>3</td><td>2.0</td><td>134.0</td><td>-37.8093</td><td>144.9944</td></tr><tr><td>4</td><td>4</td><td>1.0</td><td>120.0</td><td>-37.8072</td><td>144.9941</td></tr><tr><td>6</td><td>3</td><td>2.0</td><td>245.0</td><td>-37.8024</td><td>144.9993</td></tr><tr><td>7</td><td>2</td><td>1.0</td><td>256.0</td><td>-37.8060</td><td>144.9954</td></tr></tbody></table></div>
<p>이러한 명령으로 데이터를 시각적으로 확인하는 것은 데이터 과학자의 업무에서 중요한 부분입니다. 데이터 세트에서 추가 검사가 필요한 놀라움을 자주 발견하게 될 것입니다.</p>
<hr/>
<h1 id="building-your-model"><strong>Building Your Model</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#building-your-model" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p><strong>scikit-learn</strong> 라이브러리를 사용하여 모델을 생성합니다. 코딩 시 이 라이브러리는 샘플 코드에서 볼 수 있듯이 <strong>sklearn</strong>으로 작성됩니다. Scikit-learn은 일반적으로 DataFrames에 저장되는 데이터 유형을 모델링하기 위한 가장 인기 있는 라이브러리입니다.</p>
<p>모델을 구축하고 사용하는 단계는 다음과 같습니다.</p>
<ul>
<li><strong>정의:</strong> 어떤 유형의 모델이 될까요? 의사 결정 트리? 다른 유형의 모델? 모델 유형의 일부 다른 매개변수도 지정됩니다.</li>
<li><strong>Fit:</strong> 제공된 데이터에서 패턴을 캡처합니다. 이것이 모델링의 핵심입니다.</li>
<li><strong>예측:</strong> 소리 그대로</li>
<li><strong>평가</strong>: 모델의 예측이 얼마나 정확한지 확인합니다.</li>
</ul>
<p>다음은 scikit-learn으로 의사 결정 트리 모델을 정의하고 기능 및 대상 변수에 피팅하는 예입니다.</p>
<p>In [8]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>from sklearn.tree import DecisionTreeRegressor</span></span>
<span data-line> </span>
<span data-line><span># Define model. Specify a number for random_state to ensure same results each run</span></span>
<span data-line><span>melbourne_model = DecisionTreeRegressor(random_state=1)</span></span>
<span data-line> </span>
<span data-line><span># Fit model</span></span>
<span data-line><span>melbourne_model.fit(X, y)</span></span></code></pre></figure>
<p>Out[8]:</p>
<p><code>DecisionTreeRegressor(random_state=1)</code></p>
<p>많은 기계 학습 모델은 모델 교육에서 임의성을 허용합니다. ‘random_state’에 숫자를 지정하면 각 실행에서 동일한 결과를 얻을 수 있습니다. 이것은 좋은 습관으로 간주됩니다. 임의의 숫자를 사용하면 선택한 값에 따라 모델 품질이 크게 달라지지 않습니다.</p>
<p>이제 예측에 사용할 수 있는 적합한 모델이 있습니다.</p>
<p>실제로는 이미 가격이 책정된 주택이 아니라 시장에 출시되는 새 주택에 대한 예측을 원할 것입니다. 하지만 학습 데이터의 처음 몇 행에 대해 예측을 수행하여 예측 기능이 어떻게 작동하는지 확인합니다.</p>
<p>In [9]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>print(&quot;Making predictions for the following 5 houses:&quot;)</span></span>
<span data-line><span>print(X.head())</span></span>
<span data-line><span>print(&quot;The predictions are&quot;)</span></span>
<span data-line><span>print(melbourne_model.predict(X.head()))</span></span></code></pre></figure>
<p><code>Making predictions for the following 5 houses: Rooms Bathroom Landsize Lattitude Longtitude 1 2 1.0 156.0 -37.8079 144.9934 2 3 2.0 134.0 -37.8093 144.9944 4 4 1.0 120.0 -37.8072 144.9941 6 3 2.0 245.0 -37.8024 144.9993 7 2 1.0 256.0 -37.8060 144.9954 The predictions are [1035000. 1465000. 1600000. 1876000. 1636000.]</code></p>
<h2 id="model-validation-link">Model Validation [link]<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#model-validation-link" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>모델을 만들었습니다. 하지만 얼마나 좋은가요?</p>
<p>이 단원에서는 모델 검증을 사용하여 모델의 품질을 측정하는 방법을 배웁니다. 모델 품질을 측정하는 것은 모델을 반복적으로 개선하는 핵심입니다.</p>
<h1 id="what-is-model-validation"><strong>What is Model Validation</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#what-is-model-validation" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>구축한 거의 모든 모델을 평가하고 싶을 것입니다. 전부는 아니지만 대부분의 애플리케이션에서 모델 품질의 관련 척도는 예측 정확도입니다. 즉, 모델의 예측이 실제로 발생하는 것과 비슷할 것입니다.</p>
<p>많은 사람들이 예측 정확도를 측정할 때 큰 실수를 합니다. 그들은 _학습 데이터_로 예측을 하고 이러한 예측을 _학습 데이터_의 목표 값과 비교합니다. 이 접근 방식의 문제와 해결 방법을 잠시 후에 볼 수 있지만 먼저 이 작업을 수행하는 방법에 대해 생각해 봅시다.</p>
<p>먼저 모델 품질을 이해할 수 있는 방식으로 요약해야 합니다. 10,000채의 주택에 대한 예상 주택 가격과 실제 주택 가격을 비교하면 좋은 예측과 나쁜 예측이 혼합되어 있음을 알 수 있습니다. 10,000개의 예측 및 실제 값 목록을 살펴보는 것은 무의미합니다. 우리는 이것을 하나의 지표로 요약해야 합니다.</p>
<p>모델 품질을 요약하는 많은 측정항목이 있지만 <strong>Mean Absolute Error</strong>(<strong>MAE</strong>라고도 함)라는 항목부터 시작하겠습니다. 마지막 단어인 오류부터 시작하여 이 메트릭을 분석해 보겠습니다.</p>
<p>각 주택의 예측 오차는 다음과 같습니다.</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Plain" data-theme="github-light github-dark"><code data-language="Plain" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>error = actual−predicted</span></span></code></pre></figure>
<p>따라서 집값이 150,000달러이고 100,000달러가 될 것이라고 예측한 경우 오류는 50,000달러입니다.</p>
<p>MAE 메트릭을 사용하여 각 오류의 절대값을 취합니다. 이렇게 하면 각 오류가 양수로 변환됩니다. 그런 다음 이러한 절대 오류의 평균을 취합니다. 이것은 모델 품질의 척도입니다. 평이한 영어로는 다음과 같이 말할 수 있습니다.</p>
<blockquote>
<p>평균적으로, X에 대한 우리의 예측은 조금씩 빗나갑니다.</p>
</blockquote>
<p>MAE를 계산하려면 먼저 모델이 필요합니다. 그것은 아래의 숨겨진 셀에 내장되어 있으며 <code>코드</code> 버튼을 클릭하여 검토할 수 있습니다.</p>
<p>In [1]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span># Data Loading Code Hidden Here</span></span>
<span data-line><span>import pandas as pd</span></span>
<span data-line> </span>
<span data-line><span># Load data</span></span>
<span data-line><span>melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'</span></span>
<span data-line><span>melbourne_data = pd.read_csv(melbourne_file_path) </span></span>
<span data-line><span># Filter rows with missing price values</span></span>
<span data-line><span>filtered_melbourne_data = melbourne_data.dropna(axis=0)</span></span>
<span data-line><span># Choose target and features</span></span>
<span data-line><span>y = filtered_melbourne_data.Price</span></span>
<span data-line><span>melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', </span></span>
<span data-line><span>                        'YearBuilt', 'Lattitude', 'Longtitude']</span></span>
<span data-line><span>X = filtered_melbourne_data[melbourne_features]</span></span>
<span data-line> </span>
<span data-line><span>from sklearn.tree import DecisionTreeRegressor</span></span>
<span data-line><span># Define model</span></span>
<span data-line><span>melbourne_model = DecisionTreeRegressor()</span></span>
<span data-line><span># Fit model</span></span>
<span data-line><span>melbourne_model.fit(X, y)</span></span></code></pre></figure>
<p>Out[1]:</p>
<p><code>DecisionTreeRegressor()</code></p>
<p>모델이 있으면 평균 절대 오차를 계산하는 방법은 다음과 같습니다.</p>
<p>In [2]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>from sklearn.metrics import mean_absolute_error</span></span>
<span data-line><span>predicted_home_prices = melbourne_model.predict(X)</span></span>
<span data-line><span>mean_absolute_error(y, predicted_home_prices)</span></span></code></pre></figure>
<p>Out[2]:</p>
<p><code>434.71594577146544</code></p>
<h1 id="the-problem-with-in-sample-scores"><strong>The Problem with “In-Sample” Scores</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#the-problem-with-in-sample-scores" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>방금 계산한 측정값을 “샘플 내” 점수라고 합니다. 우리는 모델을 구축하고 평가하기 위해 주택의 단일 “샘플”을 사용했습니다. 이것이 나쁜 이유가 여기에 있습니다.</p>
<p>대규모 부동산 시장에서 문 색상이 주택 가격과 관련이 없다고 상상해 보십시오.</p>
<p>그러나 모델을 구축하는 데 사용한 데이터 샘플에서 녹색 문이 있는 모든 집은 매우 비쌌습니다. 모델의 임무는 주택 가격을 예측하는 패턴을 찾는 것이므로 이 패턴을 확인하고 항상 녹색 문이 있는 주택의 높은 가격을 예측합니다.</p>
<p>이 패턴은 교육 데이터에서 파생되었으므로 모델은 교육 데이터에서 정확하게 나타납니다.</p>
<p>그러나 모델이 새 데이터를 볼 때 이 패턴이 유지되지 않으면 실제로 사용할 때 모델이 매우 부정확합니다.</p>
<p>모델의 실질적인 가치는 새로운 데이터에 대한 예측에서 나오므로 모델을 구축하는 데 사용되지 않은 데이터에 대한 성능을 측정합니다. 이를 수행하는 가장 간단한 방법은 모델 구축 프로세스에서 일부 데이터를 제외하고 이를 사용하여 이전에 본 적이 없는 데이터에 대한 모델의 정확도를 테스트하는 것입니다. 이 데이터를 <strong>검증 데이터</strong>라고 합니다.</p>
<h1 id="coding-it"><strong>Coding It</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#coding-it" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>scikit-learn 라이브러리에는 데이터를 두 부분으로 나누는 ‘<code>train_test_split</code>’ 함수가 있습니다. 이 데이터 중 일부는 모델에 맞는 학습 데이터로 사용하고 다른 데이터는 검증 데이터로 사용하여 ‘<code>mean_absolute_error</code>’를 계산합니다.</p>
<p>코드는 다음과 같습니다.</p>
<p>In [3]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>from sklearn.model_selection import train_test_split</span></span>
<span data-line> </span>
<span data-line><span># split data into training and validation data, for both features and target</span></span>
<span data-line><span># The split is based on a random number generator. Supplying a numeric value to</span></span>
<span data-line><span># the random_state argument guarantees we get the same split every time we</span></span>
<span data-line><span># run this script.</span></span>
<span data-line><span>train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)</span></span>
<span data-line><span># Define model</span></span>
<span data-line><span>melbourne_model = DecisionTreeRegressor()</span></span>
<span data-line><span># Fit model</span></span>
<span data-line><span>melbourne_model.fit(train_X, train_y)</span></span>
<span data-line> </span>
<span data-line><span># get predicted prices on validation data</span></span>
<span data-line><span>val_predictions = melbourne_model.predict(val_X)</span></span>
<span data-line><span>print(mean_absolute_error(val_y, val_predictions))</span></span></code></pre></figure>
<p><code>258930.03550677857</code></p>
<h1 id="wow"><strong>Wow!</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#wow" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>샘플 내 데이터에 대한 평균 절대 오차는 약 500달러였습니다. 아웃 오브 샘플은 250,000 달러 이상입니다.</p>
<p>이것은 거의 정확히 맞는 모델과 대부분의 실용적인 목적에 사용할 수 없는 모델의 차이입니다. 참고로 검증 데이터의 평균 집값은 110만 달러다. 따라서 새 데이터의 오류는 평균 집값의 약 4분의 1입니다.</p>
<p>더 나은 기능이나 다른 모델 유형을 찾기 위한 실험과 같이 이 모델을 개선하는 방법은 많습니다.</p>
<p><strong>(Exercise: Model Validation)</strong></p>
<h2 id="underfitting-and-overfitting-link">Underfitting and Overfitting [link]<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#underfitting-and-overfitting-link" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>At the end of this step, you will understand the concepts of underfitting and overfitting, and you will be able to apply these ideas to make your models more accurate.</p>
<h1 id="experimenting-with-different-models"><strong>Experimenting With Different Models</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#experimenting-with-different-models" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>이 단계가 끝나면 과소적합 및 과적합의 개념을 이해하고 이러한 아이디어를 적용하여 모델을 더 정확하게 만들 수 있습니다.</p>
<p>scikit-learn의 문서에서 결정 트리 모델에 많은 옵션(오랫동안 원하거나 필요로 하는 것 이상)이 있음을 확인할 수 있습니다. 가장 중요한 옵션은 트리의 깊이를 결정합니다. 이 과정의 첫 번째 강의에서 나무의 깊이는 예측에 도달하기 전에 만드는 분할 수의 척도임을 기억하세요. 이것은 비교적 얕은 나무입니다</p>
<p><a href="http://i.imgur.com/R3ywQsR.png" class="external"><img src="http://i.imgur.com/R3ywQsR.png" alt/><svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<p>실제로 나무가 최상위 수준(모든 집)과 잎사귀 사이에 10개의 분할을 갖는 것은 드문 일이 아닙니다. 트리가 깊어질수록 데이터 세트는 더 적은 수의 집이 있는 리프로 분할됩니다. 트리가 1개만 분할된 경우 데이터를 2개의 그룹으로 나눕니다. 각 그룹이 다시 분할되면 4개의 하우스 그룹이 생성됩니다. 다시 각각을 나누면 8개의 그룹이 생성됩니다. 각 수준에서 더 많은 분할을 추가하여 그룹 수를 계속 두 배로 늘리면 10단계에 도달할 때까지 210210개의 집 그룹이 생깁니다. 1024개의 잎사귀입니다.</p>
<p>우리가 많은 잎사귀 사이에서 집을 나눌 때, 각 잎사귀에는 더 적은 수의 집이 있습니다. 집이 거의 없는 잎사귀는 해당 집의 실제 가치에 매우 가까운 예측을 하지만 새 데이터에 대해서는 매우 신뢰할 수 없는 예측을 할 수 있습니다(각 예측은 몇 개의 집에만 기반하기 때문).</p>
<p>모델이 학습 데이터와 거의 완벽하게 일치하지만 검증 및 기타 새로운 데이터에서는 제대로 작동하지 않는 과적합이라고 하는 현상입니다. 반대로 나무를 매우 얕게 만들면 집을 매우 뚜렷한 그룹으로 나누지 않습니다.</p>
<p>극단적으로 나무가 집을 2~4개로 나누더라도 각 그룹에는 여전히 다양한 집이 있습니다. 결과 예측은 훈련 데이터에서도 대부분의 주택에서 멀리 떨어져 있을 수 있습니다(동일한 이유로 유효성 검사에서도 나쁠 것입니다). 모델이 데이터에서 중요한 차이점과 패턴을 포착하지 못해 학습 데이터에서도 성능이 떨어지는 경우를 과소적합이라고 합니다.</p>
<p>검증 데이터에서 추정한 새 데이터의 정확도에 관심이 있기 때문에 과소적합과 과적합 사이의 적절한 지점을 찾고자 합니다. 시각적으로 우리는 아래 그림에서 (빨간색) 검증 곡선의 낮은 지점을 원합니다.</p>
<p><a href="http://i.imgur.com/AXSEOfI.png" class="external"><img src="http://i.imgur.com/AXSEOfI.png" alt/><svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<h1 id="example"><strong>Example</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#example" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>트리 깊이를 제어하기 위한 몇 가지 대안이 있으며 많은 경우 트리를 통과하는 일부 경로가 다른 경로보다 더 깊은 깊이를 가질 수 있습니다. 그러나 max_leaf_nodes 인수는 과적합과 과소적합을 제어하는 매우 합리적인 방법을 제공합니다. 모델이 만들 수 있는 잎이 많을수록 위 그래프의 과소적합 영역에서 과적합 영역으로 더 많이 이동합니다.</p>
<p>유틸리티 함수를 사용하여 max_leaf_nodes에 대한 다양한 값의 MAE 점수를 비교할 수 있습니다.</p>
<p>In [1]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>from sklearn.metrics import mean_absolute_error</span></span>
<span data-line><span>from sklearn.tree import DecisionTreeRegressor</span></span>
<span data-line> </span>
<span data-line><span>def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):</span></span>
<span data-line><span>    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)</span></span>
<span data-line><span>    model.fit(train_X, train_y)</span></span>
<span data-line><span>    preds_val = model.predict(val_X)</span></span>
<span data-line><span>    mae = mean_absolute_error(val_y, preds_val)</span></span>
<span data-line><span>    return(mae)</span></span></code></pre></figure>
<p>데이터는 이미 본 것과 같고 이미 작성한 코드를 사용하여 train_X, val_X, train_y 및 val_y에 로드됩니다.</p>
<p>In [2]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span># Data Loading Code Runs At This Point</span></span>
<span data-line><span>import pandas as pd</span></span>
<span data-line><span>    </span></span>
<span data-line><span># Load data</span></span>
<span data-line><span>melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'</span></span>
<span data-line><span>melbourne_data = pd.read_csv(melbourne_file_path) </span></span>
<span data-line><span># Filter rows with missing values</span></span>
<span data-line><span>filtered_melbourne_data = melbourne_data.dropna(axis=0)</span></span>
<span data-line><span># Choose target and features</span></span>
<span data-line><span>y = filtered_melbourne_data.Price</span></span>
<span data-line><span>melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', </span></span>
<span data-line><span>                        'YearBuilt', 'Lattitude', 'Longtitude']</span></span>
<span data-line><span>X = filtered_melbourne_data[melbourne_features]</span></span>
<span data-line> </span>
<span data-line><span>from sklearn.model_selection import train_test_split</span></span>
<span data-line> </span>
<span data-line><span># split data into training and validation data, for both features and target</span></span>
<span data-line><span>train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)</span></span></code></pre></figure>
<p>for-loop를 사용하여 max_leaf_nodes에 대해 다른 값으로 빌드된 모델의 정확도를 비교할 수 있습니다.</p>
<p>In [3]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span># compare MAE with differing values of max_leaf_nodes</span></span>
<span data-line><span>for max_leaf_nodes in [5, 50, 500, 5000]:</span></span>
<span data-line><span>    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)</span></span>
<span data-line><span>    print(&quot;Max leaf nodes: %d  \t\t Mean Absolute Error:  %d&quot; %(max_leaf_nodes, my_mae))</span></span></code></pre></figure>
<p><code>Max leaf nodes: 5 Mean Absolute Error: 347380 Max leaf nodes: 50 Mean Absolute Error: 258171 Max leaf nodes: 500 Mean Absolute Error: 243495 Max leaf nodes: 5000 Mean Absolute Error: 254983</code></p>
<p>나열된 옵션 중에서 최적의 리프 수는 500입니다.</p>
<hr/>
<h1 id="conclusion"><strong>Conclusion</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#conclusion" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>요점은 다음과 같습니다. 모델은 다음과 같은 문제를 겪을 수 있습니다.</p>
<ul>
<li><strong>과적합:</strong> 미래에 반복되지 않는 가짜 패턴을 캡처하여 덜 정확한 예측으로 이어짐</li>
<li><strong>과소적합:</strong> 관련 패턴을 캡처하지 못하여 예측 정확도가 떨어집니다.</li>
</ul>
<p>후보 모델의 정확도를 측정하기 위해 모델 학습에 사용되지 않는 <strong>검증</strong> 데이터를 사용합니다. 이를 통해 많은 후보 모델을 시도하고 최상의 모델을 유지할 수 있습니다.</p>
<p>(<strong>Exercise: Underfitting and Overfitting)</strong></p>
<h2 id="random-forests-link">Random Forests [link]<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#random-forests-link" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h1 id="introduction-1"><strong>Introduction</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#introduction-1" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>결정 트리는 어려운 결정을 내리게 합니다. 잎이 많은 깊은 나무는 각 예측이 잎에 있는 몇 채의 집의 과거 데이터에서 나오기 때문에 과대적합됩니다. 그러나 리프가 적은 얕은 트리는 원시 데이터에서 많은 차이를 캡처하지 못하기 때문에 성능이 좋지 않습니다.</p>
<p>오늘날의 가장 정교한 모델링 기술조차도 과소적합과 과적합 사이의 긴장에 직면해 있습니다. 그러나 많은 모델에는 더 나은 성능으로 이어질 수 있는 영리한 아이디어가 있습니다. 랜덤 포레스트를 예로 들어 보겠습니다.</p>
<p>랜덤 포레스트는 많은 트리를 사용하며 각 컴포넌트 트리의 예측을 평균하여 예측합니다. 일반적으로 단일 의사 결정 트리보다 예측 정확도가 훨씬 뛰어나며 기본 매개변수와 잘 작동합니다. 모델링을 계속하면 더 나은 성능으로 더 많은 모델을 학습할 수 있지만 많은 모델이 올바른 매개변수를 얻는 데 민감합니다.</p>
<h1 id="example-1"><strong>Example</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#example-1" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>이미 몇 번 데이터를 로드하는 코드를 보았습니다. 데이터 로딩이 끝나면 다음과 같은 변수가 있습니다.</p>
<ul>
<li>train_X</li>
<li>val_X</li>
<li>train_y</li>
<li>val_y</li>
</ul>
<p>In [1]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>import pandas as pd</span></span>
<span data-line><span>    </span></span>
<span data-line><span># Load data</span></span>
<span data-line><span>melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'</span></span>
<span data-line><span>melbourne_data = pd.read_csv(melbourne_file_path) </span></span>
<span data-line><span># Filter rows with missing values</span></span>
<span data-line><span>melbourne_data = melbourne_data.dropna(axis=0)</span></span>
<span data-line><span># Choose target and features</span></span>
<span data-line><span>y = melbourne_data.Price</span></span>
<span data-line><span>melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', </span></span>
<span data-line><span>                        'YearBuilt', 'Lattitude', 'Longtitude']</span></span>
<span data-line><span>X = melbourne_data[melbourne_features]</span></span>
<span data-line> </span>
<span data-line><span>from sklearn.model_selection import train_test_split</span></span>
<span data-line> </span>
<span data-line><span># split data into training and validation data, for both features and target</span></span>
<span data-line><span># The split is based on a random number generator. Supplying a numeric value to</span></span>
<span data-line><span># the random_state argument guarantees we get the same split every time we</span></span>
<span data-line><span># run this script.</span></span>
<span data-line><span>train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)</span></span></code></pre></figure>
<p>scikit-learn에서 결정 트리를 구축한 방법과 유사하게 랜덤 포레스트 모델을 구축합니다. 이번에는 DecisionTreeRegressor 대신 RandomForestRegressor 클래스를 사용합니다.</p>
<p>In [2]:</p>
<figure data-rehype-pretty-code-figure><pre tabindex="0" data-language="Python" data-theme="github-light github-dark"><code data-language="Python" data-theme="github-light github-dark" style="display:grid;"><span data-line><span>from sklearn.ensemble import RandomForestRegressor</span></span>
<span data-line><span>from sklearn.metrics import mean_absolute_error</span></span>
<span data-line> </span>
<span data-line><span>forest_model = RandomForestRegressor(random_state=1)</span></span>
<span data-line><span>forest_model.fit(train_X, train_y)</span></span>
<span data-line><span>melb_preds = forest_model.predict(val_X)</span></span>
<span data-line><span>print(mean_absolute_error(val_y, melb_preds))</span></span></code></pre></figure>
<p><code>191669.7536453626</code></p>
<h1 id="conclusion-1"><strong>Conclusion</strong><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#conclusion-1" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>추가 개선의 여지가 있을 수 있지만 이는 250,000의 최상의 의사 결정 트리 오류에 비해 크게 개선된 것입니다. 단일 결정 트리의 최대 깊이를 변경한 만큼 Random Forest의 성능을 변경할 수 있는 매개 변수가 있습니다. 그러나 Random Forest 모델의 가장 좋은 기능 중 하나는 이러한 튜닝 없이도 일반적으로 합리적으로 작동한다는 것입니다.</p>
<p>(<strong>Exercise: Random Forests)</strong></p>
<p><strong>(Exercise: Machine Learning Competitions)</strong></p></article><hr/><div class="page-footer"></div></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div class="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false,&quot;enableRadial&quot;:false}"></div><button class="global-graph-icon" aria-label="Global Graph"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
                s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
                c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
                C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
                c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
                v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
                s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
                C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
                S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
                s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
                s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></button></div><div class="global-graph-outer"><div class="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.2,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true,&quot;enableRadial&quot;:true}"></div></div></div><div class="toc desktop-only"><button type="button" class="toc-header" aria-controls="toc-content" aria-expanded="true"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><ul class="toc-content overflow" id="list-1"><li class="depth-0"><a href="#참조" data-for="참조">참조</a></li><li class="depth-0"><a href="#kaggle---intro-to-machine-learning" data-for="kaggle---intro-to-machine-learning">Kaggle - Intro to Machine Learning</a></li><li class="depth-1"><a href="#how-models-work-link" data-for="how-models-work-link">How Models Work [link]</a></li><li class="depth-0"><a href="#introduction" data-for="introduction">Introduction</a></li><li class="depth-0"><a href="#improving-the-decision-tree" data-for="improving-the-decision-tree">Improving the Decision Tree</a></li><li class="depth-1"><a href="#basic-data-exploration-link" data-for="basic-data-exploration-link">Basic Data Exploration [link]</a></li><li class="depth-0"><a href="#using-pandas-to-get-familiar-with-your-data" data-for="using-pandas-to-get-familiar-with-your-data">Using Pandas to Get Familiar With Your Data</a></li><li class="depth-0"><a href="#interpreting-data-description" data-for="interpreting-data-description">Interpreting Data Description</a></li><li class="depth-1"><a href="#your-first-machine-learning-model-link" data-for="your-first-machine-learning-model-link">Your First Machine Learning Model [link]</a></li><li class="depth-0"><a href="#selecting-data-for-modeling" data-for="selecting-data-for-modeling">Selecting Data for Modeling</a></li><li class="depth-1"><a href="#selecting-the-prediction-target" data-for="selecting-the-prediction-target">Selecting The Prediction Target</a></li><li class="depth-0"><a href="#choosing-features" data-for="choosing-features">Choosing “Features”</a></li><li class="depth-0"><a href="#building-your-model" data-for="building-your-model">Building Your Model</a></li><li class="depth-1"><a href="#model-validation-link" data-for="model-validation-link">Model Validation [link]</a></li><li class="depth-0"><a href="#what-is-model-validation" data-for="what-is-model-validation">What is Model Validation</a></li><li class="depth-0"><a href="#the-problem-with-in-sample-scores" data-for="the-problem-with-in-sample-scores">The Problem with “In-Sample” Scores</a></li><li class="depth-0"><a href="#coding-it" data-for="coding-it">Coding It</a></li><li class="depth-0"><a href="#wow" data-for="wow">Wow!</a></li><li class="depth-1"><a href="#underfitting-and-overfitting-link" data-for="underfitting-and-overfitting-link">Underfitting and Overfitting [link]</a></li><li class="depth-0"><a href="#experimenting-with-different-models" data-for="experimenting-with-different-models">Experimenting With Different Models</a></li><li class="depth-0"><a href="#example" data-for="example">Example</a></li><li class="depth-0"><a href="#conclusion" data-for="conclusion">Conclusion</a></li><li class="depth-1"><a href="#random-forests-link" data-for="random-forests-link">Random Forests [link]</a></li><li class="depth-0"><a href="#introduction-1" data-for="introduction-1">Introduction</a></li><li class="depth-0"><a href="#example-1" data-for="example-1">Example</a></li><li class="depth-0"><a href="#conclusion-1" data-for="conclusion-1">Conclusion</a></li><li class="overflow-end"></li></ul></div><div class="backlinks"><h3>Backlinks</h3><ul id="list-2" class="overflow"><li><a href="../../../Notion/HyeongSeok-Kim’s-Notion/HyeongSeok-Kim’s-Notion" class="internal">HyeongSeok Kim’s Notion</a></li><li><a href="../../../" class="internal">Main</a></li><li class="overflow-end"></li></ul></div></div><footer class><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.5.1</a> © 2025</p><ul><li><a href="https://github.com/404Vector/404Vector">GitHub</a></li></ul></footer></div></div></body><script type="application/javascript">function n(){let t=this.parentElement;t.classList.toggle("is-collapsed");let e=t.getElementsByClassName("callout-content")[0];if(!e)return;let l=t.classList.contains("is-collapsed");e.style.gridTemplateRows=l?"0fr":"1fr"}function c(){let t=document.getElementsByClassName("callout is-collapsible");for(let e of t){let l=e.getElementsByClassName("callout-title")[0],s=e.getElementsByClassName("callout-content")[0];if(!l||!s)continue;l.addEventListener("click",n),window.addCleanup(()=>l.removeEventListener("click",n));let o=e.classList.contains("is-collapsed");s.style.gridTemplateRows=o?"0fr":"1fr"}}document.addEventListener("nav",c);
</script><script type="module">function f(i,e){if(!i)return;function r(o){o.target===this&&(o.preventDefault(),o.stopPropagation(),e())}function t(o){o.key.startsWith("Esc")&&(o.preventDefault(),e())}i?.addEventListener("click",r),window.addCleanup(()=>i?.removeEventListener("click",r)),document.addEventListener("keydown",t),window.addCleanup(()=>document.removeEventListener("keydown",t))}function y(i){for(;i.firstChild;)i.removeChild(i.firstChild)}var h=class{constructor(e,r){this.container=e;this.content=r;this.setupEventListeners(),this.setupNavigationControls(),this.resetTransform()}isDragging=!1;startPan={x:0,y:0};currentPan={x:0,y:0};scale=1;MIN_SCALE=.5;MAX_SCALE=3;cleanups=[];setupEventListeners(){let e=this.onMouseDown.bind(this),r=this.onMouseMove.bind(this),t=this.onMouseUp.bind(this),o=this.resetTransform.bind(this);this.container.addEventListener("mousedown",e),document.addEventListener("mousemove",r),document.addEventListener("mouseup",t),window.addEventListener("resize",o),this.cleanups.push(()=>this.container.removeEventListener("mousedown",e),()=>document.removeEventListener("mousemove",r),()=>document.removeEventListener("mouseup",t),()=>window.removeEventListener("resize",o))}cleanup(){for(let e of this.cleanups)e()}setupNavigationControls(){let e=document.createElement("div");e.className="mermaid-controls";let r=this.createButton("+",()=>this.zoom(.1)),t=this.createButton("-",()=>this.zoom(-.1)),o=this.createButton("Reset",()=>this.resetTransform());e.appendChild(t),e.appendChild(o),e.appendChild(r),this.container.appendChild(e)}createButton(e,r){let t=document.createElement("button");return t.textContent=e,t.className="mermaid-control-button",t.addEventListener("click",r),window.addCleanup(()=>t.removeEventListener("click",r)),t}onMouseDown(e){e.button===0&&(this.isDragging=!0,this.startPan={x:e.clientX-this.currentPan.x,y:e.clientY-this.currentPan.y},this.container.style.cursor="grabbing")}onMouseMove(e){this.isDragging&&(e.preventDefault(),this.currentPan={x:e.clientX-this.startPan.x,y:e.clientY-this.startPan.y},this.updateTransform())}onMouseUp(){this.isDragging=!1,this.container.style.cursor="grab"}zoom(e){let r=Math.min(Math.max(this.scale+e,this.MIN_SCALE),this.MAX_SCALE),t=this.content.getBoundingClientRect(),o=t.width/2,n=t.height/2,c=r-this.scale;this.currentPan.x-=o*c,this.currentPan.y-=n*c,this.scale=r,this.updateTransform()}updateTransform(){this.content.style.transform=`translate(${this.currentPan.x}px, ${this.currentPan.y}px) scale(${this.scale})`}resetTransform(){this.scale=1;let e=this.content.querySelector("svg");this.currentPan={x:e.getBoundingClientRect().width/2,y:e.getBoundingClientRect().height/2},this.updateTransform()}},C=["--secondary","--tertiary","--gray","--light","--lightgray","--highlight","--dark","--darkgray","--codeFont"],E;document.addEventListener("nav",async()=>{let e=document.querySelector(".center").querySelectorAll("code.mermaid");if(e.length===0)return;E||=await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.esm.min.mjs");let r=E.default,t=new WeakMap;for(let n of e)t.set(n,n.innerText);async function o(){for(let s of e){s.removeAttribute("data-processed");let a=t.get(s);a&&(s.innerHTML=a)}let n=C.reduce((s,a)=>(s[a]=window.getComputedStyle(document.documentElement).getPropertyValue(a),s),{}),c=document.documentElement.getAttribute("saved-theme")==="dark";r.initialize({startOnLoad:!1,securityLevel:"loose",theme:c?"dark":"base",themeVariables:{fontFamily:n["--codeFont"],primaryColor:n["--light"],primaryTextColor:n["--darkgray"],primaryBorderColor:n["--tertiary"],lineColor:n["--darkgray"],secondaryColor:n["--secondary"],tertiaryColor:n["--tertiary"],clusterBkg:n["--light"],edgeLabelBackground:n["--highlight"]}}),await r.run({nodes:e})}await o(),document.addEventListener("themechange",o),window.addCleanup(()=>document.removeEventListener("themechange",o));for(let n=0;n<e.length;n++){let v=function(){let g=l.querySelector("#mermaid-space"),m=l.querySelector(".mermaid-content");if(!m)return;y(m);let w=c.querySelector("svg").cloneNode(!0);m.appendChild(w),l.classList.add("active"),g.style.cursor="grab",u=new h(g,m)},M=function(){l.classList.remove("active"),u?.cleanup(),u=null},c=e[n],s=c.parentElement,a=s.querySelector(".clipboard-button"),d=s.querySelector(".expand-button"),p=window.getComputedStyle(a),L=a.offsetWidth+parseFloat(p.marginLeft||"0")+parseFloat(p.marginRight||"0");d.style.right=`calc(${L}px + 0.3rem)`,s.prepend(d);let l=s.querySelector("#mermaid-container");if(!l)return;let u=null;d.addEventListener("click",v),f(l,M),window.addCleanup(()=>{u?.cleanup(),d.removeEventListener("click",v)})}});
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="../../../postscript.js" type="module"></script></html>